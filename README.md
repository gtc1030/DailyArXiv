# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-09-10

## Fluid Dynamics
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Mixed-precision numerics in scientific applications: survey and perspectives](http://arxiv.org/abs/2412.19322v3)** | 2025-09-08 | <details><summary>Show</summary><p>The explosive demand for artificial intelligence (AI) workloads has led to a significant increase in silicon area dedicated to lower-precision computations on recent high-performance computing hardware designs. However, mixed-precision capabilities, which can achieve performance improvements of 8x compared to double-precision in extreme compute-intensive workloads, remain largely untapped in most scientific applications. A growing number of efforts have shown that mixed-precision algorithmic innovations can deliver superior performance without sacrificing accuracy. These developments should prompt computational scientists to seriously consider whether their scientific modeling and simulation applications could benefit from the acceleration offered by new hardware and mixed-precision algorithms. In this survey, we (1) review progress across diverse scientific domains -- including fluid dynamics, weather and climate, quantum chemistry, and computational genomics -- that have begun adopting mixed-precision strategies; (2) examine state-of-the-art algorithmic techniques such as iterative refinement, splitting and emulation schemes, and adaptive precision solvers; (3) assess their implications for accuracy, performance, and resource utilization; and (4) survey the emerging software ecosystem that enables mixed-precision methods at scale. We conclude with perspectives and recommendations on cross-cutting opportunities, domain-specific challenges, and the role of co-design between application scientists, numerical analysts and computer scientists. Collectively, this survey underscores that mixed-precision numerics can reshape computational science by aligning algorithms with the evolving landscape of hardware capabilities.</p></details> | <details><summary>Submi...</summary><p>Submitted to Journal of Supercomputing</p></details> |
| **[ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with Domain-Specific Structured Reasoning](http://arxiv.org/abs/2506.02019v2)** | 2025-09-08 | <details><summary>Show</summary><p>Computational Fluid Dynamics (CFD) is essential for advancing scientific and engineering fields but is hindered by operational complexity, high expertise requirements, and limited accessibility. This paper introduces ChatCFD, an automated agent system for OpenFOAM simulations that processes multi-modal inputs (e.g., research papers, meshes) via an interactive interface, leveraging DeepSeek-R1 and DeepSeek-V3 large language models, a multi-agent architecture, and OpenFOAM knowledge. Its four-stage pipeline (Knowledge Base Construction, User Input Processing, Case File Generation, and Execution and Error Reflection) enables iterative trial-reflection-refinement for intricate setups, supporting diverse physical models and external meshes. Validation on 205 benchmark tutorial cases, 110 perturbed variants, and 2 literature-derived cases shows ChatCFD's 82.1 percent operational success rate on basic cases, outperforming MetaOpenFOAM (6.2 percent) and Foam-Agent (42.3 percent), and 60-80 percent on literature-derived complex cases. Turbulence model studies show a 40 percent success rate for common models versus 10 percent for rare ones like RNG k-epsilon. Physics coupling analyses reveal higher resource demands for multi-physics-coupled cases, while LLM bias toward simpler setups introduces persistent errors, such as dimensional inconsistency. Ablation studies highlight the efficacy of RAG-based modules and reflection mechanisms. By automating hypothesis testing and parameter exploration, ChatCFD accelerates scientific discovery in fluid mechanics and engineering, addressing LLM limitations through structured design and showing strong potential as a modular component in MCP-based agent networks for collaborative multi-agent systems, paving the way for scalable AI-driven CFD innovation. The code for ChatCFD is available at https://github.com/ConMoo/ChatCFD.</p></details> | 19 pages, 8 figures |
| **[A novel biomass fluidized bed gasification model coupled with machine learning and CFD simulation](http://arxiv.org/abs/2509.06056v1)** | 2025-09-07 | <details><summary>Show</summary><p>A coupling model of biomass fluidized bed gasification based on machine learning and computational fluid dynamics is proposed to improve the prediction accuracy and computational efficiency of complex thermochemical reaction process. By constructing a high-quality data set based on experimental data and high fidelity simulation results, the agent model used to describe the characteristics of reaction kinetics was trained and embedded into the computational fluid dynamics (CFD) framework to realize the real-time update of reaction rate and composition evolution.</p></details> |  |
| **[Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities](http://arxiv.org/abs/2509.06041v1)** | 2025-09-07 | <details><summary>Show</summary><p>Buoyancy-driven heat transfer in closed cavities serves as a canonical testbed for thermal design High-fidelity CFD modelling yields accurate thermal field solutions, yet its reliance on expert-crafted physics models, fine meshes, and intensive computation limits rapid iteration. Recent developments in data-driven modeling, especially Graph Neural Networks (GNNs), offer new alternatives for learning thermal-fluid behavior directly from simulation data, particularly on irregular mesh structures. However, conventional GNNs often struggle to capture long-range dependencies in high-resolution graph structures. To overcome this limitation, we propose a novel multi-stage GNN architecture that leverages hierarchical pooling and unpooling operations to progressively model global-to-local interactions across multiple spatial scales. We evaluate the proposed model on our newly developed CFD dataset simulating natural convection within a rectangular cavities with varying aspect ratios where the bottom wall is isothermal hot, the top wall is isothermal cold, and the two vertical walls are adiabatic. Experimental results demonstrate that the proposed model achieves higher predictive accuracy, improved training efficiency, and reduced long-term error accumulation compared to state-of-the-art (SOTA) GNN baselines. These findings underscore the potential of the proposed multi-stage GNN approach for modeling complex heat transfer in mesh-based fluid dynamics simulations.</p></details> |  |
| **[SPINN: An Optimal Self-Supervised Physics-Informed Neural Network Framework](http://arxiv.org/abs/2509.05886v1)** | 2025-09-07 | <details><summary>Show</summary><p>A surrogate model is developed to predict the convective heat transfer coefficient of liquid sodium (Na) flow within rectangular miniature heat sinks. Initially, kernel-based machine learning techniques and shallow neural network are applied to a dataset with 87 Nusselt numbers for liquid sodium in rectangular miniature heat sinks. Subsequently, a self-supervised physics-informed neural network and transfer learning approach are used to increase the estimation performance. In the self-supervised physics-informed neural network, an additional layer determines the weight the of physics in the loss function to balance data and physics based on their uncertainty for a better estimation. For transfer learning, a shallow neural network trained on water is adapted for use with Na. Validation results show that the self-supervised physics-informed neural network successfully estimate the heat transfer rates of Na with an error margin of approximately +8%. Using only physics for regression, the error remains between 5% to 10%. Other machine learning methods specify the prediction mostly within +8%. High-fidelity modeling of turbulent forced convection of liquid metals using computational fluid dynamics (CFD) is both time-consuming and computationally expensive. Therefore, machine learning based models offer a powerful alternative tool for the design and optimization of liquid-metal-cooled miniature heat sinks.</p></details> |  |
| **[Energy Transfer Dynamics Generated by Non-Axisymmetric Tornado-Type Flows](http://arxiv.org/abs/2509.05546v1)** | 2025-09-06 | <details><summary>Show</summary><p>The energy cascade in turbulence, first statistically described by Richardson (1922) and Kolmogorov (1941), lacked connection to the underlying fluid dynamics. Recent numerical studies of Goto et al. (2017) and Yoneda et al. (2022) revealed scale-local energy transfer via vortex stretching but remained within spatial statistics. This study aims to uncover the time-dependent elementary process behind the energy cascade by constructing a tornado-type flow in a non-axisymmetric curved cylindrical domain. Our approach reveals specific vortex dynamics responsible for energy transfer, offering new insight into the physical mechanisms of turbulence.</p></details> | 15 pages, 15 figures |
| **[Entropy stable finite difference methods via entropy correction artificial viscosity and knapsack limiting](http://arxiv.org/abs/2508.21226v2)** | 2025-09-05 | <details><summary>Show</summary><p>Entropy stable methods have become increasingly popular in the field of computational fluid dynamics. They often work by satisfying some form of a discrete entropy inequality: a discrete form of the 2nd law of thermodynamics. Schemes which satisfy a (semi-)discrete entropy inequality typically behave much more robustly, and do so in a way that is hyperparameter free. Recently, a new strategy was introduced to construct entropy stable discontinuous Galerkin methods: knapsack limiting, which blends together a low order, positivity preserving, and entropy stable scheme with a high order accurate scheme, in order to produce a high order accurate, entropy stable, and positivity preserving scheme. Another recent strategy introduces an entropy correction artificial viscosity into a high order scheme, aiming to satisfy a cell entropy inequality. In this work, we introduce the techniques of knapsack limiting and artificial viscosity for finite difference discretizations. The proposed schemes preserve high order accuracy in sufficiently smooth conditions, are entropy stable, and are hyperparameter free. Moreover, the proposed knapsack limiting scheme provably preserves positivity for the compressible Euler and Navier-Stokes equations. Both schemes achieve this goal without significant performance tradeoffs compared to state of the art stabilized schemes.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2507.14488</p></details> |
| **[A novel approach to study the wellposedness of the 3D fluid-2D plate interaction PDE System](http://arxiv.org/abs/2509.03431v1)** | 2025-09-03 | <details><summary>Show</summary><p>We consider a certain fluid-structure interaction (FSI) system with a view of obtaining an alternative methodology for establishing its strongly continuous semigroup wellposedness. (Semigroup generation for this FSI was originally considered in Avalos-Clark (2014).) The FSI model under consideration describes the vibrations of an incompressible fluid within a 3D cavity as it interacts with the elastic membrane on the ``free" upper boundary of the cavity. Such coupled PDE systems appear in variety of natural settings such as biomedicine, aeroelasticity, and fluid dynamics. Our proof of $C_0$-semigroup wellposedness is based on a proper application of Lumer Phillips Theorem. In this regard, our main challenge is to show the maximality of the corresponding semigroup generator. To this end, we develop a ``nonstandard" inf-sup approach which avoids the use of technical nonlocal maps in the associated bilinear forms--unlike the earlier paper Avalos-Clark (2014)--and allows for the solution of the fluid and plate solution variables simultanously. Our new inf-sup strategy will lead to a more efficient mixed finite element method (FEM) for approximating solutions to the FSI problem, inasmuch our novel variational formulation avoids bilinear forms which are free from the computationally-intensive nonlocal solution operators invoked in Avalos-Clark (2014). We also perform numerical tests based on this formulation using a benchmark problem and present numerical results to demonstrate the effectiveness of our approach.</p></details> | 23 pages, 4 figures |
| **[Computational Fluid Dynamics Optimization of F1 Front Wing using Physics Informed Neural Networks](http://arxiv.org/abs/2509.01963v1)** | 2025-09-02 | <details><summary>Show</summary><p>In response to recent FIA regulations reducing Formula 1 team wind tunnel hours (from 320 hours for last-place teams to 200 hours for championship leaders) and strict budget caps of 135 million USD per year, more efficient aerodynamic development tools are needed by teams. Conventional computational fluid dynamics (CFD) simulations, though offering high fidelity results, require large computational resources with typical simulation durations of 8-24 hours per configuration analysis. This article proposes a Physics-Informed Neural Network (PINN) for the fast prediction of Formula 1 front wing aerodynamic coefficients. The suggested methodology combines CFD simulation data from SimScale with first principles of fluid dynamics through a hybrid loss function that constrains both data fidelity and physical adherence based on Navier-Stokes equations. Training on force and moment data from 12 aerodynamic features, the PINN model records coefficient of determination (R-squared) values of 0.968 for drag coefficient and 0.981 for lift coefficient prediction while lowering computational time. The physics-informed framework guarantees that predictions remain adherent to fundamental aerodynamic principles, offering F1 teams an efficient tool for the fast exploration of design space within regulatory constraints.</p></details> | 10 pages, 3 figures |
| **[Towards Digital Twins for Optimal Radioembolization](http://arxiv.org/abs/2509.02607v1)** | 2025-08-30 | <details><summary>Show</summary><p>Radioembolization is a localized liver cancer treatment that delivers radioactive microspheres (30 micron) to tumors via a catheter inserted in the hepatic arterial tree. The goal is to maximize therapeutic efficacy while minimizing damage to healthy liver tissue. However, optimization is challenging due to complex hepatic artery anatomy, variable blood flow, and uncertainty in microsphere transport. The creation of dynamic, patient-specific digital twins may provide a transformative solution to these challenges. This work outlines a framework for a liver radioembolization digital twin using high-fidelity computational fluid dynamics (CFD) and/or recent physics-informed machine learning approaches. The CFD approach involves microsphere transport calculations in the hepatic arterial tree with individual patient data, which enables personalized treatment planning. Although accurate, traditional CFD is computationally expensive and limits clinical applicability. To accelerate simulations, physics-informed neural networks (PINNs) and their generative extensions play an increasingly important role. PINNs integrate governing equations, such as the Navier-Stokes equations, directly into the neural network training process, enabling mesh-free, data-efficient approximation of blood flow and microsphere transport. Physics-informed generative adversarial networks (PI-GANs), diffusion models (PI-DMs), and transformer-based architectures further enable uncertainty-aware, temporally resolved predictions with reduced computational cost. These AI surrogates not only maintain physical fidelity but also support rapid sampling of diverse flow scenarios, facilitating real-time decision support. Together, CFD and physics-informed AI methods form the foundation of dynamic, patient-specific digital twin to optimize radioembolization planning and ultimately improve clinical outcomes.</p></details> |  |
| **[Evaluate Neighbor Search for Curve-based Vector Field Processing](http://arxiv.org/abs/2509.00180v1)** | 2025-08-29 | <details><summary>Show</summary><p>Curve-based representations, particularly integral curves, are often used to represent large-scale computational fluid dynamic simulations. Processing and analyzing curve-based vector field data sets often involves searching for neighboring segments given a query point or curve segment. However, because the original flow behavior may not be fully represented by the set of integral curves and the input integral curves may not be evenly distributed in space, popular neighbor search strategies often return skewed and redundant neighboring segments. Yet, there is a lack of systematic and comprehensive research on how different configurations of neighboring segments returned by specific neighbor search strategies affect subsequent tasks. To fill this gap, this study evaluates the performance of two popular neighbor search strategies combined with different distance metrics on a point-based vector field reconstruction task and a segment saliency estimation using input integral curves. A large number of reconstruction tests and saliency calculations are conducted for the study. To characterize the configurations of neighboring segments for an effective comparison of different search strategies, a number of measures, like average neighbor distance and uniformity, are proposed. Our study leads to a few observations that partially confirm our expectations about the ideal configurations of a neighborhood while revealing additional findings that were overlooked by the community.</p></details> | 12 pages, 17 figures |
| **[Simulating many-engine spacecraft: Exceeding 1 quadrillion degrees of freedom via information geometric regularization](http://arxiv.org/abs/2505.07392v3)** | 2025-08-29 | <details><summary>Show</summary><p>We present an optimized implementation of the recently proposed information geometric regularization (IGR) for unprecedented scale simulation of compressible fluid flows applied to multi-engine spacecraft boosters. We improve upon state-of-the-art computational fluid dynamics (CFD) techniques along computational cost, memory footprint, and energy-to-solution metrics. Unified memory on coupled CPU--GPU or APU platforms increases problem size with negligible overhead. Mixed half/single-precision storage and computation on well-conditioned numerics is used. We simulate flow at 200 trillion grid points and 1 quadrillion degrees of freedom, exceeding the current record by a factor of 20. A factor of 4 wall-time speedup is achieved over optimized baselines. Ideal weak scaling is seen on OLCF Frontier, LLNL El Capitan, and CSCS Alps using the full systems. Strong scaling is near ideal at extreme conditions, including 80% efficiency on CSCS Alps with an 8-node baseline and stretching to the full system.</p></details> | <details><summary>11 pa...</summary><p>11 pages, 8 figures, 4 tables. ACM Gordon Bell Prize Finalist</p></details> |
| **[Active Learning for Deep Learning-Based Hemodynamic Parameter Estimation](http://arxiv.org/abs/2503.03453v2)** | 2025-08-27 | <details><summary>Show</summary><p>Hemodynamic parameters such as pressure and wall shear stress play an important role in diagnosis, prognosis, and treatment planning in cardiovascular diseases. These parameters can be accurately computed using computational fluid dynamics (CFD), but CFD is computationally intensive. Hence, deep learning methods have been adopted as a surrogate to rapidly estimate CFD outcomes. A drawback of such data-driven models is the need for time-consuming reference CFD simulations for training. In this work, we introduce an active learning framework to reduce the number of CFD simulations required for the training of surrogate models, lowering the barriers to their deployment in new applications. We propose three distinct querying strategies to determine for which unlabeled samples CFD simulations should be obtained. These querying strategies are based on geometrical variance, ensemble uncertainty, and adherence to the physics governing fluid dynamics. We benchmark these methods on velocity field estimation in synthetic coronary artery bifurcations and find that they allow for substantial reductions in annotation cost. Notably, we find that our strategies reduce the number of samples required by up to 50% and make the trained models more robust to difficult cases. Our results show that active learning is a feasible strategy to increase the potential of deep learning-based CFD surrogates.</p></details> |  |
| **[Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior](http://arxiv.org/abs/2410.11920v2)** | 2025-08-26 | <details><summary>Show</summary><p>Cardiovascular hemodynamic fields provide valuable medical decision markers for coronary artery disease. Computational fluid dynamics (CFD) is the gold standard for accurate, non-invasive evaluation of these quantities in silico. In this work, we propose a time-efficient surrogate model, powered by machine learning, for the estimation of pulsatile hemodynamics based on steady-state priors. We introduce deep vectorised operators, a modelling framework for discretisation-independent learning on infinite-dimensional function spaces. The underlying neural architecture is a neural field conditioned on hemodynamic boundary conditions. Importantly, we show how relaxing the requirement of point-wise action to permutation-equivariance leads to a family of models that can be parametrised by message passing and self-attention layers. We evaluate our approach on a dataset of 74 stenotic coronary arteries extracted from coronary computed tomography angiography (CCTA) with patient-specific pulsatile CFD simulations as ground truth. We show that our model produces accurate estimates of the pulsatile velocity and pressure (approximation disparity 0.368 $\pm$ 0.079) while being agnostic ($p < 0.05$ in a one-way ANOVA test) to re-sampling of the source domain, i.e. discretisation-independent. This shows that deep vectorised operators are a powerful modelling tool for cardiovascular hemodynamics estimation in coronary arteries and beyond.</p></details> | <details><summary>Publi...</summary><p>Published in "Computer Methods and Programs in Biomedicine"</p></details> |
| **[Impact of curved elements for flows over orography with a Discontinuous Galerkin scheme](http://arxiv.org/abs/2404.09319v4)** | 2025-08-26 | <details><summary>Show</summary><p>We present a quantitative assessment of the impact of high-order mappings on the simulation of flows over complex orography. Curved boundaries were not used in early numerical methods, whereas they are employed to an increasing extent in state of the art computational fluid dynamics codes, in combination with high-order methods, such as the Finite Element Method and the Spectral Element Method. Here we consider a specific Discontinuous Galerkin (DG) method implemented in the framework of the deal.II library, which natively supports high-order mappings. A number of numerical experiments based on classical benchmarks over idealized orographic profiles demonstrate the positive impact of curved boundaries on the accuracy of the results, with no significantly adverse effect on the computational cost of the simulation. These findings are also supported by results of the application of this approach to non-smooth and realistic orographic profiles.</p></details> |  |
| **[Data-Driven Discovery and Formulation Refines the Quasi-Steady Model of Flapping-Wing Aerodynamics](http://arxiv.org/abs/2508.18703v1)** | 2025-08-26 | <details><summary>Show</summary><p>Insects control unsteady aerodynamic forces on flapping wings to navigate complex environments. While understanding these forces is vital for biology, physics, and engineering, existing evaluation methods face trade-offs: high-fidelity simulations are computationally or experimentally expensive and lack explanatory power, whereas theoretical models based on quasi-steady assumptions offer insights but exhibit low accuracy. To overcome these limitations and thus enhance the accuracy of quasi-steady aerodynamic models, we applied a data-driven approach involving discovery and formulation of previously overlooked critical mechanisms. Through selection from 5,000 candidate kinematic functions, we identified mathematical expressions for three key additional mechanisms -- the effect of advance ratio, effect of spanwise kinematic velocity, and rotational Wagner effect -- which had been qualitatively recognized but were not formulated. Incorporating these mechanisms considerably reduced the prediction errors of the quasi-steady model using the computational fluid dynamics results as the ground truth, both in hawkmoth forward flight (at high Reynolds numbers) and fruit fly maneuvers (at low Reynolds numbers). The data-driven quasi-steady model enables rapid aerodynamic analysis, serving as a practical tool for understanding evolutionary adaptations in insect flight and developing bio-inspired flying robots.</p></details> | 27 pages, 13 figures |
| **[Improving Long-term Autoregressive Spatiotemporal Predictions: A Proof of Concept with Fluid Dynamics](http://arxiv.org/abs/2508.18565v1)** | 2025-08-25 | <details><summary>Show</summary><p>Data-driven methods are emerging as efficient alternatives to traditional numerical forecasting, offering fast inference and lower computational cost. Yet, for complex systems, long-term accuracy often deteriorates due to error accumulation, and autoregressive training (though effective) demands large GPU memory and may sacrifice short-term performance. We propose the Stochastic PushForward (SPF) framework, which retains one-step-ahead training while enabling multi-step learning. SPF builds a supplementary dataset from model predictions and combines it with ground truth via a stochastic acquisition strategy, balancing short- and long-term performance while reducing overfitting. Multi-step predictions are precomputed between epochs, keeping memory usage stable without storing full unrolled sequences. Experiments on the Burgers' equation and the Shallow Water benchmark show that SPF achieves higher long-term accuracy than autoregressive methods while lowering memory requirements, making it promising for resource-limited and complex simulations.</p></details> |  |
| **[Training Transformers for Mesh-Based Simulations](http://arxiv.org/abs/2508.18051v1)** | 2025-08-25 | <details><summary>Show</summary><p>Simulating physics using Graph Neural Networks (GNNs) is predominantly driven by message-passing architectures, which face challenges in scaling and efficiency, particularly in handling large, complex meshes. These architectures have inspired numerous enhancements, including multigrid approaches and $K$-hop aggregation (using neighbours of distance $K$), yet they often introduce significant complexity and suffer from limited in-depth investigations. In response to these challenges, we propose a novel Graph Transformer architecture that leverages the adjacency matrix as an attention mask. The proposed approach incorporates innovative augmentations, including Dilated Sliding Windows and Global Attention, to extend receptive fields without sacrificing computational efficiency. Through extensive experimentation, we evaluate model size, adjacency matrix augmentations, positional encoding and $K$-hop configurations using challenging 3D computational fluid dynamics (CFD) datasets. We also train over 60 models to find a scaling law between training FLOPs and parameters. The introduced models demonstrate remarkable scalability, performing on meshes with up to 300k nodes and 3 million edges. Notably, the smallest model achieves parity with MeshGraphNet while being $7\times$ faster and $6\times$ smaller. The largest model surpasses the previous state-of-the-art by $38.8$\% on average and outperforms MeshGraphNet by $52$\% on the all-rollout RMSE, while having a similar training speed. Code and datasets are available at https://github.com/DonsetPG/graph-physics.</p></details> |  |
| **[Beyond Blur: A Fluid Perspective on Generative Diffusion Models](http://arxiv.org/abs/2506.16827v2)** | 2025-08-23 | <details><summary>Show</summary><p>We propose a novel PDE-driven corruption process for generative image synthesis based on advection-diffusion processes which generalizes existing PDE-based approaches. Our forward pass formulates image corruption via a physically motivated PDE that couples directional advection with isotropic diffusion and Gaussian noise, controlled by dimensionless numbers (Peclet, Fourier). We implement this PDE numerically through a GPU-accelerated custom Lattice Boltzmann solver for fast evaluation. To induce realistic turbulence, we generate stochastic velocity fields that introduce coherent motion and capture multi-scale mixing. In the generative process, a neural network learns to reverse the advection-diffusion operator thus constituting a novel generative model. We discuss how previous methods emerge as specific cases of our operator, demonstrating that our framework generalizes prior PDE-based corruption techniques. We illustrate how advection improves the diversity and quality of the generated images while keeping the overall color palette unaffected. This work bridges fluid dynamics, dimensionless PDE theory, and deep generative modeling, offering a fresh perspective on physically informed image corruption processes for diffusion-based synthesis.</p></details> | <details><summary>ICCV ...</summary><p>ICCV 2025 main conference, 8 pages paper, 20 pages appendix, 24 figures, supplementary pseudocode in appendix, https://iccv.thecvf.com/virtual/2025/poster/1176</p></details> |
| **[The compressible Neural Particle Method for Simulating Compressible Viscous Fluid Flows](http://arxiv.org/abs/2508.16916v1)** | 2025-08-23 | <details><summary>Show</summary><p>Particle methods play an important role in computational fluid dynamics, but they are among the most difficult to implement and solve. The most common method is smoothed particle hydrodynamics, which is suitable for problem settings that involve large deformations, such as tsunamis and dam breaking. However, the calculation can become unstable depending on the distribution of particles. In contrast, the neural particle method has high computational stability for various particle distributions is a machine learning method that approximates velocity and pressure in a spatial domain using neural networks. The neural particle method has been extended to viscous flows, but until now it has been limited to incompressible flows. In this paper, we propose the compressible neural particle method, which is a new feed-forward neural network-based method that extends the original neural particle method to model compressible viscous fluid flows. The proposed method uses neural networks to calculate the velocity and pressure of fluid particles at the next time step, and the Tait equation to calculate the density to handle the compressibility. The loss function is composed of the governing equations of compressible flow and the boundary conditions, which are free surface and solid boundary conditions. We demonstrate that the proposed method can accurately solve the compressible viscous fluid flow, a problem that was difficult to solve with the smoothed particle hydrodynamics method, by applying it to a dam breaking problem.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 5 figures, submitted to PASJ</p></details> |
| **[OpenLB-UQ: An Uncertainty Quantification Framework for Incompressible Fluid Flow Simulations](http://arxiv.org/abs/2508.13867v1)** | 2025-08-19 | <details><summary>Show</summary><p>Uncertainty quantification (UQ) is crucial in computational fluid dynamics to assess the reliability and robustness of simulations, given the uncertainties in input parameters. OpenLB is an open-source lattice Boltzmann method library designed for efficient and extensible simulations of complex fluid dynamics on high-performance computers. In this work, we leverage the efficiency of OpenLB for large-scale flow sampling with a dedicated and integrated UQ module. To this end, we focus on non-intrusive stochastic collocation methods based on generalized polynomial chaos and Monte Carlo sampling. The OpenLB-UQ framework is extensively validated in convergence tests with respect to statistical metrics and sample efficiency using selected benchmark cases, including two-dimensional Taylor--Green vortex flows with up to four-dimensional uncertainty and a flow past a cylinder. Our results confirm the expected convergence rates and show promising scalability, demonstrating robust statistical accuracy as well as computational efficiency. OpenLB-UQ enhances the capability of the OpenLB library, offering researchers a scalable framework for UQ in incompressible fluid flow simulations and beyond.</p></details> |  |
| **[Fluid Dynamics and Domain Reconstruction from Noisy Flow Images Using Physics-Informed Neural Networks and Quasi-Conformal Mapping](http://arxiv.org/abs/2508.11216v1)** | 2025-08-15 | <details><summary>Show</summary><p>Blood flow imaging provides important information for hemodynamic behavior within the vascular system and plays an essential role in medical diagnosis and treatment planning. However, obtaining high-quality flow images remains a significant challenge. In this work, we address the problem of denoising flow images that may suffer from artifacts due to short acquisition times or device-induced errors. We formulate this task as an optimization problem, where the objective is to minimize the discrepancy between the modeled velocity field, constrained to satisfy the Navier-Stokes equations, and the observed noisy velocity data. To solve this problem, we decompose it into two subproblems: a fluid subproblem and a geometry subproblem. The fluid subproblem leverages a Physics-Informed Neural Network to reconstruct the velocity field from noisy observations, assuming a fixed domain. The geometry subproblem aims to infer the underlying flow region by optimizing a quasi-conformal mapping that deforms a reference domain. These two subproblems are solved in an alternating Gauss-Seidel fashion, iteratively refining both the velocity field and the domain. Upon convergence, the framework yields a high-quality reconstruction of the flow image. We validate the proposed method through experiments on synthetic flow data in a converging channel geometry under varying levels of Gaussian noise, and on real-like flow data in an aortic geometry with signal-dependent noise. The results demonstrate the effectiveness and robustness of the approach. Additionally, ablation studies are conducted to assess the influence of key hyperparameters.</p></details> |  |
| **[Interactive AI and Human Behavior: Challenges and Pathways for AI Governance](http://arxiv.org/abs/2508.16608v1)** | 2025-08-12 | <details><summary>Show</summary><p>As Generative AI systems increasingly engage in long-term, personal, and relational interactions, human-AI engagements are becoming significantly complex, making them more challenging to understand and govern. These Interactive AI systems adapt to users over time, build ongoing relationships, and even can take proactive actions on behalf of users. This new paradigm requires us to rethink how such human-AI interactions can be studied effectively to inform governance and policy development. In this paper, we draw on insights from a collaborative interdisciplinary workshop with policymakers, behavioral scientists, Human-Computer Interaction researchers, and civil society practitioners, to identify challenges and methodological opportunities arising within new forms of human-AI interactions. Based on these insights, we discuss an outcome-focused regulatory approach that integrates behavioral insights to address both the risks and benefits of emerging human-AI relationships. In particular, we emphasize the need for new methods to study the fluid, dynamic, and context-dependent nature of these interactions. We provide practical recommendations for developing human-centric AI governance, informed by behavioral insights, that can respond to the complexities of Interactive AI systems.</p></details> | <details><summary>In pr...</summary><p>In proceedings of AAAI/ACM Conference AIES 2025</p></details> |
| **[OmniFluids: Physics Pre-trained Modeling of Fluid Dynamics](http://arxiv.org/abs/2506.10862v2)** | 2025-08-09 | <details><summary>Show</summary><p>Computational fluid dynamics (CFD) drives progress in numerous scientific and engineering fields, yet high-fidelity simulations remain computationally prohibitive. While machine learning approaches offer computing acceleration, they typically specialize in single physical systems or require extensive training data, hindering their applicability in highly nonlinear and 3D flow scenarios. To overcome these limitations, we propose OmniFluids, a pure physics pre-trained model that captures fundamental fluid dynamics laws and adapts efficiently to diverse downstream tasks with minimal data. We develop a training framework combining physics-only pre-training, coarse-grid operator distillation, and few-shot fine-tuning. This enables OmniFluids to retain broad physics knowledge while delivering fast and accurate predictions. Architecturally, OmniFluids integrates a mixture of operators, a multi-frame decoder, and factorized Fourier layers, seamlessly incorporating physics-based supervision while allowing efficient and scalable modeling of diverse tasks. Extensive tests on a broad range of 2D and 3D benchmarks show that OmniFluids outperforms state-of-the-art AI-driven methods in terms of flow field prediction and turbulence statistics. It delivers 10--100$\times$ speedups over traditional solvers while maintaining a comparable accuracy and accurately identifies unknown physical parameters from sparse, noisy data. This work demonstrates the potential of training a unified CFD solver exclusively from physics knowledge, offering a new approach for efficient and generalizable modeling across complex fluid systems.</p></details> |  |
| **[Diffeomorphic Neural Operator Learning](http://arxiv.org/abs/2508.06690v1)** | 2025-08-08 | <details><summary>Show</summary><p>We present an operator learning approach for a class of evolution operators using a composition of a learned lift into the space of diffeomorphisms of the domain and the group action on the field space. In turn, this transforms the semigroup structure of the evolution operator into a corresponding group structure allowing time stepping be performed through composition on the space of diffeomorphisms rather than in the field space directly. This results in a number of structure-preserving properties related to preserving a relabelling symmetry of the dynamics as a hard constraint. We study the resolution properties of our approach, along with its connection to the techniques of diffeomorphic image registration. Numerical experiments on forecasting turbulent fluid dynamics are provided, demonstrating its conservative properties, non-diffusivity, and ability to capture anticipated statistical scaling relations at sub-grid scales. Our method provides an example of geometric operator learning and indicates a clear performance benefit from leveraging a priori known infinite-dimensional geometric structure.</p></details> |  |
| **[Performance measurements of modern Fortran MPI applications with Score-P](http://arxiv.org/abs/2508.16592v1)** | 2025-08-08 | <details><summary>Show</summary><p>Version 3.0 of the Message-Passing Interface (MPI) standard, released in 2012, introduced a new set of language bindings for Fortran 2008. By making use of modern language features and the enhanced interoperability with C, there was finally a type safe and standard conforming method to call MPI from Fortran. This highly recommended use mpi_f08 language binding has since then been widely adopted among developers of modern Fortran applications. However, tool support for the F08 bindings is still lacking almost a decade later, forcing users to recede to the less safe and convenient interfaces. Full support for the F08 bindings was added to the performance measurement infrastructure Score-P by implementing MPI wrappers in Fortran. Wrappers cover the latest MPI standard version 4.1 in its entirety, matching the features of the C wrappers. By implementing the wrappers in modern Fortran, we can provide full support for MPI procedures passing attributes, info objects, or callbacks. The implementation is regularly tested under the MPICH test suite. The new F08 wrappers were already used by two fluid dynamics simulation codes -- Neko, a spectral finite-element code derived from Nek5000, and EPIC (Elliptical Parcel-In-Cell) -- to successfully generate performance measurements. In this work, we additionally present our design considerations and sketch out the implementation, discussing the challenges we faced in the process. The key component of the implementation is a code generator that produces approximately 50k lines of MPI wrapper code to be used by Score-P, relying on the Python pympistandard module to provide programmatic access to the extracted data from the MPI standard.</p></details> |  |
| **[Monolithic Multi-level Overlapping Schwarz Solvers for Fluid Problems](http://arxiv.org/abs/2508.04356v2)** | 2025-08-08 | <details><summary>Show</summary><p>Additive overlapping Schwarz Methods are iterative methods of the domain decomposition type for the solution of partial differential equations. Numerical and parallel scalability of these methods can be achieved by adding coarse levels. A successful coarse space, inspired by iterative substructuring, is the generalized Dryja-Smith-Widlund (GDSW) space. In https://doi.org/10.1137/18M1184047, based on the GDSW approach, two-level monolithic overlapping Schwarz preconditioners for saddle point problems were introduced. We present parallel results up to 32768 MPI ranks for the solution of incompressible fluid problems for a Poiseuille flow example on the unit cube and a complex extrusion die geometry using a two- and a three-level monolithic overlapping Schwarz preconditioner. These results are achieved through the combination of the additive overlapping Schwarz solvers implemented in the Fast and Robust Overlapping Schwarz (FROSch) library https://doi.org/10.1007/978-3-030-56750-7_19, which is part of the Trilinos package ShyLU https://doi.org/10.1109/IPDPS.2012.64, and the FEATFLOW library http://www.featflow.de using a scalable interface for the efficient coupling of the two libraries. This work is part of the project StroemungsRaum - Novel Exascale-Architectures with Heterogeneous Hardware Components for Computational Fluid Dynamics Simulations, funded by the German Bundesministerium fur Forschung, Technologie und Raumfahrt BMFTR (formerly BMBF) as part of the program on New Methods and Technologies for Exascale Computing (SCALEXA).</p></details> | <details><summary>GAMM9...</summary><p>GAMM95; fixed typo in metadata</p></details> |
| **[Optimal Linear Baseline Models for Scientific Machine Learning](http://arxiv.org/abs/2508.05831v1)** | 2025-08-07 | <details><summary>Show</summary><p>Across scientific domains, a fundamental challenge is to characterize and compute the mappings from underlying physical processes to observed signals and measurements. While nonlinear neural networks have achieved considerable success, they remain theoretically opaque, which hinders adoption in contexts where interpretability is paramount. In contrast, linear neural networks serve as a simple yet effective foundation for gaining insight into these complex relationships. In this work, we develop a unified theoretical framework for analyzing linear encoder-decoder architectures through the lens of Bayes risk minimization for solving data-driven scientific machine learning problems. We derive closed-form, rank-constrained linear and affine linear optimal mappings for forward modeling and inverse recovery tasks. Our results generalize existing formulations by accommodating rank-deficiencies in data, forward operators, and measurement processes. We validate our theoretical results by conducting numerical experiments on datasets from simple biomedical imaging, financial factor analysis, and simulations involving nonlinear fluid dynamics via the shallow water equations. This work provides a robust baseline for understanding and benchmarking learned neural network models for scientific machine learning problems.</p></details> | <details><summary>40 pa...</summary><p>40 pages, 10 Figures, 9 Tables</p></details> |
| **[Data-driven control of a magnetohydrodynamic flow](http://arxiv.org/abs/2507.12479v2)** | 2025-08-07 | <details><summary>Show</summary><p>We demonstrate the feedback control of a weakly conducting magnetohydrodynamic (MHD) flow via Lorentz forces generated by externally applied electric and magnetic fields. Specifically, we steer the flow of an electrolyte toward prescribed velocity or vorticity patterns using arrays of electrodes and electromagnets positioned around and beneath a fluid reservoir, with feedback provided by planar particle image velocimetry (PIV). Control is implemented using a model predictive control (MPC) framework, in which control signals are computed by minimizing a cost function over the predicted evolution of the flow. The predictor is constructed entirely from data using Koopman operator theory, which enables a linear representation of the underlying nonlinear fluid dynamics. This linearity allows the MPC problem to be solved by alternating between two small and efficiently solvable convex quadratic programs (QPs): one for the electrodes and one for the electromagnets. The resulting controller runs in a closed loop on a standard laptop, enabling real-time control of the flow. We demonstrate the functionality of the approach through experiments in which the flow is shaped to match a range of reference velocity fields and a time-varying vorticity field.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 7 figures; name changed, added references, polished language, expanded appendix</p></details> |
| **[Fully implicit timestepping methods for the rotating shallow water equations](http://arxiv.org/abs/2508.02358v1)** | 2025-08-04 | <details><summary>Show</summary><p>Fully implicit timestepping methods have several potential advantages for atmosphere/ocean simulation. First, being unconditionally stable, they degrade more gracefully as the Courant number increases, typically requiring more solver iterations rather than suddenly blowing up. Second, particular choices of implicit timestepping methods can extend energy conservation properties of spatial discretisations to the fully discrete method. Third, these methods avoid issues related to splitting errors that can occur in some situations, and avoid the complexities of splitting methods. Fully implicit timestepping methods have had limited application in geophysical fluid dynamics due to challenges of finding suitable iterative solvers, since the coupled treatment of advection prevents the standard elimination techniques. However, overlapping Additive Schwarz methods, provide a robust, scalable iterative approach for solving the monolithic coupled system for all fields and Runge-Kutta stages. In this study we investigate this approach applied to the rotating shallow water equations, facilitated by the Irksome package which provides automated code generation for implicit Runge-Kutta methods. We compare various schemes in terms of accuracy and efficiency using an implicit/explicit splitting method, namely the ARK2 scheme of Giraldo et al (2013), as a benchmark. This provides an initial look at whether implicit Runge-Kutta methods can be viable for atmosphere and ocean simulation.</p></details> |  |
| **[Insect-Wing Structured Microfluidic System for Reservoir Computing](http://arxiv.org/abs/2508.10915v1)** | 2025-08-01 | <details><summary>Show</summary><p>As the demand for more efficient and adaptive computing grows, nature-inspired architectures offer promising alternatives to conventional electronic designs. Microfluidic platforms, drawing on biological forms and fluid dynamics, present a compelling foundation for low-power, high-resilience computing in environments where electronics are unsuitable. This study explores a hybrid reservoir computing system based on a dragonfly-wing inspired microfluidic chip, which encodes temporal input patterns as fluid interactions within the micro channel network. The system operates with three dye-based inlet channels and three camera-monitored detection areas, transforming discrete spatial patterns into dynamic color output signals. These reservoir output signals are then modified and passed to a simple and trainable readout layer for pattern classification. Using a combination of raw reservoir outputs and synthetically generated outputs, we evaluated system performance, system clarity, and data efficiency. The results demonstrate consistent classification accuracies up to $91\%$, even with coarse resolution and limited training data, highlighting the viability of the microfluidic reservoir computing.</p></details> |  |
| **[Adaptive Mesh Refinement for Two-Phase Viscoelastic Fluid Mixture Models](http://arxiv.org/abs/2409.19974v3)** | 2025-08-01 | <details><summary>Show</summary><p>Multiphase flows are an important class of fluid flow and their study facilitates the development of diverse applications in industrial, natural, and biomedical systems. We consider a model that uses a continuum description of both phases in which separate momentum equations are used for each phase along with a co-incompressibility condition on the velocity fields. The resulting system of equations poses numerical challenges due to the presence of multiple non-linear terms and the co-incompressibility condition, and the resulting fluid dynamics motivate the development of an adaptive mesh refinement (AMR) technique to accurately capture regions of high stresses and large material gradients while keeping computational costs low. We present an accurate, robust, and efficient computational method for simulating multiphase mixtures on adaptive grids, and utilize a multigrid solver to precondition the saddle-point system. We demonstrate that the AMR discretization asymptotically approaches second order accuracy in $L^1$, $L^2$ and $L^\infty$ norms. The solver can accurately resolve sharp gradients in the solution and, with the multigrid preconditioning strategy introduced herein, the linear solver iterations are independent of grid spacing. Our AMR solver offers a major cost savings benefit, providing up to ten fold speedup over a uniform grid in the numerical experiments presented here, with greater speedup possible depending on the problem set-up.</p></details> |  |
| **[A Multi-physics Model of Flow from Coronary Angiography: Insights to Microvascular Function](http://arxiv.org/abs/2412.04798v2)** | 2025-07-31 | <details><summary>Show</summary><p>Coronary Microvascular Dysfunction (CMD) is characterized by impaired vasodilation and can lead to insufficient blood flow to the myocardium during stress or exertion, affecting millions of people globally. Despite their diagnostic value, invasive, wire-based diagnosis techniques of CMD, such as index of microcirculatory resistance (IMR) and coronary flow reserve (CFR), are underutilized due to their complexity and inconsistency. Coronary angiography, one of the most commonly used imaging modalities, offers valuable flow information that assists in diagnosing CMD. However, this information is not fully understood or utilized in current clinical practice. In this study, a 3D-0D coupled multi-physics computational fluid dynamics (CFD) model was developed and calibrated to simulate and study the process of contrast injection and washout during clinical angiography. A contrast intensity profile (CIP) was introduced to describe the dynamics of coronary angiography data. Additionally, sensitivity studies were conducted to evaluate the influence of various coronary lumped parameter model (LPM) parameters on the shapes of CIPs. The results demonstrate that the multi-physics model can be effectively calibrated to produce physiologically meaningful hemodynamic results. Sensitivity studies reveal that resistance has a greater impact on the rising and falling slopes of CIP than capacitance, with higher resistance amplifying this effect. The model and results are presented here. These results are potentially transformative, as they provide a tool for interpreting angiographic data and ultimately extracting information concerning coronary microcirculation.</p></details> | 29 pages, 14 figures |

## Model Reduction
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Parameter Robustness in Data-Driven Estimation of Dynamical Systems](http://arxiv.org/abs/2509.06534v1)** | 2025-09-08 | <details><summary>Show</summary><p>We study the robustness of system estimation to parametric perturbations in system dynamics and initial conditions. We define the problem of sensitivity-based parametric uncertainty quantification in dynamical system estimation. The main contribution of this paper is the development of a novel robustness metric for estimation of parametrized linear dynamical systems with and without control actions. For the computation of this metric, we delineate the uncertainty contributions arising from control actions, system dynamics, and initial conditions. Furthermore, to validate our theoretical findings, we establish connections between these new results and the existing literature on the robustness of model reduction. This work provides guidance for selecting estimation methods based on tolerable levels of parametric uncertainty and paves the way for new cost functions in data-driven estimation that reward sensitivity to a desired subset of parameters while penalizing others.</p></details> | <details><summary>Submi...</summary><p>Submitted for publication in the IEEE Conference on Decision and Control (CDC) 2025</p></details> |
| **[Fractional differential equations: non-constant coefficients, simulation and model reduction](http://arxiv.org/abs/2509.02465v1)** | 2025-09-02 | <details><summary>Show</summary><p>We consider boundary value problems with Riemann-Liouville fractional derivatives of order $s\in (1, 2)$ with non-constant diffusion and reaction coefficients. A variational formulation is derived and analyzed leading to the well-posedness of the continuous problem and its Finite Element discretization. Then, the Reduced Basis Method through a greedy algorithm for parametric diffusion and reaction coefficients is analyzed. Its convergence properties, and in particular the decay of the Kolmogorov $n$-width, are seen to depend on the fractional order $s$. Finally, numerical results confirming our findings are presented.</p></details> |  |
| **[A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients](http://arxiv.org/abs/2504.18054v2)** | 2025-09-01 | <details><summary>Show</summary><p>Achieving strongly symmetric stress approximations for linear elasticity problems in high-contrast media poses a significant computational challenge. Conventional methods often struggle with prohibitively high computational costs due to excessive degrees of freedom, limiting their practical applicability. To overcome this challenge, we introduce an efficient multiscale model reduction method and a computationally inexpensive coarse-grid simulation technique for linear elasticity equations in highly heterogeneous, high-contrast media. We first utilize a stable stress-displacement mixed finite element method to discretize the linear elasticity problem and then present the construction of multiscale basis functions for the displacement and the stress. The mixed formulation offers several advantages such as direct stress computation without post-processing, local momentum conservation (ensuring physical consistency), and robustness against locking effects, even for nearly incompressible materials. Theoretical analysis confirms that our method is inf-sup stable and locking-free, with first-order convergence relative to the coarse mesh size. Notably, the convergence remains independent of contrast ratios as enlarging oversampling regions. Numerical experiments validate the method's effectiveness, demonstrating its superior performance even under extreme contrast conditions.</p></details> |  |
| **[Machine-precision energy conservative quadrature hyperreduction of Lagrangian hydrodynamics](http://arxiv.org/abs/2508.21279v1)** | 2025-08-29 | <details><summary>Show</summary><p>We present an energy conservative, quadrature based model reduction framework for the compressible Euler equations of Lagrangian hydrodynamics. Building on a high order finite element discretization of the governing equations, we develop a projection based reduced model using data driven reduced basis functions and hyperreduction via the empirical quadrature procedure (EQP). We introduce a strongly energy conservative variant of EQP that enforces exact discrete total energy conservation during the hyperreduction process. Numerical experiments for four benchmark problems -- Sedov blast, Gresho vortex, triple point and Taylor-Green vortex -- demonstrate that the numerical implementation of our proposed method conserves total energy to near machine precision while maintaining accuracy comparable to the basic EQP formulation. These results establish the energy conservative EQP (CEQP) method as an effective structure preserving hyperreduction strategy for the reduced simulation of nonlinear Lagrangian hydrodynamics.</p></details> | 24 pages, 1 figure |
| **[Possible Principles for Aligned Structure Learning Agents](http://arxiv.org/abs/2410.00258v3)** | 2025-08-27 | <details><summary>Show</summary><p>This paper offers a roadmap for the development of scalable aligned artificial intelligence (AI) from first principle descriptions of natural intelligence. In brief, a possible path toward scalable aligned AI rests upon enabling artificial agents to learn a good model of the world that includes a good model of our preferences. For this, the main objective is creating agents that learn to represent the world and other agents' world models; a problem that falls under structure learning (a.k.a. causal representation learning or model discovery). We expose the structure learning and alignment problems with this goal in mind, as well as principles to guide us forward, synthesizing various ideas across mathematics, statistics, and cognitive science. 1) We discuss the essential role of core knowledge, information geometry and model reduction in structure learning, and suggest core structural modules to learn a wide range of naturalistic worlds. 2) We outline a way toward aligned agents through structure learning and theory of mind. As an illustrative example, we mathematically sketch Asimov's Laws of Robotics, which prescribe agents to act cautiously to minimize the ill-being of other agents. We supplement this example by proposing refined approaches to alignment. These observations may guide the development of artificial intelligence in helping to scale existing -- or design new -- aligned structure learning systems.</p></details> | <details><summary>24 pa...</summary><p>24 pages of content, 33 with references; accepted version</p></details> |
| **[Multi-field decomposed hyper-reduced order modeling of damage-plasticity simulations](http://arxiv.org/abs/2508.19957v1)** | 2025-08-27 | <details><summary>Show</summary><p>This paper presents a multi-field decomposed approach for hyper-reduced order modeling to overcome the limitations of traditional model reduction techniques for gradient-extended damage-plasticity simulations. The discrete empirical interpolation method (DEIM) and the energy-conserving sampling and weighting method (ECSW) are extended to account for the multi-field nature of the problem. Both methods yield stable reduced order simulations, while significantly reducing the computational cost compared to full-order simulations. Two numerical examples are presented to demonstrate the performance and limitations of the proposed approaches. The decomposed ECSW method has overall higher accuracy and lower computational cost than the decomposed DEIM method.</p></details> |  |
| **[Constraint Matters: Multi-Modal Representation for Reducing Mixed-Integer Linear programming](http://arxiv.org/abs/2508.18742v1)** | 2025-08-26 | <details><summary>Show</summary><p>Model reduction, which aims to learn a simpler model of the original mixed integer linear programming (MILP), can solve large-scale MILP problems much faster. Most existing model reduction methods are based on variable reduction, which predicts a solution value for a subset of variables. From a dual perspective, constraint reduction that transforms a subset of inequality constraints into equalities can also reduce the complexity of MILP, but has been largely ignored. Therefore, this paper proposes a novel constraint-based model reduction approach for the MILP. Constraint-based MILP reduction has two challenges: 1) which inequality constraints are critical such that reducing them can accelerate MILP solving while preserving feasibility, and 2) how to predict these critical constraints efficiently. To identify critical constraints, we first label these tight-constraints at the optimal solution as potential critical constraints and design a heuristic rule to select a subset of critical tight-constraints. To learn the critical tight-constraints, we propose a multi-modal representation technique that leverages information from both instance-level and abstract-level MILP formulations. The experimental results show that, compared to the state-of-the-art methods, our method improves the quality of the solution by over 50\% and reduces the computation time by 17.47\%.</p></details> |  |
| **[Generalizations of data-driven balancing: What to sample for different balancing-based reduced models](http://arxiv.org/abs/2312.12561v2)** | 2025-08-25 | <details><summary>Show</summary><p>The quadrature-based balanced truncation (QuadBT) framework of arXiv:2104.01006 is a non-intrusive reformulation of balanced truncation (BT), a classical projection-based model-order reduction technique for linear systems. QuadBT is non-intrusive in the sense that it builds approximate balanced truncation reduced-order models entirely from system response data, e.g., transfer function measurements, without the need to reference an explicit state-space realization of the underlying full-order model. In this work, we generalize the QuadBT framework to other types of balanced truncation model reduction. Namely, we show what transfer function data are required to compute data-driven reduced models by balanced stochastic truncation, positive-real balanced truncation, and bounded-real balanced truncation. In each case, these data are evaluations of particular spectral factors associated with the system of interest. These results lay the theoretical foundation for data-driven reformulations of the aforementioned BT variants. Although it is not yet clear how to compute or obtain these spectral factor data in a practical real-world setting, examples using synthetic (numerically evaluated) transfer function data are included to validate the data-based reduced models.</p></details> | 16 pages, 3 figures |
| **[Reduced basis solvers for unfitted methods on parameterized domains](http://arxiv.org/abs/2508.15320v2)** | 2025-08-24 | <details><summary>Show</summary><p>In this paper, we present a unified framework for reduced basis approximations of parametrized partial differential equations defined on parameter-dependent domains. Our approach combines unfitted finite element methods with both classical and tensor-based reduced basis techniques -- particularly the tensor-train reduced basis method -- to enable efficient and accurate model reduction on general geometries. To address the challenge of reconciling geometric variability with fixed-dimensional snapshot representations, we adopt a deformation-based strategy that maps a reference configuration to each parameterized domain. Furthermore, we introduce a localization procedure to construct dictionaries of reduced subspaces and hyper-reduction approximations, which are obtained via matrix discrete empirical interpolation in our work. We extend the proposed framework to saddle-point problems by adapting the supremizer enrichment strategy to unfitted methods and deformed configurations, demonstrating that the supremizer operator can be defined on the reference configuration without loss of stability. Numerical experiments on two- and three-dimensional problems -- including Poisson, linear elasticity, incompressible Stokes and Navier-Stokes equations -- demonstrate the flexibility, accuracy and efficiency of the proposed methodology.</p></details> | <details><summary>22 pa...</summary><p>22 pages, 7 figures, 5 tables</p></details> |
| **[First and Second Order Optimal $\mathcal{H}_2$ Model Reduction for Linear Continuous-Time Systems](http://arxiv.org/abs/2508.17503v1)** | 2025-08-24 | <details><summary>Show</summary><p>In this paper, we investigate the optimal $\mathcal{H}_2$ model reduction problem for single-input single-output (SISO) continuous-time linear time-invariant (LTI) systems. A semi-definite relaxation (SDR) approach is proposed to determine globally optimal interpolation points, providing an effective way to compute the reduced-order models via Krylov projection-based methods. In contrast to iterative approaches, we use the controllability Gramian and the moment-matching conditions to recast the model reduction problem as a convex optimization by introducing an upper bound $\gamma$ to minimize the $\mathcal{H}_2$ norm of the model reduction error system. We also prove that the relaxation is exact for first order reduced models and demonstrate, through examples, that it is exact for second order reduced models. We compare the performance of our proposed method with other iterative approaches and shift-selection methods on examples. Importantly, our approach also provides a means to verify the global optimality of known locally convergent methods.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, CDC conference</p></details> |
| **[Stabilization of Parabolic Time-Varying PDEs using Certified Reduced-Order Receding Horizon Control](http://arxiv.org/abs/2508.16801v1)** | 2025-08-22 | <details><summary>Show</summary><p>We address the stabilization of linear, time-varying parabolic PDEs using finite-dimensional receding horizon controls (RHCs) derived from reduced-order models (ROMs). We first prove exponential stability and suboptimality of the continuous-time full-order model (FOM) RHC scheme in Hilbert spaces. A Galerkin model reduction is then introduced, along with a rigorous a posteriori error analysis for the associated finite-horizon optimal control problems. This results in a ROM-based RHC algorithm that adaptively constructs reduced-order controls, ensuring exponential stability of the FOM closed-loop state and providing computable performance bounds with respect to the infinite-horizon FOM control problem. Numerical experiments with a non-smooth cost functional involving the squared l1-norm confirm the methods effectiveness, even for exponentially unstable systems.</p></details> |  |
| **[Stokes-Brinkman-Darcy models for fluid-porous systems: derivation, analysis and validation](http://arxiv.org/abs/2404.16577v2)** | 2025-08-19 | <details><summary>Show</summary><p>Flow interaction between a plain-fluid region in contact with a porous layer attracted significant attention from modelling and analysis sides due to numerous applications in biology, environment and industry. In the most widely used coupled model, fluid flow is described by the Stokes equations in the free-flow domain and Darcy's law in the porous medium, and complemented by the appropriate interface conditions. However, traditional coupling concepts are restricted, with a few exceptions, to one-dimensional flows parallel to the fluid-porous interface. In this work, we use an alternative approach to model interaction between the plain-fluid domain and porous medium by considering a transition zone, and propose the full- and hybrid-dimensional Stokes-Brinkman-Darcy models. In the first case, the equi-dimensional Brinkman equations are considered in the transition region, and the appropriate interface conditions are set on the top and bottom of the transition zone. In the latter case, we perform a dimensional model reduction by averaging the Brinkman equations in the normal direction and using the proposed transmission conditions. The well-posedness of both coupled problems is proved, and some numerical simulations are carried out in order to validate the concepts.</p></details> | <details><summary>23 pa...</summary><p>23 pages, 8 figures, Published in Applied Mathematics and Computation, 2025, DOI:/10.1016/j.amc.2025.129687</p></details> |
| **[Power-Series Approach to Moment-Matching-Based Model Reduction of MIMO Polynomial Nonlinear Systems](http://arxiv.org/abs/2508.13595v1)** | 2025-08-19 | <details><summary>Show</summary><p>The model reduction problem for high-order multi-input, multi-output (MIMO) polynomial nonlinear systems based on moment matching is addressed. The technique of power-series decomposition is exploited: this decomposes the solution of the nonlinear PDE characterizing the center manifold into the solutions of a series of recursively defined Sylvester equations. This approach allows yielding nonlinear reduced-order models in very much the same way as in the linear case (e.g. analytically). Algorithms are proposed for obtaining the order and the parameters of the reduced-order models with precision of degree $\kappa$. The approach also provides new insights into the nonlinear moment matching problem: first, a lower bound for the order of the reduced-order model is obtained, which, in the MIMO case, can be strictly less than the number of matched moments; second, it is revealed that the lower bound is affected by the ratio of the number of the input and output channels; third, it is shown that under mild conditions, a nonlinear reduced-order model can always be constructed with either a linear state equation or a linear output equation.</p></details> |  |
| **[Sum-of-Gaussians tensor neural networks for high-dimensional Schrödinger equation](http://arxiv.org/abs/2508.10454v1)** | 2025-08-14 | <details><summary>Show</summary><p>We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor neural network (SOG-TNN) algorithm for solving the high-dimensional Schr\"odinger equation. The SOG-TNN utilizes a low-rank tensor product representation of the solution to overcome the curse of dimensionality associated with high-dimensional integration. To handle the Coulomb interaction, we introduce an SOG decomposition to approximate the interaction kernel such that it is dimensionally separable, leading to a tensor representation with rapid convergence. We further develop a range-splitting scheme that partitions the Gaussian terms into short-, long-, and mid-range components. They are treated with the asymptotic expansion, the low-rank Chebyshev expansion, and the model reduction with singular-value decomposition, respectively, significantly reducing the number of two-dimensional integrals in computing electron-electron interactions. The SOG decomposition well resolves the computational challenge due to the singularity of the Coulomb interaction, leading to an efficient algorithm for the high-dimensional problem under the TNN framework. Numerical results demonstrate the outstanding performance of the new method, revealing that the SOG-TNN is a promising way for tackling large and complex quantum systems.</p></details> | 22 pages, 6 figures |
| **[Weighted Proper Orthogonal Decomposition for High-Dimensional Optimization](http://arxiv.org/abs/2508.09084v1)** | 2025-08-12 | <details><summary>Show</summary><p>While proper orthogonal decomposition (POD) is widely used for model reduction, its standard form does not take into account any parametric model structure. Extensions to POD have been proposed to address this, but these either require large amounts of solution data, lack online adaptivity, or have limited approximation accuracy. We circumvent these limitations by instead assigning weights to the snapshot matrix columns, and updating these whenever the model is evaluated at a new point in the parameter space. We derive an a posteriori error bound that depends on these snapshot weights, show how these weights can be chosen to tighten the error bound, and present an algorithm to compute the corresponding reduced basis efficiently. We show how this weighted POD approach can be used to naturally generalize the calculation of reduced basis derivatives to situations with multidimensional parameter spaces and snapshots at multiple locations in the parameter space. Lastly, we cover how these approaches can be implemented within an optimization algorithm, without the need for an offline training phase. The proposed weighted POD methods with and without reduced basis derivatives are applied to a gradient-based shell thickness optimization problem with 105 design parameters and a time-dependent partial differential equation. The numerical solutions obtained for this problem attain errors that are several orders of magnitude smaller when using weighted POD than those computed with regular POD and Grassmann manifold interpolation, while having comparable wall times per query and requiring fewer high-dimensional model snapshots to reach an optimal solution.</p></details> | 26 pages, 7 figures |
| **[COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models](http://arxiv.org/abs/2508.08144v1)** | 2025-08-11 | <details><summary>Show</summary><p>The rapid growth of resource-constrained mobile platforms, including mobile robots, wearable systems, and Internet-of-Things devices, has increased the demand for computationally efficient neural network controllers (NNCs) that can operate within strict hardware limitations. While deep neural networks (DNNs) demonstrate superior performance in control applications, their substantial computational complexity and memory requirements present significant barriers to practical deployment on edge devices. This paper introduces a comprehensive model compression methodology that leverages component-aware structured pruning to determine the optimal pruning magnitude for each pruning group, ensuring a balance between compression and stability for NNC deployment. Our approach is rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC), a state-of-the-art model-based reinforcement learning algorithm, with a systematic integration of mathematical stability guarantee properties, specifically Lyapunov criteria. The key contribution of this work lies in providing a principled framework for determining the theoretical limits of model compression while preserving controller stability. Experimental validation demonstrates that our methodology successfully reduces model complexity while maintaining requisite control performance and stability characteristics. Furthermore, our approach establishes a quantitative boundary for safe compression ratios, enabling practitioners to systematically determine the maximum permissible model reduction before violating critical stability properties, thereby facilitating the confident deployment of compressed NNCs in resource-limited environments.</p></details> | <details><summary>Submi...</summary><p>Submitted in: The 2026 IEEE/SICE International Symposium on System Integration (SII 2026)</p></details> |
| **[Efficient data-driven regression for reduced-order modeling of spatial pattern formation](http://arxiv.org/abs/2508.06833v1)** | 2025-08-09 | <details><summary>Show</summary><p>We present an efficient data-driven regression approach for constructing reduced-order models (ROMs) of reaction-diffusion systems exhibiting pattern formation. The ROMs are learned non-intrusively from available training data of physically accurate numerical simulations. The method can be applied to general nonlinear systems through the use of polynomial model form, while not requiring knowledge of the underlying physical model, governing equations, or numerical solvers. The process of learning ROMs is posed as a low-cost least-squares problem in a reduced-order subspace identified via Proper Orthogonal Decomposition (POD). Numerical experiments on classical pattern-forming systems--including the Schnakenberg and Mimura--Tsujikawa models--demonstrate that higher-order surrogate models significantly improve prediction accuracy while maintaining low computational cost. The proposed method provides a flexible, non-intrusive model reduction framework, well suited for the analysis of complex spatio-temporal pattern formation phenomena.</p></details> |  |
| **[A unified framework for the analysis, numerical approximation and model reduction of linear operator equations, Part I: Well-posedness in space and time](http://arxiv.org/abs/2508.05407v1)** | 2025-08-07 | <details><summary>Show</summary><p>We present a unified framework to construct well-posed formulations for large classes of linear operator equations including elliptic, parabolic and hyperbolic partial differential equations. This general approach incorporates known weak variational formulations as well as novel space-time variational forms of the hyperbolic wave equation. The main concept is completion and extension of operators starting from the strong form of the problem. This paper lays the theoretical foundation for a unified approach towards numerical approximation methods and also model reduction of parameterized linear operator equations which will be the subject of the following parts.</p></details> | <details><summary>linea...</summary><p>linear operator equations, well-posedness, space-time variational methods</p></details> |
| **[State dimension reduction of recurrent equilibrium networks with contraction and robustness preservation](http://arxiv.org/abs/2508.02843v1)** | 2025-08-04 | <details><summary>Show</summary><p>Recurrent equilibrium networks (RENs) are effective for learning the dynamics of complex dynamical systems with certified contraction and robustness properties through unconstrained learning. While this opens the door to learning large-scale RENs, deploying such large-scale RENs in real-time applications on resource-limited devices remains challenging. Since a REN consists of a feedback interconnection of linear time-invariant (LTI) dynamics and static activation functions, this article proposes a projection-based approach to reduce the state dimension of the LTI component of a trained REN. One of the two projection matrices is dedicated to preserving contraction and robustness by leveraging the already-learned REN contraction certificate. The other projection matrix is iteratively updated to improve the accuracy of the reduced-order REN based on necessary $h_2$-optimality conditions for LTI model reduction. Numerical examples validate the approach, demonstrating significant state dimension reduction with limited accuracy loss while preserving contraction and robustness.</p></details> |  |
| **[Model reduction for fully nonlinear stochastic systems](http://arxiv.org/abs/2508.02263v1)** | 2025-08-04 | <details><summary>Show</summary><p>This paper presents a novel model order reduction framework tailored for fully nonlinear stochastic dynamics without lifting them to quadratic systems and without using linearization techniques. By directly leveraging structural properties of the nonlinearities -- such as local and one-sided Lipschitz continuity or one-sided linear growth conditions -- the approach defines generalized reachability and observability Gramians through Lyapunov-type differential operators. These Gramians enable projection-based reduction while preserving essential dynamics and stochastic characteristics. The paper provides sufficient conditions for the existence of these Gramians, including a Lyapunov-based mean square stability criterion, and derives explicit output error bounds for the reduced order models. Furthermore, the work introduces a balancing and truncation procedure for obtaining reduced systems and demonstrates how dominant subspaces can be identified from the spectrum of the Gramians. The theoretical findings are grounded in rigorous stochastic analysis, extending balanced truncation techniques to a broad class of nonlinear systems under stochastic excitation.</p></details> |  |
| **[Kernel-Based Sparse Additive Nonlinear Model Structure Detection through a Linearization Approach](http://arxiv.org/abs/2508.01453v1)** | 2025-08-02 | <details><summary>Show</summary><p>The choice of parameterization in Nonlinear (NL) system models greatly affects the quality of the estimated model. Overly complex models can be impractical and hard to interpret, necessitating data-driven methods for simpler and more accurate representations. In this paper, we propose a data-driven approach to simplify a class of continuous-time NL system models using linear approximations around varying operating points. Specifically, for sparse additive NL models, our method identifies the number of NL subterms and their corresponding input spaces. Under small-signal operation, we approximate the unknown NL system as a trajectory-scheduled Linear Parameter-Varying (LPV) system, with LPV coefficients representing the gradient of the NL function and indicating input sensitivity. Using this sensitivity measure, we determine the NL system's structure through LPV model reduction by identifying non-zero LPV coefficients and selecting scheduling parameters. We introduce two sparse estimators within a vector-valued Reproducing Kernel Hilbert Space (RKHS) framework to estimate the LPV coefficients while preserving their structural relationships. The structure of the sparse additive NL model is then determined by detecting non-zero elements in the gradient vector (LPV coefficients) and the Hessian matrix (Jacobian of the LPV coefficients). We propose two computationally tractable RKHS-based estimators for this purpose. The sparsified Hessian matrix reveals the NL model's structure, with numerical simulations confirming the approach's effectiveness.</p></details> |  |
| **[Low-dimensional observer design for stable linear systems by model reduction](http://arxiv.org/abs/2508.00609v1)** | 2025-08-01 | <details><summary>Show</summary><p>This paper presents a low-dimensional observer design for stable, single-input single-output, continuous-time linear time-invariant (LTI) systems. Leveraging the model reduction by moment matching technique, we approximate the system with a reduced-order model. Based on this reduced-order model, we design a low-dimensional observer that estimates the states of the original system. We show that this observer establishes exact asymptotic state reconstruction for a given class of inputs tied to the observer's dimension. Furthermore, we establish an exponential input-to-state stability property for generic inputs, ensuring a bounded estimation error. Numerical simulations confirm the effectiveness of the approach for a benchmark model reduction problem.</p></details> |  |
| **[Partial Floquet Transformation and Model Order Reduction of Linear Time-Periodic Systems](http://arxiv.org/abs/2508.00221v1)** | 2025-07-31 | <details><summary>Show</summary><p>Time-periodic dynamical systems occur commonly both in nature and as engineered systems. Large-scale linear time-periodic dynamical systems, for example, may arise through linearization of a nonlinear system about a given periodic solution (possibly as a consequence of a baseline periodic forcing) with subsequent spatial discretization. The potential need to simulate responses to a wide variety of input profiles (viewed as perturbations off a baseline periodic forcing) creates a potent incentive for effective model reduction strategies applicable to linear time-periodic (LTP) systems. Classical approaches that take into account the underlying time-periodic system structure often utilize the Floquet transform; however, computation of the Floquet transform is typically intractable for large order systems. In this paper, we develop the notion of a partial Floquet transformation connected to selected invariant subspaces of a time-varying differential operator associated with the LTP system. We modify and repurpose the Dominant Pole Algorithm of Rommes to identify effective invariant subspaces useful for model reduction. We discuss the construction of associated partial Floquet transformations and time-varying reduction bases with which to produce effective reduced-order LTP models and illustrate the process on a simple time-periodic system.</p></details> | 21 pages |
| **[Tensor-based reduction of linear parameter-varying state-space models](http://arxiv.org/abs/2507.23591v1)** | 2025-07-31 | <details><summary>Show</summary><p>The Linear Parameter-Varying (LPV) framework is a powerful tool for controlling nonlinear and complex systems, but the conversion of nonlinear models into LPV forms often results in high-dimensional and overly conservative LPV models. To be able to apply control strategies, there is often a need for model reduction in order to reduce computational needs. This paper presents the first systematic approach for the joint reduction of state order and scheduling signal dimension of LPV state space models. The existing methods typically address these reductions separately. By formulating a tensorial form of LPV models with an affine dependency on the scheduling variables, we leverage tensor decomposition to find the dominant components of state and scheduling subspaces. We extend the common Petrov-Galerkin projection approach to LPV framework by adding a scheduling projection. This extension enables the joint reduction. To find suitable subspaces for the extended Petrov-Galerkin projection, we have developed two different methods: tensor-based LPV moment matching, and an approach through Proper Orthogonal Decomposition. Advantages of the proposed methods are demonstrated on two different series-interconnected mass-spring-damper systems with nonlinear springs: one primarily used for comparison with other methods and a more elaborate higher-order model designed to assess scalability.</p></details> |  |
| **[Structure-Preserving Discretization and Model Reduction for Energy-Based Models](http://arxiv.org/abs/2507.21552v1)** | 2025-07-29 | <details><summary>Show</summary><p>We investigate discretization strategies for a recently introduced class of energy-based models. The model class encompasses classical port-Hamiltonian systems, generalized gradient flows, and certain systems with algebraic constraints. Our framework combines existing ideas from the literature and systematically addresses temporal discretization, spatial discretization, and model order reduction, ensuring that all resulting schemes are dissipation-preserving in the sense of a discrete dissipation inequality. For this, we use a Petrov-Galerkin ansatz together with appropriate projections. Numerical results for a nonlinear circuit model and the Cahn-Hilliard equation illustrate the effectiveness of the approach.</p></details> | 20 pages, 5 figures |
| **[PySHRED: A Python package for SHallow REcurrent Decoding for sparse sensing, model reduction and scientific discovery](http://arxiv.org/abs/2507.20954v1)** | 2025-07-28 | <details><summary>Show</summary><p>SHallow REcurrent Decoders (SHRED) provide a deep learning strategy for modeling high-dimensional dynamical systems and/or spatiotemporal data from dynamical system snapshot observations. PySHRED is a Python package that implements SHRED and several of its major extensions, including for robust sensing, reduced order modeling and physics discovery. In this paper, we introduce the version 1.0 release of PySHRED, which includes data preprocessors and a number of cutting-edge SHRED methods specifically designed to handle real-world data that may be noisy, multi-scale, parameterized, prohibitively high-dimensional, and strongly nonlinear. The package is easy to install, thoroughly-documented, supplemented with extensive code examples, and modularly-structured to support future additions. The entire codebase is released under the MIT license and is available at https://github.com/pyshred-dev/pyshred.</p></details> | 15 pages, 9 figures |
| **[Operator Inference Aware Quadratic Manifolds with Isotropic Reduced Coordinates for Nonintrusive Model Reduction](http://arxiv.org/abs/2507.20463v1)** | 2025-07-28 | <details><summary>Show</summary><p>Quadratic manifolds for nonintrusive reduced modeling are typically trained to minimize the reconstruction error on snapshot data, which means that the error of models fitted to the embedded data in downstream learning steps is ignored. In contrast, we propose a greedy training procedure that takes into account both the reconstruction error on the snapshot data and the prediction error of reduced models fitted to the data. Because our procedure learns quadratic manifolds with the objective of achieving accurate reduced models, it avoids oscillatory and other non-smooth embeddings that can hinder learning accurate reduced models. Numerical experiments on transport and turbulent flow problems show that quadratic manifolds trained with the proposed greedy approach lead to reduced models with up to two orders of magnitude higher accuracy than quadratic manifolds trained with respect to the reconstruction error alone.</p></details> | 23 pages, 8 figures |
| **[Symmetry-reduced model reduction of shift-equivariant systems via operator inference](http://arxiv.org/abs/2507.18780v1)** | 2025-07-24 | <details><summary>Show</summary><p>We consider data-driven reduced-order models of partial differential equations with shift equivariance. Shift-equivariant systems typically admit traveling solutions, and the main idea of our approach is to represent the solution in a traveling reference frame, in which it can be described by a relatively small number of basis functions. Existing methods for operator inference allow one to approximate a reduced-order model directly from data, without knowledge of the full-order dynamics. Our method adds additional terms to ensure that the reduced-order model not only approximates the spatially frozen profile of the solution, but also estimates the traveling speed as a function of that profile. We validate our approach using the Kuramoto-Sivashinsky equation, a one-dimensional partial differential equation that exhibits traveling solutions and spatiotemporal chaos. Results indicate that our method robustly captures traveling solutions, and exhibits improved numerical stability over the standard operator inference approach.</p></details> | <details><summary>30 pa...</summary><p>30 pages, 7 figures. Orally presented at the SIAM Conference on Applications of Dynamical Systems (SIAM DS25). Submitted to Advances in Computational Mathematics (ACOM)</p></details> |
| **[Exact Model Reduction for Continuous-Time Open Quantum Dynamics](http://arxiv.org/abs/2412.05102v3)** | 2025-07-23 | <details><summary>Show</summary><p>We consider finite-dimensional many-body quantum systems described by time-independent Hamiltonians and Markovian master equations, and present a systematic method for constructing smaller-dimensional, reduced models that exactly reproduce the time evolution of a set of initial conditions or observables of interest. Our approach exploits Krylov operator spaces and their extension to operator algebras, and may be used to obtain reduced linear models of minimal dimension, well-suited for simulation on classical computers, or reduced quantum models that preserve the structural constraints of physically admissible quantum dynamics, as required for simulation on quantum computers. Notably, we prove that the reduced quantum-dynamical generator is still in Lindblad form. By introducing a new type of observable-dependent symmetries, we show that our method provides a non-trivial generalization of techniques that leverage symmetries, unlocking new reduction opportunities. We quantitatively benchmark our method on paradigmatic open many-body systems of relevance to condensed-matter and quantum-information physics. In particular, we demonstrate how our reduced models can quantitatively describe decoherence dynamics in central-spin systems coupled to structured environments, magnetization transport in boundary-driven dissipative spin chains, and unwanted error dynamics on information encoded in a noiseless quantum code.</p></details> |  |
| **[Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies](http://arxiv.org/abs/2507.14901v1)** | 2025-07-20 | <details><summary>Show</summary><p>Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.</p></details> |  |
| **[Expansive Natural Neural Gradient Flows for Energy Minimization](http://arxiv.org/abs/2507.13475v1)** | 2025-07-17 | <details><summary>Show</summary><p>This paper develops expansive gradient dynamics in deep neural network-induced mapping spaces. Specifically, we generate tools and concepts for minimizing a class of energy functionals in an abstract Hilbert space setting covering a wide scope of applications such as PDEs-based inverse problems and supervised learning. The approach hinges on a Hilbert space metric in the full diffeomorphism mapping space, which could be viewed as a generalized Wasserstein-2 metric. We then study a projection gradient descent method within deep neural network parameterized sets. More importantly, we develop an adaptation and expanding strategy to step-by-step enlarge the deep neural network structures. In particular, the expansion mechanism aims to enhance the alignment of the neural manifold induced natural gradient direction as well as possible with the ideal Hilbert space gradient descent direction leveraging the fact that we can evaluate projections of the Hilbert space gradient. We demonstrate the efficacy of the proposed strategy for several simple model problems for energies arising in the context of supervised learning, model reduction, or inverse problems. In particular, we highlight the importance of assembling the neural flow matrix based on the inner product for the ambient Hilbert space. The actual algorithms are the simplest specifications of a broader spectrum based on a correspondingly wider discussion, postponing a detailed analysis to forthcoming work.</p></details> | 40 pages, 19 figures |
| **[Non-intrusive model reduction of advection-dominated hyperbolic problems using neural network shift augmented manifold transformation](http://arxiv.org/abs/2407.18419v3)** | 2025-07-15 | <details><summary>Show</summary><p>Advection-dominated problems are predominantly noticed in nature, engineering systems, and various industrial processes. Traditional linear compression methods, such as proper orthogonal decomposition (POD) and reduced basis (RB) methods are ill-suited for these problems, due to slow Kolmogorov $n$-width decay. This results in inefficient and inaccurate reduced order models (ROMs). There are few non-linear approaches to accelerate the Kolmogorov $n$-width decay. In this work, we use a neural network shift augmented transformation technique that employs automatic shift detection. This approach leverages a deep-learning framework to derive a parameter-dependent mapping between the original manifold $\mathcal{M}$ and the transformed manifold $\tilde{\mathcal{M}}$. We apply a linear compression method to obtain a low-dimensional linear approximation subspace of the transformed manifold $\tilde{\mathcal{M}}$. Furthermore, we construct non-intrusive reduced order models on the resulting transformed linear approximation subspace and employ automatic shift detection for predictions in the online stage. We propose a complete framework, the neural network shift-augmented proper orthogonal decomposition-based reduced order model (NNsPOD-ROM) algorithm, comprising both offline and online stages for model reduction of advection-dominated problems. We test our proposed methodology on numerous experiments to evaluate its performance on the 1D linear advection equation, a higher order method benchmark case - the 2D isentropic convective vortex, and 2D two-phase flow.</p></details> | 22 pages, 19 Figures |
| **[Kernel-based Greedy Approximation of Parametric Elliptic Boundary Value Problems](http://arxiv.org/abs/2507.06731v1)** | 2025-07-09 | <details><summary>Show</summary><p>We recently introduced a scale of kernel-based greedy schemes for approximating the solutions of elliptic boundary value problems. The procedure is based on a generalized interpolation framework in reproducing kernel Hilbert spaces and was coined PDE-$\beta$-greedy procedure, where the parameter $\beta \geq 0$ is used in a greedy selection criterion and steers the degree of function adaptivity. Algebraic convergence rates have been obtained for Sobolev-space kernels and solutions of finite smoothness. We now report a result of exponential convergence rates for the case of infinitely smooth kernels and solutions. We furthermore extend the approximation scheme to the case of parametric PDEs by the use of state-parameter product kernels. In the surrogate modelling context, the resulting approach can be interpreted as an a priori model reduction approach, as no solution snapshots need to be precomputed. Numerical results show the efficiency of the approximation procedure for problems which occur as challenges for other parametric MOR procedures: non-affine geometry parametrizations, moving sources or high-dimensional domains.</p></details> |  |
| **[Gramians for a New Class of Nonlinear Control Systems Using Koopman and a Novel Generalized SVD](http://arxiv.org/abs/2507.04188v1)** | 2025-07-05 | <details><summary>Show</summary><p>Model reduction with error bounds in nonlinear systems with non-affine control inputs remains an active field of research. In this work we present a construction for Controllability and Observability Gramians in a class of non-affine control input systems satisfying certain induced norm properties. We do so using a combination of representational forms, including a novel function decomposition that resembles linear Singular Value Decomposition (SVD), in tandem with an additional unconventional decomposition of the dynamics, and Koopman operator theory. The resulting representation allows one to place error bounds on the $H_{\infty}$ norm on a reduced-order representation of the system computed using finite-dimensional nonlinear Controllability and Observability Gramians.</p></details> |  |
| **[An ensemble Kalman approach to randomized maximum likelihood estimation](http://arxiv.org/abs/2507.03207v1)** | 2025-07-03 | <details><summary>Show</summary><p>This work proposes ensemble Kalman randomized maximum likelihood estimation, a new derivative-free method for performing randomized maximum likelihood estimation, which is a method that can be used to generate approximate samples from posterior distributions in Bayesian inverse problems. The new method has connections to ensemble Kalman inversion and works by evolving an ensemble so that each ensemble member solves an instance of a randomly perturbed optimization problem. Linear analysis demonstrates that ensemble members converge exponentially fast to randomized maximum likelihood estimators and, furthermore, that the new method produces samples from the Bayesian posterior when applied to a suitably regularized optimization problem. The method requires that the forward operator, relating the unknown parameter to the data, be evaluated once per iteration per ensemble member, which can be prohibitively expensive when the forward model requires the evolution of a high-dimensional dynamical system. We propose a strategy for making the proposed method tractable in this setting based on a balanced truncation model reduction method tailored to the Bayesian smoothing problem. Theoretical results show near-optimality of this model reduction approach via convergence to an optimal approximation of the posterior covariance as a low-rank update to the prior covariance. Numerical experiments verify theoretical results and illustrate computational acceleration through model reduction.</p></details> | 34 pages, 4 figures |
| **[Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations](http://arxiv.org/abs/2507.00301v1)** | 2025-06-30 | <details><summary>Show</summary><p>This work presents structure-preserving Lift & Learn, a scientific machine learning method that employs lifting variable transformations to learn structure-preserving reduced-order models for nonlinear partial differential equations (PDEs) with conservation laws. We propose a hybrid learning approach based on a recently developed energy-quadratization strategy that uses knowledge of the nonlinearity at the PDE level to derive an equivalent quadratic lifted system with quadratic system energy. The lifted dynamics obtained via energy quadratization are linear in the old variables, making model learning very effective in the lifted setting. Based on the lifted quadratic PDE model form, the proposed method derives quadratic reduced terms analytically and then uses those derived terms to formulate a constrained optimization problem to learn the remaining linear reduced operators in a structure-preserving way. The proposed hybrid learning approach yields computationally efficient quadratic reduced-order models that respect the underlying physics of the high-dimensional problem. We demonstrate the generalizability of quadratic models learned via the proposed structure-preserving Lift & Learn method through three numerical examples: the one-dimensional wave equation with exponential nonlinearity, the two-dimensional sine-Gordon equation, and the two-dimensional Klein-Gordon-Zakharov equations. The numerical results show that the proposed learning approach is competitive with the state-of-the-art structure-preserving data-driven model reduction method in terms of both accuracy and computational efficiency.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2503.02273</p></details> |
| **[Dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances](http://arxiv.org/abs/2506.23892v1)** | 2025-06-30 | <details><summary>Show</summary><p>Bayesian inverse problems use observed data to update a prior probability distribution for an unknown state or parameter of a scientific system to a posterior distribution conditioned on the data. In many applications, the unknown parameter is high-dimensional, making computation of the posterior expensive due to the need to sample in a high-dimensional space and the need to evaluate an expensive high-dimensional forward model relating the unknown parameter to the data. However, inverse problems often exhibit low-dimensional structure due to the fact that the available data are only informative in a low-dimensional subspace of the parameter space. Dimension reduction approaches exploit this structure by restricting inference to the low-dimensional subspace informed by the data, which can be sampled more efficiently. Further computational cost reductions can be achieved by replacing expensive high-dimensional forward models with cheaper lower-dimensional reduced models. In this work, we propose new dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances, which arise in many practical inference settings. The dimension reduction approach is applicable to general linear Bayesian inverse problems whereas the model reduction approaches are specific to the problem of inferring the initial condition of a linear dynamical system. We provide theoretical approximation guarantees as well as numerical experiments demonstrating the accuracy and efficiency of the proposed approaches.</p></details> |  |
| **[Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems](http://arxiv.org/abs/2505.00460v2)** | 2025-06-25 | <details><summary>Show</summary><p>In situations where the solution of a high-fidelity dynamical system needs to be evaluated repeatedly, over a vast pool of parametric configurations and in absence of access to the underlying governing equations, data-driven model reduction techniques are preferable. We propose a novel active learning approach to build a parametric data-driven reduced-order model (ROM) by greedily picking the most important parameter samples from the parameter domain. As a result, during the ROM construction phase, the number of high-fidelity solutions dynamically grow in a principled fashion. The high-fidelity solution snapshots are expressed in several parameter-specific linear subspaces, with the help of proper orthogonal decomposition (POD), and the relative distance between these subspaces is used as a guiding mechanism to perform active learning. For successfully achieving this, we provide a distance measure to evaluate the similarity between pairs of linear subspaces with different dimensions, and also show that this distance measure is a metric. The usability of the proposed subspace-distance-enabled active learning (SDE-AL) framework is demonstrated by augmenting two existing non-intrusive reduced-order modeling approaches, and providing their active-learning-driven (ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN. Furthermore, we report positive results for two parametric physical models, highlighting the efficiency of the proposed SDE-AL approach.</p></details> | <details><summary>31 pa...</summary><p>31 pages, 10 figures, 4 tables; v2: minor improvements</p></details> |
| **[A parametric tensor ROM for the shallow water dam break problem](http://arxiv.org/abs/2506.20007v1)** | 2025-06-24 | <details><summary>Show</summary><p>We develop a variant of a tensor reduced-order model (tROM) for the parameterized shallow-water dam-break problem. This hyperbolic system presents multiple challenges for model reduction, including a slow decay of the Kolmogorov $N$-width of the solution manifold, shock formation, and the loss of smooth solution dependence on parameters. These issues limit the performance of traditional Proper Orthogonal Decomposition based ROMs. Our tROM approach, based on a low-rank tensor decomposition, builds a parameter-to-solution map from high-fidelity snapshots and constructs localized reduced bases via a local POD procedure. We apply this method to both dry-bed and wet-bed problem setups, showing that the non-interpolatory variant of the tROM, combined with Chebyshev sampling near critical parameter values, effectively captures parameter-dependent behavior and significantly outperforms standard POD-ROMs. This is especially evident in the wet-bed case, where POD-ROMs exhibit poor resolution of shock waves and spurious oscillations.</p></details> |  |
| **[Model Reduction of Homogeneous Polynomial Dynamical Systems via Tensor Decomposition](http://arxiv.org/abs/2506.19165v1)** | 2025-06-23 | <details><summary>Show</summary><p>Model reduction plays a critical role in system control, with established methods such as balanced truncation widely used for linear systems. However, extending these methods to nonlinear settings, particularly polynomial dynamical systems that are often used to model higher-order interactions in physics, biology, and ecology, remains a significant challenge. In this article, we develop a novel model reduction method for homogeneous polynomial dynamical systems (HPDSs) with linear input and output grounded in tensor decomposition. Leveraging the inherent tensor structure of HPDSs, we construct reduced models by extracting dominant mode subspaces via higher-order singular value decomposition. Notably, we establish that key system-theoretic properties, including stability, controllability, and observability, are preserved in the reduced model. We demonstrate the effectiveness of our method using numerical examples.</p></details> |  |
| **[Maximum volume coordinates for Grassmann interpolation: Lagrange, Hermite, and errors](http://arxiv.org/abs/2506.01574v2)** | 2025-06-20 | <details><summary>Show</summary><p>We present a novel approach to Riemannian interpolation on the Grassmann manifold. Instead of relying on the Riemannian normal coordinates, i.e. the Riemannian exponential and logarithm maps, we approach the interpolation problem with an alternative set of local coordinates and corresponding parameterizations. A special property of these coordinates is that their calculation does not require any matrix decompositions. This is a numerical advantage over Riemann normal coordinates and many other retractions on the Grassmann manifold, especially when derivative data are to be treated. To estimate the interpolation error, we examine the conditioning of these mappings and state explicit bounds. It turns out that the parameterizations are well-conditioned, but the coordinate mappings are generally not. As a remedy, we introduce maximum-volume coordinates that are based on a search for subblocks of column-orthogonal matrices of large absolute determinant. We show that the order of magnitude of the asymptotic interpolation error on $\Gr(n,p)$ is the same as in the Euclidean space. Two numerical experiments are conducted. The first is an academic one, where we interpolate a parametric orthogonal projector $QQ^T$, where the $Q$--factor stems from a parametric compact QR--decomposition. The second experiment is in the context of parametric model reduction of dynamical systems, where we interpolate reduced subspaces that are obtained by proper orthogonal decomposition.</p></details> | 34 pages, 6 figures |
| **[Model Reduction of a Flexible Nonsmooth Oscillator Recovers its Entire Bifurcation Structure](http://arxiv.org/abs/2311.17947v4)** | 2025-06-19 | <details><summary>Show</summary><p>We study the reduced order modeling of a piecewise-linear, globally nonlinear flexible oscillator in which a Bernoulli-Euler beam is subjected to a position-triggered kick force and a piecewise restoring force at its tip. The nonsmooth boundary conditions, which determine different regions of a hybrid phase space, can generally be expected to excite many degrees of freedom. With kick strength as parameter, the system's bifurcation diagram is found to exhibit a range of periodic and chaotic behaviors. Proper orthogonal decomposition (POD) is used to obtain a single set of global basis functions spanning all of the hybrid regions. The reduced order model (ROM) dimension is chosen using previously developed energy closure analysis, ensuring approximate energy balance on the reduced subspace. This yields accurate ROMs with 8 degrees of freedom. Remarkably, we find that ROMs formulated using using data from individual periodic steady states can nevertheless be used to reconstruct the entire bifurcation structure of the original system without updating. This demonstrates that, despite being constructed with steady state data, the ROMs model sufficiently small transients with enough accuracy to permit using simple continuation for the bifurcation diagram. We also find ROM subspaces obtained for different values of the bifurcation parameter are essentially identical. Thus, POD augmented with energy closure analysis is found to reliably yield effective dimension estimates and ROMs for this nonlinear, nonsmooth system that are robust across stability transitions, including even period doubling cascades to chaos, thereby greatly reducing data requirements and computational costs.</p></details> | 32 pages, 8 figures |
| **[Data-Driven Model Reduction by Moment Matching for Linear and Nonlinear Parametric Systems](http://arxiv.org/abs/2506.10866v1)** | 2025-06-12 | <details><summary>Show</summary><p>Theory and methods to obtain parametric reduced-order models by moment matching are presented. The definition of the parametric moment is introduced, and methods (model-based and data-driven) for the approximation of the parametric moment of linear and nonlinear parametric systems are proposed. These approximations are exploited to construct families of parametric reduced-order models that match the approximate parametric moment of the system to be reduced and preserve key system properties such as asymptotic stability and dissipativity. The use of the model reduction methods is illustrated by means of a parametric benchmark model for the linear case and a large-scale wind farm model for the nonlinear case. In the illustration, a comparison of the proposed approximation methods is drawn and their advantages/disadvantages are discussed.</p></details> | <details><summary>16 pa...</summary><p>16 pages, 6 figures, submitted to IEEE Transactions on Automatic Control</p></details> |
| **[Multiscale model reduction and two-level Schwarz preconditioner for H(curl) elliptic problems](http://arxiv.org/abs/2506.07381v1)** | 2025-06-09 | <details><summary>Show</summary><p>This paper addresses the efficient solution of linear systems arising from curl-conforming finite element discretizations of $H(\mathrm{curl})$ elliptic problems with heterogeneous coefficients. We first employ the discrete form of a multiscale spectral generalized finite element method (MS-GFEM) for model reduction and prove that the method exhibits exponential convergence with respect to the number of local degrees of freedom. The proposed method and its convergence analysis are applicable in broad settings, including general heterogeneous ($L^{\infty}$) coefficients, domains and subdomains with nontrivial topology, irregular subdomain geometries, and high-order finite element discretizations. Furthermore, we formulate the method as an iterative solver, yielding a two-level restricted additive Schwarz type preconditioner based on the MS-GFEM coarse space. The GMRES algorithm, applied to the preconditioned system, is shown to converge at a rate of at least $\Lambda$, where $\Lambda$ denotes the error bound of the discrete MS-GFEM approximation. Numerical experiments in both two and three dimensions demonstrate the superior performance of the proposed methods in terms of dimensionality reduction.</p></details> |  |
| **[Energy-stable Port-Hamiltonian Systems](http://arxiv.org/abs/2506.06471v1)** | 2025-06-06 | <details><summary>Show</summary><p>We combine energy-stable and port-Hamiltonian (pH) systems to obtain energy-stable port-Hamiltonian (espH) systems. The idea is to extend the known energy-stable systems with an input-output port, which results in a pH formulation. One advantage of the new espH formulation is that it naturally preserves its espH structure throughout discretization (in space and time) and model reduction.</p></details> | 10 pages |
| **[Model Reduction for Transport-Dominated Problems via Cross-Correlation Based Snapshot Registration](http://arxiv.org/abs/2501.01299v2)** | 2025-06-04 | <details><summary>Show</summary><p>Traditional linear approximation methods, such as proper orthogonal decomposition and the reduced basis method, are ill-suited for transport-dominated problems due to the slow decay of the Kolmogorov $n$-width, leading to inefficient and inaccurate reduced-order models. In this work, we propose a model reduction approach for transport-dominated problems by employing cross-correlation based snapshot registration to accelerate the Kolmogorov $n$-width decay, thereby enabling the construction of efficient and accurate reduced-order models using linear approximation methods. We propose a complete framework comprising offline-online stages for the development of reduced order models using the cross-correlation based snapshots registration. The effectiveness of the proposed approach is demonstrated using two test cases: 1D travelling waves and the higher-order methods benchmark test case, 2D isentropic convective vortex.</p></details> |  |
| **[An iterative tangential interpolation framework for model reduction of MIMO systems](http://arxiv.org/abs/2506.03410v1)** | 2025-06-03 | <details><summary>Show</summary><p>We consider model reduction of large-scale MIMO systems using tangential interpolation in the frequency domain. Our scheme is related to the recently-developed Adaptive Antoulas--Anderson (AAA) algorithm, which is an iterative algorithm that uses concepts from the Loewner framework. Our algorithm uses low-rank interpolation and iteratively adds interpolation points based on several criteria including minimizing maximum errors. We show there is freedom in the interpolation point selection method, leading to multiple algorithms that have trade-offs between computational complexity and approximation performance. We prove that a weighted \(H_2\) norm of a representative error system is monotonically decreasing as interpolation points are added. Finally, we provide computational results and some comparisons with prior works, demonstrating performance on par with standard model reduction methods.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 4 figures Submitted to IEEE TAC</p></details> |
| **[AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models](http://arxiv.org/abs/2505.24784v1)** | 2025-05-30 | <details><summary>Show</summary><p>Current deep reinforcement learning (DRL) approaches achieve state-of-the-art performance in various domains, but struggle with data efficiency compared to human learning, which leverages core priors about objects and their interactions. Active inference offers a principled framework for integrating sensory information with prior knowledge to learn a world model and quantify the uncertainty of its own beliefs and predictions. However, active inference models are usually crafted for a single task with bespoke knowledge, so they lack the domain flexibility typical of DRL approaches. To bridge this gap, we propose a novel architecture that integrates a minimal yet expressive set of core priors about object-centric dynamics and interactions to accelerate learning in low-data regimes. The resulting approach, which we call AXIOM, combines the usual data efficiency and interpretability of Bayesian approaches with the across-task generalization usually associated with DRL. AXIOM represents scenes as compositions of objects, whose dynamics are modeled as piecewise linear trajectories that capture sparse object-object interactions. The structure of the generative model is expanded online by growing and learning mixture models from single events and periodically refined through Bayesian model reduction to induce generalization. AXIOM masters various games within only 10,000 interaction steps, with both a small number of parameters compared to DRL, and without the computational expense of gradient-based optimization.</p></details> | <details><summary>10 pa...</summary><p>10 pages main text, 4 figures, 2 tables; 25 pages supplementary material, 8 figures</p></details> |
| **[Structure Identification of NDS with Descriptor Subsystems under Asynchronous, Non-Uniform, and Slow-Rate Sampling](http://arxiv.org/abs/2503.20319v2)** | 2025-05-28 | <details><summary>Show</summary><p>Networked dynamic systems (NDS) exhibit collective behavior shaped by subsystem dynamics and complex interconnections, yet identifying these interconnections remains challenging due to irregularities in sampled data, including asynchronous, non-uniform, and low-rate sampling. This paper proposes a novel two-stage structure identification algorithm that leverages system zero-order moments, a concept traditionally used in model order reduction, to bridge system identification and model reduction. First, zero-order moments are estimated from steady-state time-domain outputs; second, subsystem interconnections are explicitly reconstructed from these moments. The method generalizes existing approaches by handling asynchronous, non-uniform, and slow sampling simultaneously, eliminating constraints on input signal periodicity and extending applicability to multi-input multi-output NDS with arbitrary interconnections. Unlike black-box identification techniques, our approach explicitly recovers subsystem interconnection structures. Validation on the IEEE 14-bus system demonstrates the algorithm's effectiveness in recovering subsystem interconnections from irregular sampling data.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 3 figures, cdc2025</p></details> |
| **[Least Squares Model Reduction: A Two-Stage System-Theoretic Interpretation](http://arxiv.org/abs/2505.20604v1)** | 2025-05-27 | <details><summary>Show</summary><p>Model reduction simplifies complex dynamical systems while preserving essential properties. This paper revisits a recently proposed system-theoretic framework for least squares moment matching. It interprets least squares model reduction in terms of two steps process: constructing a surrogate model to satisfy interpolation constraints, then projecting it onto a reduced-order space. Using tools from output regulation theory and Krylov projections, this approach provides a new view on classical methods. For illustration, we reexamine the least-squares model reduction method by Lucas and Smith, offering new insights into its structure.</p></details> | <details><summary>13th ...</summary><p>13th IFAC Symposium on Nonlinear Control Systems. arXiv admin note: substantial text overlap with arXiv:2110.06072</p></details> |
| **[EGPT-PINN: Entropy-enhanced Generative Pre-Trained Physics Informed Neural Networks for parameterized nonlinear conservation laws](http://arxiv.org/abs/2501.01587v2)** | 2025-05-25 | <details><summary>Show</summary><p>We propose an entropy-enhanced Generative Pre-Trained Physics-Informed Neural Network with a transform layer (EGPT-PINN) for solving parameterized nonlinear conservation laws. The EGPT-PINN extends the traditional physics-informed neural networks and its recently proposed generative pre-trained strategy for linear model reduction to nonlinear model reduction and shock-capturing domains. By utilizing an adaptive meta-network, a simultaneously trained transform layer, entropy enhancement strategies, implementable shock interaction analysis, and a separable training process, the EGPT-PINN efficiently captures complex parameter-dependent shock formations and interactions. Numerical results of EGPT-PINN applied to the families of inviscid Burgers' equation and the Euler equations, parameterized by their initial conditions, demonstrate the robustness and accuracy of the proposed technique. It accurately solves the viscosity solution via very few neurons without leveraging any {\it a priori} knowledge of the equations or its initial condition. Moreover, via a simple augmentation of the loss function by model-data mismatch, we demonstrate the robustness of EGPT-PINN in solving inverse problems more accurately than the vanilla and entropy-enhanced versions of PINN.</p></details> | 24 pages,12 figures |
| **[Automatic and Structure-Aware Sparsification of Hybrid Neural ODEs](http://arxiv.org/abs/2505.18996v1)** | 2025-05-25 | <details><summary>Show</summary><p>Hybrid neural ordinary differential equations (neural ODEs) integrate mechanistic models with neural ODEs, offering strong inductive bias and flexibility, and are particularly advantageous in data-scarce healthcare settings. However, excessive latent states and interactions from mechanistic models can lead to training inefficiency and over-fitting, limiting practical effectiveness of hybrid neural ODEs. In response, we propose a new hybrid pipeline for automatic state selection and structure optimization in mechanistic neural ODEs, combining domain-informed graph modifications with data-driven regularization to sparsify the model for improving predictive performance and stability while retaining mechanistic plausibility. Experiments on synthetic and real-world data show improved predictive performance and robustness with desired sparsity, establishing an effective solution for hybrid model reduction in healthcare applications.</p></details> |  |
| **[A New Fick-Jacobs Derivation with Applications to Computational Branched Diffusion Networks](http://arxiv.org/abs/2501.08247v2)** | 2025-05-22 | <details><summary>Show</summary><p>The Fick-Jacobs equation is a classical model reduction of 3-dimensional diffusion in a tube of varying radius to a 1-dimensional problem with radially scaled derivatives. This model has been shown to be unstable when the radial gradient is too steep. In this work, we present a new derivation of the Fick-Jacobs equation that results in the addition of higher order spatial derivative terms that provide additional stability in a wide variety of cases and improved solution convergence. We also derive new numerical schemes for branched nodes within networks and provide stability conditions for these schemes. The computational accuracy, efficiency, and stability of our method is demonstrated through a variety of numerical examples.</p></details> | 23 pages, 15 figures |
| **[Neural empirical interpolation method for nonlinear model reduction](http://arxiv.org/abs/2406.03562v2)** | 2025-05-11 | <details><summary>Show</summary><p>In this paper, we introduce the neural empirical interpolation method (NEIM), a neural network-based alternative to the discrete empirical interpolation method for reducing the time complexity of computing the nonlinear term in a reduced order model (ROM) for a parameterized nonlinear partial differential equation. NEIM is a greedy algorithm which accomplishes this reduction by approximating an affine decomposition of the nonlinear term of the ROM, where the vector terms of the expansion are given by neural networks depending on the ROM solution, and the coefficients are given by an interpolation of some "optimal" coefficients. Because NEIM is based on a greedy strategy, we are able to provide a basic error analysis to investigate its performance. NEIM has the advantages of being easy to implement in models with automatic differentiation, of being a nonlinear projection of the ROM nonlinearity, of being efficient for both nonlocal and local nonlinearities, and of relying solely on data and not the explicit form of the ROM nonlinearity. We demonstrate the effectiveness of the methodology on solution-dependent and solution-independent nonlinearities, a nonlinear elliptic problem, and a nonlinear parabolic model of liquid crystals. Code availability: https://github.com/maxhirsch/NEIM</p></details> |  |
| **[Application of a Novel Model Reduction Technique to the Assessment of Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems](http://arxiv.org/abs/2401.11398v2)** | 2025-05-10 | <details><summary>Show</summary><p>Assessing the boundedness and stability of vector nonlinear systems with variable delays and coefficients remains a challenging problem with broad applications in science and engineering. Existing methods tend to produce overly conservative criteria that offer limited practical value and often fail to explicitly characterize the temporal evolution of solution norms. This paper presents a novel framework for evaluating the evolution of solution norms in such systems. This approach constructs scalar counterparts for the original vector equations. We prove that the solutions to these scalar nonlinear equations, which also include delays and variable coefficients, provide upper bounds for the norms of the original solutions, if the history functions for both equations are properly matched. This reduction enables the evaluation of the boundedness and stability of vector systems through the analysis of the dynamics of their scalar counterparts, which can be performed via straightforward simulations or simplified analytical reasoning. Consequently, we introduce new criteria for boundedness and stability and estimate the radii of the balls containing history functions that yield bounded or stable solutions for the original vector systems. Finally, we validated our inferences through representative simulations that also assessed the accuracy of the proposed approach.</p></details> | 18 pages |
| **[Development of Reduced Feeder and Load Models Using Practical Topological and Loading Data](http://arxiv.org/abs/2505.06439v1)** | 2025-05-09 | <details><summary>Show</summary><p>Distribution feeder and load model reduction methods are essential for maintaining a good tradeoff between accurate representation of grid behavior and reduced computational complexity in power system studies. An effective algorithm to obtain a reduced order representation of the practical feeders using utility topological and loading data has been presented in this paper. Simulations conducted in this work show that the reduced feeder and load model of a utility feeder, obtained using the proposed method, can accurately capture contactor and motor stalling behaviors for critical events such as fault induced delayed voltage recovery.</p></details> |  |
| **[Stochastic Subspace via Probabilistic Principal Component Analysis for Characterizing Model Error](http://arxiv.org/abs/2504.19963v2)** | 2025-05-06 | <details><summary>Show</summary><p>This paper proposes a probabilistic model of subspaces based on the probabilistic principal component analysis (PCA). Given a sample of vectors in the embedding space -- commonly known as a snapshot matrix -- this method uses quantities derived from the probabilistic PCA to construct distributions of the sample matrix, as well as the principal subspaces. It is applicable to projection-based reduced-order modeling methods, such as proper orthogonal decomposition and related model reduction methods. The stochastic subspace thus constructed can be used, for example, to characterize model-form uncertainty in computational mechanics. The proposed method has multiple desirable properties: (1) it is naturally justified by the probabilistic PCA and has analytic forms for the induced random matrix models; (2) it satisfies linear constraints, such as boundary conditions of all kinds, by default; (3) it has only one hyperparameter, which significantly simplifies training; and (4) its algorithm is very easy to implement. We demonstrate the performance of the proposed method via several numerical examples in computational mechanics and structural dynamics.</p></details> |  |
| **[Weighted balanced truncation method for approximating kernel functions by exponentials](http://arxiv.org/abs/2503.03183v2)** | 2025-05-06 | <details><summary>Show</summary><p>Kernel approximation with exponentials is useful in many problems with convolution quadrature and particle interactions such as integral-differential equations, molecular dynamics and machine learning. This paper proposes a weighted balanced truncation to construct an optimal model reduction method for compressing the number of exponentials in the sum-of-exponentials approximation of kernel functions. This method shows great promise in approximating long-range kernels, achieving over 4 digits of accuracy improvement for the Ewald-splitting and inverse power kernels in comparison with the classical balanced truncation. Numerical results demonstrate its excellent performance and attractive features for practical applications.</p></details> | 11 pages, 6 figures |
| **[$\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems by multivariate rational interpolation](http://arxiv.org/abs/2505.03057v1)** | 2025-05-05 | <details><summary>Show</summary><p>This paper addresses the $\mathcal{H}_2$-optimal approximation of linear dynamical systems with quadratic-output functions, also known as linear quadratic-output systems. Our major contributions are threefold. First, we derive interpolation-based first-order optimality conditions for the linear quadratic-output $\mathcal{H}_2$ minimization problem. These conditions correspond to the mixed-multipoint tangential interpolation of the full-order linear- and quadratic-output transfer functions, and generalize the Meier-Luenberger optimality framework for the $\mathcal{H}_2$-optimal model reduction of linear time-invariant systems. Second, given the interpolation data, we show how to enforce these mixed-multipoint tangential interpolation conditions explicitly by Petrov-Galerkin projection of the full-order model matrices. Third, to find the optimal interpolation data, we build on this projection framework and propose a generalization of the iterative rational Krylov algorithm for the $\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems, called LQO-IRKA. Upon convergence, LQO-IRKA produces a reduced linear quadratic-output system that satisfies the interpolatory optimality conditions. The method only requires solving shifted linear systems and matrix-vector products, thus making it suitable for large-scale problems. Numerical examples are included to illustrate the effectiveness of the proposed method.</p></details> |  |
| **[Steady-State Cascade Operators and their Role in Linear Control, Estimation, and Model Reduction Problems](http://arxiv.org/abs/2408.07568v2)** | 2025-05-01 | <details><summary>Show</summary><p>Certain linear matrix operators arise naturally in systems analysis and design problems involving cascade interconnections of linear time-invariant systems, including problems of stabilization, estimation, and model order reduction. We conduct here a comprehensive study of these operators and their relevant system-theoretic properties. The general theory is leveraged to delineate both known and new design methodologies for control and observation of cascades, and to characterize structural properties of reduced models. Several entirely new designs arise from this systematic categorization, including new recursive and low-gain design frameworks for observation of cascaded systems. The benefits of the results beyond the linear time-invariant setting are demonstrated through preliminary extensions for nonlinear systems, with an outlook towards the development of a similarly comprehensive nonlinear theory.</p></details> | <details><summary>16 pa...</summary><p>16 pages, 5 figures, revised version</p></details> |
| **[Generative Learning for Slow Manifolds and Bifurcation Diagrams](http://arxiv.org/abs/2504.20375v1)** | 2025-04-29 | <details><summary>Show</summary><p>In dynamical systems characterized by separation of time scales, the approximation of so called ``slow manifolds'', on which the long term dynamics lie, is a useful step for model reduction. Initializing on such slow manifolds is a useful step in modeling, since it circumvents fast transients, and is crucial in multiscale algorithms alternating between fine scale (fast) and coarser scale (slow) simulations. In a similar spirit, when one studies the infinite time dynamics of systems depending on parameters, the system attractors (e.g., its steady states) lie on bifurcation diagrams. Sampling these manifolds gives us representative attractors (here, steady states of ODEs or PDEs) at different parameter values. Algorithms for the systematic construction of these manifolds are required parts of the ``traditional'' numerical nonlinear dynamics toolkit. In more recent years, as the field of Machine Learning develops, conditional score-based generative models (cSGMs) have demonstrated capabilities in generating plausible data from target distributions that are conditioned on some given label. It is tempting to exploit such generative models to produce samples of data distributions conditioned on some quantity of interest (QoI). In this work, we present a framework for using cSGMs to quickly (a) initialize on a low-dimensional (reduced-order) slow manifold of a multi-time-scale system consistent with desired value(s) of a QoI (a ``label'') on the manifold, and (b) approximate steady states in a bifurcation diagram consistent with a (new, out-of-sample) parameter value. This conditional sampling can help uncover the geometry of the reduced slow-manifold and/or approximately ``fill in'' missing segments of steady states in a bifurcation diagram.</p></details> | <details><summary>17 pa...</summary><p>17 pages, 13 figures, 1 table</p></details> |
| **[Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction](http://arxiv.org/abs/2504.17655v1)** | 2025-04-24 | <details><summary>Show</summary><p>This paper presents a comprehensive empirical analysis of conformal prediction methods on a challenging aerial image dataset featuring diverse events in unconstrained environments. Conformal prediction is a powerful post-hoc technique that takes the output of any classifier and transforms it into a set of likely labels, providing a statistical guarantee on the coverage of the true label. Unlike evaluations on standard benchmarks, our study addresses the complexities of data-scarce and highly variable real-world settings. We investigate the effectiveness of leveraging pretrained models (MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to generate informative prediction sets. To further evaluate the impact of calibration, we consider two parallel pipelines (with and without temperature scaling) and assess performance using two key metrics: empirical coverage and average prediction set size. This setup allows us to systematically examine how calibration choices influence the trade-off between reliability and efficiency. Our findings demonstrate that even with relatively small labeled samples and simple nonconformity scores, conformal prediction can yield valuable uncertainty estimates for complex tasks. Moreover, our analysis reveals that while temperature scaling is often employed for calibration, it does not consistently lead to smaller prediction sets, underscoring the importance of careful consideration in its application. Furthermore, our results highlight the significant potential of model compression techniques within the conformal prediction pipeline for deployment in resource-constrained environments. Based on our observations, we advocate for future research to delve into the impact of noisy or ambiguous labels on conformal prediction performance and to explore effective model reduction strategies.</p></details> | <details><summary>17 pa...</summary><p>17 pages, 5 figures, and 2 tables</p></details> |
| **[On the Benefits of Memory for Modeling Time-Dependent PDEs](http://arxiv.org/abs/2409.02313v2)** | 2025-04-24 | <details><summary>Show</summary><p>Data-driven techniques have emerged as a promising alternative to traditional numerical methods for solving PDEs. For time-dependent PDEs, many approaches are Markovian -- the evolution of the trained system only depends on the current state, and not the past states. In this work, we investigate the benefits of using memory for modeling time-dependent PDEs: that is, when past states are explicitly used to predict the future. Motivated by the Mori-Zwanzig theory of model reduction, we theoretically exhibit examples of simple (even linear) PDEs, in which a solution that uses memory is arbitrarily better than a Markovian solution. Additionally, we introduce Memory Neural Operator (MemNO), a neural operator architecture that combines recent state space models (specifically, S4) and Fourier Neural Operators (FNOs) to effectively model memory. We empirically demonstrate that when the PDEs are supplied in low resolution or contain observation noise at train and test time, MemNO significantly outperforms the baselines without memory -- with up to 6x reduction in test error. Furthermore, we show that this benefit is particularly pronounced when the PDE solutions have significant high-frequency Fourier modes (e.g., low-viscosity fluid dynamics) and we construct a challenging benchmark dataset consisting of such PDEs.</p></details> |  |
| **[Robust, positive and exact model reduction via monotone matrices](http://arxiv.org/abs/2406.11696v3)** | 2025-04-22 | <details><summary>Show</summary><p>This work focuses on the problem of exact model reduction of positive linear systems, by leveraging minimal realization theory. While determining the existence of a positive reachable realization remains in general an open problem, we are able to fully characterize the cases in which the new model is obtained with non-negative reduction matrices, and hence positivity of the reduced model is robust with respect to small perturbations of the original system. The characterization is obtained by specializing monotone matrix theory to positive matrices. In addition, we provide a systematic method to construct positive reductions also when minimal ones are not available, by exploiting algebraic techniques.</p></details> |  |
| **[SUPRA: Subspace Parameterized Attention for Neural Operator on General Domains](http://arxiv.org/abs/2504.15897v1)** | 2025-04-22 | <details><summary>Show</summary><p>Neural operators are efficient surrogate models for solving partial differential equations (PDEs), but their key components face challenges: (1) in order to improve accuracy, attention mechanisms suffer from computational inefficiency on large-scale meshes, and (2) spectral convolutions rely on the Fast Fourier Transform (FFT) on regular grids and assume a flat geometry, which causes accuracy degradation on irregular domains. To tackle these problems, we regard the matrix-vector operations in the standard attention mechanism on vectors in Euclidean space as bilinear forms and linear operators in vector spaces and generalize the attention mechanism to function spaces. This new attention mechanism is fully equivalent to the standard attention but impossible to compute due to the infinite dimensionality of function spaces. To address this, inspired by model reduction techniques, we propose a Subspace Parameterized Attention (SUPRA) neural operator, which approximates the attention mechanism within a finite-dimensional subspace. To construct a subspace on irregular domains for SUPRA, we propose using the Laplacian eigenfunctions, which naturally adapt to domains' geometry and guarantee the optimal approximation for smooth functions. Experiments show that the SUPRA neural operator reduces error rates by up to 33% on various PDE datasets while maintaining state-of-the-art computational efficiency.</p></details> |  |
| **[Estimation and inference in error-in-operator model](http://arxiv.org/abs/2504.11834v2)** | 2025-04-21 | <details><summary>Show</summary><p>Many statistical problems can be reduced to a linear inverse problem in which only a noisy version of the operator is available. Particular examples include random design regression, deconvolution problem, instrumental variable regression, functional data analysis, error-in-variable regression, drift estimation in stochastic diffusion, and many others. The pragmatic plug-in approach can be well justified in the classical asymptotic setup with a growing sample size. However, recent developments in high dimensional inference reveal some new features of this problem. In high dimensional linear regression with a random design, the plug-in approach is questionable but the use of a simple ridge penalization yields a benign overfitting phenomenon; see \cite{baLoLu2020}, \cite{ChMo2022}, \cite{NoPuSp2024}. This paper revisits the general Error-in-Operator problem for finite samples and high dimension of the source and image spaces. A particular focus is on the choice of a proper regularization. We show that a simple ridge penalty (Tikhonov regularization) works properly in the case when the operator is more regular than the signal. In the opposite case, some model reduction technique like spectral truncation should be applied.</p></details> |  |
| **[Distributed computing for physics-based data-driven reduced modeling at scale: Application to a rotating detonation rocket engine](http://arxiv.org/abs/2407.09994v2)** | 2025-04-19 | <details><summary>Show</summary><p>High-performance computing (HPC) has revolutionized our ability to perform detailed simulations of complex real-world processes. A prominent contemporary example is from aerospace propulsion, where HPC is used for rotating detonation rocket engine (RDRE) simulations in support of the design of next-generation rocket engines; however, these simulations take millions of core hours even on powerful supercomputers, which makes them impractical for engineering tasks like design exploration and risk assessment. Data-driven reduced-order models (ROMs) aim to address this limitation by constructing computationally cheap yet sufficiently accurate approximations that serve as surrogates for the high-fidelity model. This paper contributes a distributed memory algorithm that achieves fast and scalable construction of predictive physics-based ROMs trained from sparse datasets of extremely large state dimension. The algorithm learns structured physics-based ROMs that approximate the dynamical systems underlying those datasets.This enables model reduction for problems at a scale and complexity that exceeds the capabilities of standard, serial approaches. We demonstrate our algorithm's scalability using up to $2,048$ cores on the Frontera supercomputer at the Texas Advanced Computing Center. We focus on a real-world three-dimensional RDRE for which one millisecond of simulated physical time requires one million core hours on a supercomputer. Using a training dataset of $2,536$ snapshots each of state dimension $76$ million, our distributed algorithm enables the construction of a predictive data-driven reduced model in just $13$ seconds on $2,048$ cores on Frontera.</p></details> | 22 pages, 8 figures |
| **[$\mathcal{H}_2$-optimal Model Reduction of Linear Quadratic Output Systems in Finite Frequency Range](http://arxiv.org/abs/2408.07939v2)** | 2025-04-18 | <details><summary>Show</summary><p>In frequency-limited model order reduction, the objective is to maintain the frequency response of the original system within a specified frequency range in the reduced-order model. In this paper, a mathematical expression for the frequency-limited $\mathcal{H}_2$ norm is derived, which quantifies the error within the desired frequency interval. Subsequently, the necessary conditions for a local optimum of the frequency-limited $\mathcal{H}_2$ norm of the error are derived. The inherent difficulty in satisfying these conditions within a Petrov-Galerkin projection framework is also discussed. Using the optimality conditions and the Petrov-Galerkin projection, a stationary point iteration algorithm is proposed, which approximately satisfies these optimality conditions upon convergence. The main computational effort in the proposed algorithm involves solving sparse-dense Sylvester equations. These equations are frequently encountered in $\mathcal{H}_2$ model order reduction algorithms and can be solved efficiently. Moreover, the algorithm bypasses the requirement of matrix logarithm computation, which is typically necessary for most frequency-limited reduction methods and can be computationally demanding for high-order systems. An illustrative example is provided to numerically validate the developed theory. The proposed algorithm's effectiveness in accurately approximating the original high-order model within the specified frequency range is demonstrated through the reduction of an advection-diffusion equation-based model, commonly used in model reduction literature for testing algorithms. Additionally, the algorithm's computational efficiency is highlighted by successfully reducing a flexible space structure model of order one million.</p></details> |  |
| **[Interpolatory model reduction of dynamical systems with root mean squared error](http://arxiv.org/abs/2403.08894v3)** | 2025-04-18 | <details><summary>Show</summary><p>The root mean squared error is an important measure used in a variety of applications such as structural dynamics and acoustics to model averaged deviations from standard behavior. For large-scale systems, simulations of this quantity quickly become computationally prohibitive. Classical model order reduction techniques attempt to resolve this issue via the construction of surrogate models that emulate the root mean squared error measure using an intermediate linear system. However, this approach requires a potentially large number of linear outputs, which can be disadvantageous in the design of reduced-order models. In this work, we consider directly the root mean squared error as the quantity of interest using the concept of quadratic-output models and propose several new model reduction techniques for the construction of appropriate surrogates. We test the proposed methods on a model for the vibrational response of a plate with tuned vibration absorbers.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 2 figures, 2 tables</p></details> |
| **[Balanced Truncation via Tangential Interpolation](http://arxiv.org/abs/2409.13358v2)** | 2025-04-10 | <details><summary>Show</summary><p>This paper examines the construction of rth-order truncated balanced realizations via tangential interpolation at r specified interpolation points. It is demonstrated that when the truncated Hankel singular values are negligible-that is, when the discarded states are nearly uncontrollable and unobservable-balanced truncation simplifies to a bi-tangential Hermite interpolation problem at r interpolation points. In such cases, the resulting truncated balanced realization is nearly H2-optimal and thus interpolates the original model at the mirror images of its poles along its residual directions. Like standard H2-optimal model reduction, where the interpolation points and tangential directions that yield a local optimum are not known, in balanced truncation as well, the interpolation points and tangential directions required to produce a truncated balanced realization remain unknown. To address this, we propose an iterative tangential interpolation-based algorithm for balanced truncation. Upon convergence, the algorithm yields a low-rank truncated balanced realization that accurately preserves the r largest Hankel singular values of the original system. An adaptive scheme to automatically select the order r of the reduced model is also proposed. The algorithm is fully automatic, choosing both the interpolation data and the model order without user intervention. Additionally, an adaptive low-rank solver for Lyapunov equations based on tangential interpolation is proposed, automatically selecting both the interpolation data and the rank without user intervention. The performance of the proposed algorithms is evaluated on benchmark models, confirming their efficacy.</p></details> |  |
| **[Machine Learning (ML) based Reduced Order Modeling (ROM) for linear and non-linear solid and structural mechanics](http://arxiv.org/abs/2504.06860v1)** | 2025-04-09 | <details><summary>Show</summary><p>Multiple model reduction techniques have been proposed to tackle linear and non linear problems. Intrusive model order reduction techniques exhibit high accuracy levels, however, they are rarely used as a standalone industrial tool, because of the required high level knowledge involved in the construction and usage of these techniques. Moreover, the computation time benefit is compromised for highly nonlinear problems. On the other hand, non-intrusive methods often struggle with accuracy in nonlinear cases, typically requiring a large design of experiment and a large number of snapshots achieve a reliable performance. However, generating the stiffness matrix in a non-intrusive approach presents an optimal way to align accuracy with efficiency, allying the advantages of both intrusive and non-intrusive methods.This work introduces a lightly intrusive model order reduction technique that employs machine learning within a Proper Orthogonal Decomposition framework to achieve this alliance. By leveraging outputs from commercial full-order models, this method constructs a reduced-order model that operates effectively without requiring expert user intervention. The proposed technique has the possibility to approximate linear non affine as well as non linear terms. It is showcased for linear and nonlinear structural mechanics problems.</p></details> |  |
| **[Scalable mixed-domain Gaussian process modeling and model reduction for longitudinal data](http://arxiv.org/abs/2111.02019v4)** | 2025-04-08 | <details><summary>Show</summary><p>Gaussian process (GP) models that combine both categorical and continuous input variables have found use in analysis of longitudinal data and computer experiments. However, standard inference for these models has the typical cubic scaling, and common scalable approximation schemes for GPs cannot be applied since the covariance function is non-continuous. In this work, we derive a basis function approximation scheme for mixed-domain covariance functions, which scales linearly with respect to the number of observations and total number of basis functions. The proposed approach is naturally applicable to also Bayesian GP regression with discrete observation models. We demonstrate the scalability of the approach and compare model reduction techniques for additive GP models in a longitudinal data context. We confirm that we can approximate the exact GP model accurately in a fraction of the runtime compared to fitting the corresponding exact model. In addition, we demonstrate a scalable model reduction workflow for obtaining smaller and more interpretable models when dealing with a large number of candidate predictors.</p></details> |  |
| **[On Differential Controllability and Observability Functions](http://arxiv.org/abs/2504.03250v1)** | 2025-04-04 | <details><summary>Show</summary><p>Differential balancing theory for nonlinear model reduction relies on differential controllability and observability functions. In this paper, we further investigate them from two different perspectives. First, we establish novel connections between these differential energy functions and their incremental counterparts by assuming the existence of the corresponding optimal state feedback for each controllability function. Specifically, an upper bound on the incremental controllability/observability function is provided by the corresponding differential energy function. Conversely, an upper bound on the differential controllability function can be estimated from the incremental controllability function. Furthermore, the differential observability function can be constructed from the incremental observability function. Second, we explore the positive definiteness of the differential controllability/observability function in the context of controllability/observability and stability.</p></details> |  |
| **[Data-Driven Nonlinear Model Reduction to Spectral Submanifolds via Oblique Projection](http://arxiv.org/abs/2503.21895v1)** | 2025-03-27 | <details><summary>Show</summary><p>The dynamics in a primary Spectral Submanifold (SSM) constructed over the slowest modes of a dynamical system provide an ideal reduced-order model for nearby trajectories. Modeling the dynamics of trajectories further away from the primary SSM, however, is difficult if the linear part of the system exhibits strong non-normal behavior. Such non-normality implies that simply projecting trajectories onto SSMs along directions normal to the slow linear modes will not pair those trajectories correctly with their reduced counterparts on the SSMs. In principle, a well-defined nonlinear projection along a stable invariant foliation exists and would exactly match the full dynamics to the SSM-reduced dynamics. This foliation, however, cannot realistically be constructed from practically feasible amounts and distributions of experimental data. Here we develop an oblique projection technique that is able to approximate this foliation efficiently, even from a single experimental trajectory of a significantly non-normal and nonlinear beam.</p></details> |  |
| **[Validation and Calibration of Energy Models with Real Vehicle Data from Chassis Dynamometer Experiments](http://arxiv.org/abs/2503.21057v1)** | 2025-03-27 | <details><summary>Show</summary><p>Accurate estimation of vehicle fuel consumption typically requires detailed modeling of complex internal powertrain dynamics, often resulting in computationally intensive simulations. However, many transportation applications-such as traffic flow modeling, optimization, and control-require simplified models that are fast, interpretable, and easy to implement, while still maintaining fidelity to physical energy behavior. This work builds upon a recently developed model reduction pipeline that derives physics-like energy models from high-fidelity Autonomie vehicle simulations. These reduced models preserve essential vehicle dynamics, enabling realistic fuel consumption estimation with minimal computational overhead. While the reduced models have demonstrated strong agreement with their Autonomie counterparts, previous validation efforts have been confined to simulation environments. This study extends the validation by comparing the reduced energy model's outputs against real-world vehicle data. Focusing on the MidSUV category, we tune the baseline Autonomie model to closely replicate the characteristics of a Toyota RAV4. We then assess the accuracy of the resulting reduced model in estimating fuel consumption under actual drive conditions. Our findings suggest that, when the reference Autonomie model is properly calibrated, the simplified model produced by the reduction pipeline can provide reliable, semi-principled fuel rate estimates suitable for large-scale transportation applications.</p></details> |  |

## Reduced Order Model
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Synthetic Acceleration Preconditioners for Parametric Radiative Transfer Equations based on Trajectory-Aware Reduced Order Models](http://arxiv.org/abs/2509.05001v1)** | 2025-09-05 | <details><summary>Show</summary><p>The parametric radiative transfer equation (RTE) arises in multi-query applications, such as design optimization, inverse problems, and uncertainty quantification, which require solving the RTE multiple times for various parameters. Classical synthetic acceleration (SA) preconditioners are designed based on low-order approximations of a kinetic correction equation, e.g., its diffusion limit in diffusion synthetic acceleration (DSA). Despite their widespread success, these methods rely on empirical physical assumptions and do not leverage low-rank structures across parameters of the parametric problem. To address these limitations, our previous work introduced a reduced-order model (ROM) enhanced preconditioner called ROMSAD, which exploits low-rank structures across parameters and the original kinetic description of the correction equation. While ROMSAD improves overall efficiency compared with DSA, its efficiency reduces after the first iteration, because the construction of the underlying ROM ignores the preconditioner-dependence of the residual trajectory, leading to a mismatch between the offline and online residual trajectories. To overcome this issue, we introduce a trajectory-aware framework that iteratively constructs ROMs to eliminate the mismatch between offline and online residual trajectories. Numerical tests demonstrate superior efficiency over DSA, and substantial gains in both efficiency and robustness over ROMSAD. For a parametric lattice problem, trajectory-aware ROM preconditioners achieve rapid convergence within only $2$-$3$ iterations online.</p></details> | 32 pages, 9 figures |
| **[Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots](http://arxiv.org/abs/2509.04722v1)** | 2025-09-05 | <details><summary>Show</summary><p>As humanoid robots enter real-world environments, ensuring robust locomotion across diverse environments is crucial. This paper presents a computationally efficient hierarchical control framework for humanoid robot locomotion based on reduced-order models -- enabling versatile step planning and incorporating arm and torso dynamics to better stabilize the walking. At the high level, we use the step-to-step dynamics of the ALIP model to simultaneously optimize over step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP trajectories are used as references to a linear MPC framework that extends the standard SRB-MPC to also include simplified arm and torso dynamics. We validate the performance of our approach through simulation and hardware experiments on the Unitree G1 humanoid robot. In the proposed framework the high-level step planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard mini-PC. Adaptive step timing increased the push recovery success rate by 36%, and the upper body control improved the yaw disturbance rejection. We also demonstrate robust locomotion across diverse indoor and outdoor terrains, including grass, stone pavement, and uneven gym mats.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 6 figures, accepted to IEEE-RAS International Conference on Humanoid Robots 2025</p></details> |
| **[Taming High-Dimensional Dynamics: Learning Optimal Projections onto Spectral Submanifolds](http://arxiv.org/abs/2504.03157v2)** | 2025-09-04 | <details><summary>Show</summary><p>High-dimensional nonlinear systems pose considerable challenges for modeling and control across many domains, from fluid mechanics to advanced robotics. Such systems are typically approximated with reduced-order models, which often rely on orthogonal projections, a simplification that may lead to large prediction errors. In this work, we derive optimality of fiber-aligned projections onto spectral submanifolds, preserving the nonlinear geometric structure and minimizing long-term prediction error. We propose a data-driven procedure to learn these projections from trajectories and demonstrate its effectiveness through a 180-dimensional robotic system. Our reduced-order models achieve up to fivefold improvement in trajectory tracking accuracy under model predictive control compared to the state of the art.</p></details> |  |
| **[Autoencoder-based non-intrusive model order reduction in continuum mechanics](http://arxiv.org/abs/2509.02237v1)** | 2025-09-02 | <details><summary>Show</summary><p>We propose a non-intrusive, Autoencoder-based framework for reduced-order modeling in continuum mechanics. Our method integrates three stages: (i) an unsupervised Autoencoder compresses high-dimensional finite element solutions into a compact latent space, (ii) a supervised regression network maps problem parameters to latent codes, and (iii) an end-to-end surrogate reconstructs full-field solutions directly from input parameters. To overcome limitations of existing approaches, we propose two key extensions: a force-augmented variant that jointly predicts displacement fields and reaction forces at Neumann boundaries, and a multi-field architecture that enables coupled field predictions, such as in thermo-mechanical systems. The framework is validated on nonlinear benchmark problems involving heterogeneous composites, anisotropic elasticity with geometric variation, and thermo-mechanical coupling. Across all cases, it achieves accurate reconstructions of high-fidelity solutions while remaining fully non-intrusive. These results highlight the potential of combining deep learning with dimensionality reduction to build efficient and extensible surrogate models. Our publicly available implementation provides a foundation for integrating data-driven model order reduction into uncertainty quantification, optimization, and digital twin applications.</p></details> |  |
| **[Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction](http://arxiv.org/abs/2410.18148v4)** | 2025-08-31 | <details><summary>Show</summary><p>Representation learning for high-dimensional, complex physical systems aims to identify a low-dimensional intrinsic latent space, which is crucial for reduced-order modeling and modal analysis. To overcome the well-known Kolmogorov barrier, deep autoencoders (AEs) have been introduced in recent years, but they often suffer from poor convergence behavior as the rank of the latent space increases. To address this issue, we propose the learnable weighted hybrid autoencoder, a hybrid approach that combines the strengths of singular value decomposition (SVD) with deep autoencoders through a learnable weighted framework. We find that the introduction of learnable weighting parameters is essential -- without them, the resulting model would either collapse into a standard POD or fail to exhibit the desired convergence behavior. Interestingly, we empirically find that our trained model has a sharpness thousands of times smaller compared to other models. Our experiments on classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and forced isotropic turbulence datasets, demonstrate that our approach significantly improves generalization performance compared to several competing methods. Additionally, when combining with time series modeling techniques (e.g., Koopman operator, LSTM), the proposed technique offers significant improvements for surrogate modeling of high-dimensional multi-scale PDE systems.</p></details> | 34 pages |
| **[Reduced-Order Modeling of Cyclo-Stationary Time Series Using Score-Based Generative Methods](http://arxiv.org/abs/2508.19448v2)** | 2025-08-30 | <details><summary>Show</summary><p>Many natural systems exhibit cyclo-stationary behavior characterized by periodic forcing such as annual and diurnal cycles. We present a data-driven method leveraging recent advances in score-based generative modeling to construct reduced-order models for such cyclo-stationary time series. Our approach accurately reproduces the statistical properties and temporal correlations of the original data, enabling efficient generation of synthetic trajectories. We demonstrate the performance of the method through application to the Planet Simulator (PlaSim) climate model, constructing a reduced-order model for the 20 leading principal components of surface temperature driven by the annual cycle. The resulting surrogate model accurately reproduces the marginal and joint probability distributions, autocorrelation functions, and spatial coherence of the original climate system across multiple validation metrics. The approach offers substantial computational advantages, enabling generation of centuries of synthetic climate data in minutes compared to weeks required for equivalent full model simulations. This work opens new possibilities for efficient modeling of periodically forced systems across diverse scientific domains, providing a principled framework for balancing computational efficiency with physical fidelity in reduced-order modeling applications.</p></details> |  |
| **[A Layered Control Perspective on Legged Locomotion: Embedding Reduced Order Models via Hybrid Zero Dynamics](http://arxiv.org/abs/2509.00294v1)** | 2025-08-30 | <details><summary>Show</summary><p>Reduced-order models (ROMs) provide a powerful means of synthesizing dynamic walking gaits on legged robots. Yet this approach lacks the formal guarantees enjoyed by methods that utilize the full-order model (FOM) for gait synthesis, e.g., hybrid zero dynamics. This paper aims to unify these approaches through a layered control perspective. In particular, we establish conditions on when a ROM of locomotion yields stable walking on the full-order hybrid dynamics. To achieve this result, given an ROM we synthesize a zero dynamics manifold encoding the behavior of the ROM -- controllers can be synthesized that drive the FOM to this surface, yielding hybrid zero dynamics. We prove that a stable periodic orbit in the ROM implies an input-to-state stable periodic orbit of the FOM's hybrid zero dynamics, and hence the FOM dynamics. This result is demonstrated in simulation on a linear inverted pendulum ROM and a 5-link planar walking FOM.</p></details> |  |
| **[Data-Driven Bifurcation Handling in Physics-Based Reduced-Order Vascular Hemodynamic Models](http://arxiv.org/abs/2508.21165v1)** | 2025-08-28 | <details><summary>Show</summary><p>Three-dimensional (3D) finite-element simulations of cardiovascular flows provide high-fidelity predictions to support cardiovascular medicine, but their high computational cost limits clinical practicality. Reduced-order models (ROMs) offer computationally efficient alternatives but suffer reduced accuracy, particularly at vessel bifurcations where complex flow physics are inadequately captured by standard Poiseuille flow assumptions. We present an enhanced numerical framework that integrates machine learning-predicted bifurcation coefficients into zero-dimensional (0D) hemodynamic ROMs to improve accuracy while maintaining computational efficiency. We develop a resistor-resistor-inductor (RRI) model that uses neural networks to predict pressure-flow relationships from bifurcation geometry, incorporating linear and quadratic resistances along with inductive effects. The method employs non-dimensionalization to reduce training data requirements and apriori flow split prediction for improved bifurcation characterization. We incorporate the RRI model into a 0D model using an optimization-based solution strategy. We validate the approach in isolated bifurcations and vascular trees, across Reynolds numbers from 0 to 5,500, defining ROM accuracy by comparison to 3D finite element simulation. Results demonstrate substantial accuracy improvements: averaged across all trees and Reynolds numbers, the RRI method reduces inlet pressure errors from 54 mmHg (45%) for standard 0D models to 25 mmHg (17%), while a simplified resistor-inductor (RI) variant achieves 31 mmHg (26%) error. The enhanced 0D models show particular effectiveness at high Reynolds numbers and in extensive vascular networks. This hybrid numerical approach enables accurate, real-time hemodynamic modeling for clinical decision support, uncertainty quantification, and digital twins in cardiovascular biomedical engineering.</p></details> | 32 pages, 13 figures |
| **[A Deep-Learning Enhanced Gappy Proper Orthogonal Decomposition Method for Conjugate Heat Transfer Problem](http://arxiv.org/abs/2508.20633v1)** | 2025-08-28 | <details><summary>Show</summary><p>The current study aims to develop a non-intrusive Reduced Order Model (ROM) to reconstruct the full temperature field for a large-scale industrial application based on both numerical and experimental datasets. The proposed approach is validated against a domestic refrigerator. At the full order level, air circulation and heat transfer in fluid and between fluid and surrounding solids in the fridge were numerically studied using the Conjugated Heat Transfer (CHT) method to explore both the natural and forced convection-based fridge model followed by a parametric study-based on the ambient temperature, fridge fan velocity, and evaporator temperature. The main novelty of the current work is the introduction of a stable Artificial Neural Network (ANN) enhanced Gappy Proper Orthogonal Decomposition (GPOD) method which shows better performance than the conventional GPOD approach in such large-scale industrial applications. The full-order model is validated with the experimental results and the prediction accuracy of the surrogate model associated with different reduced-order approaches is compared with the benchmark numerical results or high-fidelity results. In our current work, we show that a prediction error of one degree centigrade and computational speed-up of 5000 is achieved even at a very sparse training dataset using the proposed deep-learning enhanced GPOD approach.</p></details> |  |
| **[Self-consistent clustering analysis for homogenisation of heterogeneous plates](http://arxiv.org/abs/2508.20446v1)** | 2025-08-28 | <details><summary>Show</summary><p>This work introduces a reduced-order model for plate structures with periodic micro-structures by coupling self-consistent clustering analysis (SCA) with the Lippmann-Schwinger equation, enabling rapid multiscale homogenisation of heterogeneous plates. A plate-specific SCA scheme is derived for the first time and features two key elements: (i) an offline-online strategy that combines Green's functions with k-means data compression, and (ii) an online self-consistent update that exploits the weak sensitivity of the reference medium. The framework handles both linear and nonlinear problems in classical plate theory and first-order shear deformation theory, and its performance is verified on linear isotropic perforated plates and woven composites, as well as on non-linear elasto-plastic perforated plates and woven composites with damage. Across all cases the proposed model matches the accuracy of FFT-based direct numerical simulation while reducing computational cost by over an order of magnitude.</p></details> |  |
| **[Multi-field decomposed hyper-reduced order modeling of damage-plasticity simulations](http://arxiv.org/abs/2508.19957v1)** | 2025-08-27 | <details><summary>Show</summary><p>This paper presents a multi-field decomposed approach for hyper-reduced order modeling to overcome the limitations of traditional model reduction techniques for gradient-extended damage-plasticity simulations. The discrete empirical interpolation method (DEIM) and the energy-conserving sampling and weighting method (ECSW) are extended to account for the multi-field nature of the problem. Both methods yield stable reduced order simulations, while significantly reducing the computational cost compared to full-order simulations. Two numerical examples are presented to demonstrate the performance and limitations of the proposed approaches. The decomposed ECSW method has overall higher accuracy and lower computational cost than the decomposed DEIM method.</p></details> |  |
| **[Predicting Forced Responses of Probability Distributions via the Fluctuation-Dissipation Theorem and Generative Modeling](http://arxiv.org/abs/2504.13333v2)** | 2025-08-27 | <details><summary>Show</summary><p>We present a novel and flexible data-driven framework for estimating the response of higher-order moments of nonlinear stochastic systems to small external perturbations. The classical Generalized Fluctuation--Dissipation Theorem (GFDT) links the unperturbed steady-state distribution to the system's linear response. While standard implementations relying on Gaussian approximations can predict the mean response, they often fail to capture changes in higher-order moments. To overcome this, we combine GFDT with score-based generative modeling to estimate the system's score function directly from data. We demonstrate the framework's versatility by employing two complementary score estimation techniques tailored to the system's characteristics: (i) a clustering-based algorithm (KGMM) for systems with low-dimensional effective dynamics, and (ii) a denoising score matching method implemented with a U-Net architecture for high-dimensional, spatially-extended systems where reduced-order modeling is not feasible. Our method is validated on several stochastic models relevant to climate dynamics: three reduced-order models of increasing complexity and a 2D Navier--Stokes model representing a turbulent flow with a localized perturbation. In all cases, the approach accurately captures strongly nonlinear and non-Gaussian features of the system's response, significantly outperforming traditional Gaussian approximations.</p></details> |  |
| **[Controlling instability in the Vlasov-Poisson system through moment-based optimization](http://arxiv.org/abs/2508.18412v1)** | 2025-08-25 | <details><summary>Show</summary><p>Controlling instability in plasma is one of the central challenges in fusion energy research. Among the various sources of instability, kinetic effects play a significant role. In this work, we aim to suppress the instability induced by kinetic effects by designing an external electric field. However, rather than directly solving the full kinetic Vlasov-Poisson system, we focus on a reduced-order model, specifically the moment-based system, to capture the underlying dynamics. This approach is motivated by the desire to reduce the computational cost associated with repeatedly solving the high-dimensional kinetic equations during the optimization of the electric field. Additionally, moment-based data is more readily accessible in practice, making a moment-based control framework more adaptable to data-driven scenarios. We investigate the effectiveness of moment-based control both analytically and numerically, by comparing it to control based on the full kinetic model.</p></details> |  |
| **[Generalizations of data-driven balancing: What to sample for different balancing-based reduced models](http://arxiv.org/abs/2312.12561v2)** | 2025-08-25 | <details><summary>Show</summary><p>The quadrature-based balanced truncation (QuadBT) framework of arXiv:2104.01006 is a non-intrusive reformulation of balanced truncation (BT), a classical projection-based model-order reduction technique for linear systems. QuadBT is non-intrusive in the sense that it builds approximate balanced truncation reduced-order models entirely from system response data, e.g., transfer function measurements, without the need to reference an explicit state-space realization of the underlying full-order model. In this work, we generalize the QuadBT framework to other types of balanced truncation model reduction. Namely, we show what transfer function data are required to compute data-driven reduced models by balanced stochastic truncation, positive-real balanced truncation, and bounded-real balanced truncation. In each case, these data are evaluations of particular spectral factors associated with the system of interest. These results lay the theoretical foundation for data-driven reformulations of the aforementioned BT variants. Although it is not yet clear how to compute or obtain these spectral factor data in a practical real-world setting, examples using synthetic (numerically evaluated) transfer function data are included to validate the data-based reduced models.</p></details> | 16 pages, 3 figures |
| **[DesCartes Builder: A Tool to Develop Machine-Learning Based Digital Twins](http://arxiv.org/abs/2508.17988v1)** | 2025-08-25 | <details><summary>Show</summary><p>Digital twins (DTs) are increasingly utilized to monitor, manage, and optimize complex systems across various domains, including civil engineering. A core requirement for an effective DT is to act as a fast, accurate, and maintainable surrogate of its physical counterpart, the physical twin (PT). To this end, machine learning (ML) is frequently employed to (i) construct real-time DT prototypes using efficient reduced-order models (ROMs) derived from high-fidelity simulations of the PT's nominal behavior, and (ii) specialize these prototypes into DT instances by leveraging historical sensor data from the target PT. Despite the broad applicability of ML, its use in DT engineering remains largely ad hoc. Indeed, while conventional ML pipelines often train a single model for a specific task, DTs typically require multiple, task- and domain-dependent models. Thus, a more structured approach is required to design DTs. In this paper, we introduce DesCartes Builder, an open-source tool to enable the systematic engineering of ML-based pipelines for real-time DT prototypes and DT instances. The tool leverages an open and flexible visual data flow paradigm to facilitate the specification, composition, and reuse of ML models. It also integrates a library of parameterizable core operations and ML algorithms tailored for DT design. We demonstrate the effectiveness and usability of DesCartes Builder through a civil engineering use case involving the design of a real-time DT prototype to predict the plastic strain of a structure.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 4 figures. Accepted at EDTconf 2025</p></details> |
| **[Enhancing material behavior discovery using embedding-oriented Physically-Guided Neural Networks with Internal Variables](http://arxiv.org/abs/2508.00959v2)** | 2025-08-25 | <details><summary>Show</summary><p>Physically Guided Neural Networks with Internal Variables are SciML tools that use only observable data for training and and have the capacity to unravel internal state relations. They incorporate physical knowledge both by prescribing the model architecture and using loss regularization, thus endowing certain specific neurons with a physical meaning as internal state variables. Despite their potential, these models face challenges in scalability when applied to high-dimensional data such as fine-grid spatial fields or time-evolving systems. In this work, we propose some enhancements to the PGNNIV framework that address these scalability limitations through reduced-order modeling techniques. Specifically, we introduce alternatives to the original decoder structure using spectral decomposition, POD, and pretrained autoencoder-based mappings. These surrogate decoders offer varying trade-offs between computational efficiency, accuracy, noise tolerance, and generalization, while improving drastically the scalability. Additionally, we integrate model reuse via transfer learning and fine-tuning strategies to exploit previously acquired knowledge, supporting efficient adaptation to novel materials or configurations, and significantly reducing training time while maintaining or improving model performance. To illustrate these various techniques, we use a representative case governed by the nonlinear diffusion equation, using only observable data. Results demonstrate that the enhanced PGNNIV framework successfully identifies the underlying constitutive state equations while maintaining high predictive accuracy. It also improves robustness to noise, mitigates overfitting, and reduces computational demands. The proposed techniques can be tailored to various scenarios depending on data availability, resources, and specific modeling objectives, overcoming scalability challenges in all the scenarios.</p></details> |  |
| **[First and Second Order Optimal $\mathcal{H}_2$ Model Reduction for Linear Continuous-Time Systems](http://arxiv.org/abs/2508.17503v1)** | 2025-08-24 | <details><summary>Show</summary><p>In this paper, we investigate the optimal $\mathcal{H}_2$ model reduction problem for single-input single-output (SISO) continuous-time linear time-invariant (LTI) systems. A semi-definite relaxation (SDR) approach is proposed to determine globally optimal interpolation points, providing an effective way to compute the reduced-order models via Krylov projection-based methods. In contrast to iterative approaches, we use the controllability Gramian and the moment-matching conditions to recast the model reduction problem as a convex optimization by introducing an upper bound $\gamma$ to minimize the $\mathcal{H}_2$ norm of the model reduction error system. We also prove that the relaxation is exact for first order reduced models and demonstrate, through examples, that it is exact for second order reduced models. We compare the performance of our proposed method with other iterative approaches and shift-selection methods on examples. Importantly, our approach also provides a means to verify the global optimality of known locally convergent methods.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, CDC conference</p></details> |
| **[Learning Spatio-Temporal Dynamics via Operator-Valued RKHS and Kernel Koopman Methods](http://arxiv.org/abs/2508.18307v1)** | 2025-08-23 | <details><summary>Show</summary><p>We introduce a unified framework for learning the spatio-temporal dynamics of vector valued functions by combining operator valued reproducing kernel Hilbert spaces (OV-RKHS) with kernel based Koopman operator methods. The approach enables nonparametric and data driven estimation of complex time evolving vector fields while preserving both spatial and temporal structure. We establish representer theorems for time dependent OV-RKHS interpolation, derive Sobolev type approximation bounds for smooth vector fields, and provide spectral convergence guarantees for kernel Koopman operator approximations. This framework supports efficient reduced order modeling and long term prediction of high dimensional nonlinear systems, offering theoretically grounded tools for forecasting, control, and uncertainty quantification in spatio-temporal machine learning.</p></details> |  |
| **[Stabilization of Parabolic Time-Varying PDEs using Certified Reduced-Order Receding Horizon Control](http://arxiv.org/abs/2508.16801v1)** | 2025-08-22 | <details><summary>Show</summary><p>We address the stabilization of linear, time-varying parabolic PDEs using finite-dimensional receding horizon controls (RHCs) derived from reduced-order models (ROMs). We first prove exponential stability and suboptimality of the continuous-time full-order model (FOM) RHC scheme in Hilbert spaces. A Galerkin model reduction is then introduced, along with a rigorous a posteriori error analysis for the associated finite-horizon optimal control problems. This results in a ROM-based RHC algorithm that adaptively constructs reduced-order controls, ensuring exponential stability of the FOM closed-loop state and providing computable performance bounds with respect to the infinite-horizon FOM control problem. Numerical experiments with a non-smooth cost functional involving the squared l1-norm confirm the methods effectiveness, even for exponentially unstable systems.</p></details> |  |
| **[Power-Series Approach to Moment-Matching-Based Model Reduction of MIMO Polynomial Nonlinear Systems](http://arxiv.org/abs/2508.13595v1)** | 2025-08-19 | <details><summary>Show</summary><p>The model reduction problem for high-order multi-input, multi-output (MIMO) polynomial nonlinear systems based on moment matching is addressed. The technique of power-series decomposition is exploited: this decomposes the solution of the nonlinear PDE characterizing the center manifold into the solutions of a series of recursively defined Sylvester equations. This approach allows yielding nonlinear reduced-order models in very much the same way as in the linear case (e.g. analytically). Algorithms are proposed for obtaining the order and the parameters of the reduced-order models with precision of degree $\kappa$. The approach also provides new insights into the nonlinear moment matching problem: first, a lower bound for the order of the reduced-order model is obtained, which, in the MIMO case, can be strictly less than the number of matched moments; second, it is revealed that the lower bound is affected by the ratio of the number of the input and output channels; third, it is shown that under mild conditions, a nonlinear reduced-order model can always be constructed with either a linear state equation or a linear output equation.</p></details> |  |
| **[Reduced-order modeling of Hamiltonian dynamics based on symplectic neural networks](http://arxiv.org/abs/2508.11911v1)** | 2025-08-16 | <details><summary>Show</summary><p>We introduce a novel data-driven symplectic induced-order modeling (ROM) framework for high-dimensional Hamiltonian systems that unifies latent-space discovery and dynamics learning within a single, end-to-end neural architecture. The encoder-decoder is built from Henon neural networks (HenonNets) and may be augmented with linear SGS-reflector layers. This yields an exact symplectic map between full and latent phase spaces. Latent dynamics are advanced by a symplectic flow map implemented as a HenonNet. This unified neural architecture ensures exact preservation of the underlying symplectic structure at the reduced-order level, significantly enhancing the fidelity and long-term stability of the resulting ROM. We validate our method through comprehensive numerical experiments on canonical Hamiltonian systems. The results demonstrate the method's capability for accurate trajectory reconstruction, robust predictive performance beyond the training horizon, and accurate Hamiltonian preservation. These promising outcomes underscore the effectiveness and potential applicability of our symplectic ROM framework for complex dynamical systems across a broad range of scientific and engineering disciplines.</p></details> |  |
| **[Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](http://arxiv.org/abs/2508.11542v1)** | 2025-08-15 | <details><summary>Show</summary><p>This paper presents a data-driven, nested Operator Inference (OpInf) approach for learning physics-informed reduced-order models (ROMs) from snapshot data of high-dimensional dynamical systems. The approach exploits the inherent hierarchy within the reduced space to iteratively construct initial guesses for the OpInf learning problem that prioritize the interactions of the dominant modes. The initial guess computed for any target reduced dimension corresponds to a ROM with provably smaller or equal snapshot reconstruction error than with standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from previously learned models, enabling versatile application scenarios involving dynamic basis and model form updates. We demonstrate the performance of our algorithm on a cubic heat conduction problem, with nested OpInf achieving a four times smaller error than standard OpInf at a comparable offline time. Further, we apply nested OpInf to a large-scale, parameterized model of the Greenland ice sheet where, despite model form approximation errors, it learns a ROM with, on average, 3% error and computational speed-up factor above 19,000.</p></details> |  |
| **[Efficient data-driven regression for reduced-order modeling of spatial pattern formation](http://arxiv.org/abs/2508.06833v1)** | 2025-08-09 | <details><summary>Show</summary><p>We present an efficient data-driven regression approach for constructing reduced-order models (ROMs) of reaction-diffusion systems exhibiting pattern formation. The ROMs are learned non-intrusively from available training data of physically accurate numerical simulations. The method can be applied to general nonlinear systems through the use of polynomial model form, while not requiring knowledge of the underlying physical model, governing equations, or numerical solvers. The process of learning ROMs is posed as a low-cost least-squares problem in a reduced-order subspace identified via Proper Orthogonal Decomposition (POD). Numerical experiments on classical pattern-forming systems--including the Schnakenberg and Mimura--Tsujikawa models--demonstrate that higher-order surrogate models significantly improve prediction accuracy while maintaining low computational cost. The proposed method provides a flexible, non-intrusive model reduction framework, well suited for the analysis of complex spatio-temporal pattern formation phenomena.</p></details> |  |
| **[Adaptive Collocation Point Strategies For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method](http://arxiv.org/abs/2501.07700v4)** | 2025-08-07 | <details><summary>Show</summary><p>Physics-informed neural networks (PINNs) have gained significant attention for solving forward and inverse problems related to partial differential equations (PDEs). While advancements in loss functions and network architectures have improved PINN accuracy, the impact of collocation point sampling on their performance remains underexplored. Fixed sampling methods, such as uniform random sampling and equispaced grids, can fail to capture critical regions with high solution gradients, limiting their effectiveness for complex PDEs. Adaptive methods, inspired by adaptive mesh refinement from traditional numerical methods, address this by dynamically updating collocation points during training but may overlook residual dynamics between updates, potentially losing valuable information. To overcome this limitation, we propose two adaptive collocation point selection strategies utilizing the QR Discrete Empirical Interpolation Method (QR-DEIM), a reduced-order modeling technique for efficiently approximating nonlinear functions. Our results on benchmark PDEs demonstrate that our QR-DEIM-based approaches improve PINN accuracy compared to existing methods, offering a promising direction for adaptive collocation point strategies.</p></details> |  |
| **[Convolutional autoencoders for the reconstruction of three-dimensional interfacial multiphase flows](http://arxiv.org/abs/2508.04084v1)** | 2025-08-06 | <details><summary>Show</summary><p>In this work, we perform a comprehensive investigation of autoencoders for reduced-order modeling of three-dimensional multiphase flows. Focusing on the accuracy of reconstructing multiphase flow volume/mass fractions with a standard convolutional architecture, we examine the advantages and disadvantages of different interface representation choices (diffuse, sharp, level set). We use a combination of synthetic data with non-trivial interface topologies and high-resolution simulation data of multiphase homogeneous isotropic turbulence for training and validation. This study clarifies the best practices for reducing the dimensionality of multiphase flows via autoencoders. Consequently, this paves the path for uncoupling the training of autoencoders for accurate reconstruction and the training of temporal or input/output models such as neural operators (e.g., FNOs, DeepONets) and neural ODEs on the lower-dimensional latent space given by the autoencoders. As such, the implications of this study are significant and of interest to the multiphase flow community and beyond.</p></details> |  |
| **[POD-based reduced order modeling of global-in-time iterative decoupled algorithms for Biot's consolidation model](http://arxiv.org/abs/2508.04082v1)** | 2025-08-06 | <details><summary>Show</summary><p>This paper focuses on the efficient numerical algorithms of a three-field Biot's consolidation model. The approach begins with the introduction of innovative monolithic and global-in-time iterative decoupled algorithms, which incorporate the backward differentiation formulas for time discretization. In each iteration, these algorithms involve solving a diffusion subproblem over the entire temporal domain, followed by solving a generalized Stokes subproblem over the same time interval. To accelerate the global-in-time iterative process, we present a reduced order modeling approach based on proper orthogonal decomposition, aimed at reducing the primary computational cost from the generalized Stokes subproblem. The effectiveness of this novel method is validated both theoretically and through numerical experiments.</p></details> |  |
| **[A parameterized Wasserstein Hamiltonian flow approach for solving the Schrödinger equation](http://arxiv.org/abs/2505.11762v2)** | 2025-08-05 | <details><summary>Show</summary><p>In this paper, we propose a new method to compute the solution of time-dependent Schr\"odinger equation (TDSE). Using push-forward maps and Wasserstein Hamiltonian flow, we reformulate the TDSE as a Hamiltonian system in terms of push-forward maps. The new formulation can be viewed as a generative model in the Wasserstein space, which is a manifold of probability density functions. Then we parameterize the push-forward maps by reduce-order models such as neural networks. This induces a new metric in the parameter space by pulling back the Wasserstein metric on density manifold, which further results in a system of ordinary differential equations (ODEs) for the parameters of the reduce-order model. Leveraging the computational techniques from deep learning, such as Neural ODE, we design an algorithm to solve the TDSE in the parameterized push-forward map space, which provides an alternative approach with the potential to scale up to high-dimensional problems. Several numerical examples are presented to demonstrate the performance of this algorithm.</p></details> |  |
| **[Reduced Order Data-driven Twin Models for Nonlinear PDEs by Randomized Koopman Orthogonal Decomposition and Explainable Deep Learning](http://arxiv.org/abs/2508.03325v1)** | 2025-08-05 | <details><summary>Show</summary><p>This study introduces a data-driven twin modeling framework based on modern Koopman operator theory, offering a significant advancement over classical modal decomposition by accurately capturing nonlinear dynamics with reduced complexity and no manual parameter adjustment. The method integrates a novel algorithm with Pareto front analysis to construct a compact, high-fidelity reduced-order model that balances accuracy and efficiency. An explainable NLARX deep learning framework enables real-time, adaptive calibration and prediction, while a key innovation-computing orthogonal Koopman modes via randomized orthogonal projections-ensures optimal data representation. This approach for data-driven twin modeling is fully self-consistent, avoiding heuristic choices and enhancing interpretability through integrated explainable learning techniques. The proposed method is demonstrated on shock wave phenomena using three experiments of increasing complexity, accompanied by a qualitative analysis of the resulting data-driven twin models.</p></details> | 34 pages, 9 figures |
| **[Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization](http://arxiv.org/abs/2508.02953v1)** | 2025-08-04 | <details><summary>Show</summary><p>Contact-rich problems, such as snake robot locomotion, offer unexplored yet rich opportunities for optimization-based trajectory and acyclic contact planning. So far, a substantial body of control research has focused on emulating snake locomotion and replicating its distinctive movement patterns using shape functions that either ignore the complexity of interactions or focus on complex interactions with matter (e.g., burrowing movements). However, models and control frameworks that lie in between these two paradigms and are based on simple, fundamental rigid body dynamics, which alleviate the challenging contact and control allocation problems in snake locomotion, remain absent. This work makes meaningful contributions, substantiated by simulations and experiments, in the following directions: 1) introducing a reduced-order model based on Moreau's stepping-forward approach from differential inclusion mathematics, 2) verifying model accuracy, 3) experimental validation.</p></details> |  |
| **[Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots](http://arxiv.org/abs/2508.06538v1)** | 2025-08-04 | <details><summary>Show</summary><p>Reduced-order models are essential for motion planning and control of quadruped robots, as they simplify complex dynamics while preserving critical behaviors. This paper introduces a novel methodology for deriving such interpretable dynamic models, specifically for jumping. We capture the high-dimensional, nonlinear jumping dynamics in a low-dimensional latent space by proposing a learning architecture combining Sparse Identification of Nonlinear Dynamics (SINDy) with physical structural priors on the jump dynamics. Our approach demonstrates superior accuracy to the traditional actuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through simulation and hardware experiments across different jumping strategies.</p></details> | <details><summary>8 pag...</summary><p>8 pages, under review</p></details> |
| **[Model reduction for fully nonlinear stochastic systems](http://arxiv.org/abs/2508.02263v1)** | 2025-08-04 | <details><summary>Show</summary><p>This paper presents a novel model order reduction framework tailored for fully nonlinear stochastic dynamics without lifting them to quadratic systems and without using linearization techniques. By directly leveraging structural properties of the nonlinearities -- such as local and one-sided Lipschitz continuity or one-sided linear growth conditions -- the approach defines generalized reachability and observability Gramians through Lyapunov-type differential operators. These Gramians enable projection-based reduction while preserving essential dynamics and stochastic characteristics. The paper provides sufficient conditions for the existence of these Gramians, including a Lyapunov-based mean square stability criterion, and derives explicit output error bounds for the reduced order models. Furthermore, the work introduces a balancing and truncation procedure for obtaining reduced systems and demonstrates how dominant subspaces can be identified from the spectrum of the Gramians. The theoretical findings are grounded in rigorous stochastic analysis, extending balanced truncation techniques to a broad class of nonlinear systems under stochastic excitation.</p></details> |  |
| **[Low-dimensional observer design for stable linear systems by model reduction](http://arxiv.org/abs/2508.00609v1)** | 2025-08-01 | <details><summary>Show</summary><p>This paper presents a low-dimensional observer design for stable, single-input single-output, continuous-time linear time-invariant (LTI) systems. Leveraging the model reduction by moment matching technique, we approximate the system with a reduced-order model. Based on this reduced-order model, we design a low-dimensional observer that estimates the states of the original system. We show that this observer establishes exact asymptotic state reconstruction for a given class of inputs tied to the observer's dimension. Furthermore, we establish an exponential input-to-state stability property for generic inputs, ensuring a bounded estimation error. Numerical simulations confirm the effectiveness of the approach for a benchmark model reduction problem.</p></details> |  |
| **[PySHRED: A Python package for SHallow REcurrent Decoding for sparse sensing, model reduction and scientific discovery](http://arxiv.org/abs/2507.20954v1)** | 2025-07-28 | <details><summary>Show</summary><p>SHallow REcurrent Decoders (SHRED) provide a deep learning strategy for modeling high-dimensional dynamical systems and/or spatiotemporal data from dynamical system snapshot observations. PySHRED is a Python package that implements SHRED and several of its major extensions, including for robust sensing, reduced order modeling and physics discovery. In this paper, we introduce the version 1.0 release of PySHRED, which includes data preprocessors and a number of cutting-edge SHRED methods specifically designed to handle real-world data that may be noisy, multi-scale, parameterized, prohibitively high-dimensional, and strongly nonlinear. The package is easy to install, thoroughly-documented, supplemented with extensive code examples, and modularly-structured to support future additions. The entire codebase is released under the MIT license and is available at https://github.com/pyshred-dev/pyshred.</p></details> | 15 pages, 9 figures |
| **[Efficient Adjoint Petrov-Galerkin Reduced Order Models for fluid flows governed by the incompressible Navier-Stokes equations](http://arxiv.org/abs/2507.20739v1)** | 2025-07-28 | <details><summary>Show</summary><p>This research paper investigates the Adjoint Petrov-Galerkin (APG) method for reduced order models (ROM) and fluid dynamics governed by the incompressible Navier-Stokes equations. The Adjoint Petrov-Galerkin ROM, derived using the Mori-Zwanzig formalism, demonstrates superior accuracy and stability compared to standard Galerkin ROMs. However, challenges arise due to the time invariance of the test basis vectors, resulting in high computational requirements. To address this, we introduce a new efficient Adjoint Petrov-Galerkin (eAPG) ROM formulation, extending its application to the incompressible Navier-Stokes equations by exploiting the polynomial structure inherent in these equations. The offline and online phases partition eliminates the need for repeated test basis vector evaluations. This improves computational efficiency in comparison to the general Adjoint Petrov-Galerkin ROM formulation. A novel approach to augmenting the memory length, a critical factor influencing the stability and accuracy of the APG-ROM, is introduced, employing a data-driven optimization. Numerical results for the 3D turbulent flow around a circular cylinder demonstrate the efficacy of the proposed approach. Error measures and computational cost evaluations, considering metrics such as floating point operations and simulation time, provide a comprehensive analysis.</p></details> |  |
| **[Symmetry-reduced model reduction of shift-equivariant systems via operator inference](http://arxiv.org/abs/2507.18780v1)** | 2025-07-24 | <details><summary>Show</summary><p>We consider data-driven reduced-order models of partial differential equations with shift equivariance. Shift-equivariant systems typically admit traveling solutions, and the main idea of our approach is to represent the solution in a traveling reference frame, in which it can be described by a relatively small number of basis functions. Existing methods for operator inference allow one to approximate a reduced-order model directly from data, without knowledge of the full-order dynamics. Our method adds additional terms to ensure that the reduced-order model not only approximates the spatially frozen profile of the solution, but also estimates the traveling speed as a function of that profile. We validate our approach using the Kuramoto-Sivashinsky equation, a one-dimensional partial differential equation that exhibits traveling solutions and spatiotemporal chaos. Results indicate that our method robustly captures traveling solutions, and exhibits improved numerical stability over the standard operator inference approach.</p></details> | <details><summary>30 pa...</summary><p>30 pages, 7 figures. Orally presented at the SIAM Conference on Applications of Dynamical Systems (SIAM DS25). Submitted to Advances in Computational Mathematics (ACOM)</p></details> |
| **[Data-Driven Model Order Reduction for Continuous- and Discrete-Time Nonlinear Systems](http://arxiv.org/abs/2507.18131v1)** | 2025-07-24 | <details><summary>Show</summary><p>Model order reduction simplifies high-dimensional dynamical systems by deriving lower-dimensional models that preserve essential system characteristics. These techniques are crucial to controller design for complex systems while significantly reducing computational costs. Nevertheless, constructing effective reduced-order models (ROMs) poses considerable challenges, particularly for dynamical systems characterized by highly nonlinear terms. These challenges are further exacerbated when the actual system model is unavailable, a scenario frequently encountered in real-world applications. In this work, we propose a data-driven framework for the construction of ROMs for both continuous- and discrete-time nonlinear dynamical systems with unknown mathematical models. By leveraging two sets of data collected from the system, referred to as two input-state trajectories, we first construct a data-based closed-loop representation of the system. We then establish a similarity relation between the output trajectories of the original system and those of its data-driven ROM employing the notion of simulation functions (SFs), thereby enabling a formal characterization of their closeness. To achieve this, we propose data-dependent semidefinite programs as sufficient conditions to simultaneously construct both ROMs and SFs, while offering correctness guarantees. We demonstrate that the obtained data-driven ROMs can be employed for synthesizing controllers that ensure the unknown system satisfies high-level logic properties. This is accomplished by first designing controllers for the data-driven ROMs and then translating the results back to the original system through an interface function. We evaluate the efficacy of our data-driven findings through four benchmark case studies involving unknown dynamics with highly nonlinear terms.</p></details> |  |
| **[Inverse scattering for Schrödinger equation in the frequency domain via data-driven reduced order modeling](http://arxiv.org/abs/2503.11034v2)** | 2025-07-23 | <details><summary>Show</summary><p>In this paper we develop a numerical method for solving an inverse scattering problem of estimating the scattering potential in a Schr\"{o}dinger equation from frequency domain measurements based on reduced order models (ROM). The ROM is a projection of Schr\"{o}dinger operator onto a subspace spanned by its solution snapshots at certain wavenumbers. Provided the measurements are performed at these wavenumbers, the ROM can be constructed in a data-driven manner from the measurements on a surface surrounding the scatterers. Once the ROM is computed, the scattering potential can be estimated using non-linear optimization that minimizes the ROM misfit. Such an approach typically outperforms the conventional methods based on data misfit minimization. We develop two variants of ROM-based algorithms for inverse scattering and test them on a synthetic example in two spatial dimensions.</p></details> |  |
| **[A reduced-order model for segregated fluid-structure interaction solvers based on an ALE approach](http://arxiv.org/abs/2305.13613v3)** | 2025-07-23 | <details><summary>Show</summary><p>This article presents a Galerkin projection-based reduced-order modelling (ROM) approach for segregated fluid-structure interaction (FSI) problems, formulated within an Arbitrary Lagrangian Eulerian (ALE) framework at low Reynolds numbers using the Finite Volume Method (FVM). The ROM is constructed using Proper Orthogonal Decomposition (POD) and incorporates a data-driven technique that combines classical Galerkin projection with radial basis function (RBF) networks. The results demonstrate the numerical stability and accuracy of the proposed method relative to the high-fidelity model. The ROM successfully captures transient flow fields and, importantly, the forces acting on the moving structure without exhibiting unphysical growth or divergence over time. This is further supported by the bounded evolution of error metrics and physical observables, which remain consistent with the full-order simulations throughout the prediction horizon. The method's effectiveness is validated through a benchmark vortex-induced vibration (VIV) case involving a circular cylinder at Reynolds number Re=200. The hybrid ROM approach yields an accurate and efficient tool for solving FSI problems involving mesh motion.</p></details> |  |
| **[Modeling Advection-Dominated Flows with Space-Local Reduced-Order Models](http://arxiv.org/abs/2409.08793v2)** | 2025-07-22 | <details><summary>Show</summary><p>Reduced-order models (ROMs) are often used to accelerate the simulation of large physical systems. However, traditional ROM techniques, such as those based on proper orthogonal decomposition (POD), often struggle with advection-dominated flows due to the slow singular value decay. This results in high computational costs and potential instabilities. This paper proposes a novel approach using space-local POD to address the challenges arising from the slow singular value decay. Instead of global basis functions, our method employs local basis functions that are applied across the domain, analogous to the finite element method, but with a data-driven basis. By dividing the domain into subdomains and applying the space-local POD, we achieve a representation that is sparse and that generalizes better outside the training regime. This allows the use of a larger number of basis functions compared to standard POD, without prohibitive computational costs. To ensure smoothness across subdomain boundaries, we introduce overlapping subdomains inspired by the partition of unity method. Our approach is validated through simulations of the 1D and 2D advection equation. We demonstrate that using our space-local approach we obtain a ROM that generalizes better to flow conditions which are not part of the training data. In addition, we show that the constructed ROM inherits the energy conservation and non-linear stability properties from the full-order model. Finally, we find that using a space-local ROM allows for larger time steps.</p></details> | <details><summary>30 pa...</summary><p>30 pages, 13 figures, source code can be found at https://github.com/tobyvg/local_POD_overlap.jl</p></details> |
| **[Blending data and physics for reduced-order modeling of systems with spatiotemporal chaotic dynamics](http://arxiv.org/abs/2507.21299v1)** | 2025-07-21 | <details><summary>Show</summary><p>While data-driven techniques are powerful tools for reduced-order modeling of systems with chaotic dynamics, great potential remains for leveraging known physics (i.e. a full-order model (FOM)) to improve predictive capability. We develop a hybrid reduced order model (ROM), informed by both data and FOM, for evolving spatiotemporal chaotic dynamics on an invariant manifold whose coordinates are found using an autoencoder. This approach projects the vector field of the FOM onto the invariant manifold; then, this physics-derived vector field is either corrected using dynamic data, or used as a Bayesian prior that is updated with data. In both cases, the neural ordinary differential equation approach is used. We consider simulated data from the Kuramoto-Sivashinsky and complex Ginzburg-Landau equations. Relative to the data-only approach, for scenarios of abundant data, scarce data, and even an incorrect FOM (i.e. erroneous parameter values), the hybrid approach yields substantially improved time-series predictions.</p></details> |  |
| **[Is memory all you need? Data-driven Mori-Zwanzig modeling of Lagrangian particle dynamics in turbulent flows](http://arxiv.org/abs/2507.16058v1)** | 2025-07-21 | <details><summary>Show</summary><p>The dynamics of Lagrangian particles in turbulence play a crucial role in mixing, transport, and dispersion processes in complex flows. Their trajectories exhibit highly non-trivial statistical behavior, motivating the development of surrogate models that can reproduce these trajectories without incurring the high computational cost of direct numerical simulations of the full Eulerian field. This task is particularly challenging because reduced-order models typically lack access to the full set of interactions with the underlying turbulent field. Novel data-driven machine learning techniques can be very powerful in capturing and reproducing complex statistics of the reduced-order/surrogate dynamics. In this work, we show how one can learn a surrogate dynamical system that is able to evolve a turbulent Lagrangian trajectory in a way that is point-wise accurate for short-time predictions (with respect to Kolmogorov time) and stable and statistically accurate at long times. This approach is based on the Mori--Zwanzig formalism, which prescribes a mathematical decomposition of the full dynamical system into resolved dynamics that depend on the current state and the past history of a reduced set of observables and the unresolved orthogonal dynamics due to unresolved degrees of freedom of the initial state. We show how by training this reduced order model on a point-wise error metric on short time-prediction, we are able to correctly learn the dynamics of the Lagrangian turbulence, such that also the long-time statistical behavior is stably recovered at test time. This opens up a range of new applications, for example, for the control of active Lagrangian agents in turbulence.</p></details> |  |
| **[Data-Driven Reduced-Order Models for Port-Hamiltonian Systems with Operator Inference](http://arxiv.org/abs/2501.02183v2)** | 2025-07-18 | <details><summary>Show</summary><p>Hamiltonian operator inference has been developed in [Sharma, H., Wang, Z., Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn structure-preserving reduced-order models (ROMs) for Hamiltonian systems. The method constructs a low-dimensional model using only data and knowledge of the functional form of the Hamiltonian. The resulting ROMs preserve the intrinsic structure of the system, ensuring that the mechanical and physical properties of the system are maintained. In this work, we extend this approach to port-Hamiltonian systems, which generalize Hamiltonian systems by including energy dissipation, external input, and output. Based on snapshots of the system's state and output, together with the information about the functional form of the Hamiltonian, reduced operators are inferred through optimization and are then used to construct data-driven ROMs. To further alleviate the complexity of evaluating nonlinear terms in the ROMs, a hyper-reduction method via discrete empirical interpolation is applied. Accordingly, we derive error estimates for the ROM approximations of the state and output. Finally, we demonstrate the structure preservation, as well as the accuracy of the proposed port-Hamiltonian operator inference framework, through numerical experiments on a linear mass-spring-damper problem and a nonlinear Toda lattice problem.</p></details> | 28 pages, 13 figures |
| **[RONOM: Reduced-Order Neural Operator Modeling](http://arxiv.org/abs/2507.12814v1)** | 2025-07-17 | <details><summary>Show</summary><p>Time-dependent partial differential equations are ubiquitous in physics-based modeling, but they remain computationally intensive in many-query scenarios, such as real-time forecasting, optimal control, and uncertainty quantification. Reduced-order modeling (ROM) addresses these challenges by constructing a low-dimensional surrogate model but relies on a fixed discretization, which limits flexibility across varying meshes during evaluation. Operator learning approaches, such as neural operators, offer an alternative by parameterizing mappings between infinite-dimensional function spaces, enabling adaptation to data across different resolutions. Whereas ROM provides rigorous numerical error estimates, neural operator learning largely focuses on discretization convergence and invariance without quantifying the error between the infinite-dimensional and the discretized operators. This work introduces the reduced-order neural operator modeling (RONOM) framework, which bridges concepts from ROM and operator learning. We establish a discretization error bound analogous to those in ROM, and get insights into RONOM's discretization convergence and discretization robustness. Moreover, two numerical examples are presented that compare RONOM to existing neural operators for solving partial differential equations. The results demonstrate that RONOM using standard vector-to-vector neural networks achieves comparable performance in input generalization and superior performance in both spatial super-resolution and discretization robustness, while also offering novel insights into temporal super-resolution scenarios.</p></details> |  |
| **[Non-intrusive model reduction of advection-dominated hyperbolic problems using neural network shift augmented manifold transformation](http://arxiv.org/abs/2407.18419v3)** | 2025-07-15 | <details><summary>Show</summary><p>Advection-dominated problems are predominantly noticed in nature, engineering systems, and various industrial processes. Traditional linear compression methods, such as proper orthogonal decomposition (POD) and reduced basis (RB) methods are ill-suited for these problems, due to slow Kolmogorov $n$-width decay. This results in inefficient and inaccurate reduced order models (ROMs). There are few non-linear approaches to accelerate the Kolmogorov $n$-width decay. In this work, we use a neural network shift augmented transformation technique that employs automatic shift detection. This approach leverages a deep-learning framework to derive a parameter-dependent mapping between the original manifold $\mathcal{M}$ and the transformed manifold $\tilde{\mathcal{M}}$. We apply a linear compression method to obtain a low-dimensional linear approximation subspace of the transformed manifold $\tilde{\mathcal{M}}$. Furthermore, we construct non-intrusive reduced order models on the resulting transformed linear approximation subspace and employ automatic shift detection for predictions in the online stage. We propose a complete framework, the neural network shift-augmented proper orthogonal decomposition-based reduced order model (NNsPOD-ROM) algorithm, comprising both offline and online stages for model reduction of advection-dominated problems. We test our proposed methodology on numerous experiments to evaluate its performance on the 1D linear advection equation, a higher order method benchmark case - the 2D isentropic convective vortex, and 2D two-phase flow.</p></details> | 22 pages, 19 Figures |
| **[Adaptive Reduced Basis Trust Region Methods for Parabolic Inverse Problems](http://arxiv.org/abs/2507.11130v1)** | 2025-07-15 | <details><summary>Show</summary><p>We consider nonlinear inverse problems arising in the context of parameter identification for parabolic partial differential equations (PDEs). For stable reconstructions, regularization methods such as the iteratively regularized Gauss-Newton method (IRGNM) are commonly used, but their application is computationally demanding due to the high-dimensional nature of PDE discretizations. To address this bottleneck, we propose a reduced-order modeling approach that accelerates both the state and adjoint evaluations required for derivative-based optimization. Our method builds on the recent contribution [Kartmann et al. Adaptive reduced basis trust region methods for parameter identification problems. Comput. Sci. Eng. 1, 3 (2024)] for elliptic forward operators and constructs the reduced forward operator adaptively in an online fashion, combining both parameter and state space reduction. To ensure reliability, we embed the IRGNM iteration within an adaptive, error-aware trust-region framework that certifies the accuracy of the reduced-order approximations. We demonstrate the effectiveness of the proposed approach through numerical results for both time-dependent and time-independent parameter identification problems in dynamic reaction-diffusion systems. The implementation is made available for reproducibility and further use.</p></details> | 40 pages, 12 figures |
| **[New Feedback Control and Adaptive Evolve-Filter-Relax Regularization for the Navier-Stokes Equations in the Convection-Dominated Regime](http://arxiv.org/abs/2307.00675v2)** | 2025-07-10 | <details><summary>Show</summary><p>We propose, analyze, and investigate numerically a novel feedback control strategy for high Reynolds number flows. For both the continuous and the discrete (finite element) settings, we prove that the new strategy yields accurate results for high Reynolds numbers that were not covered by current results. We also show that the new feedback control yields more accurate results than the current control approaches in marginally-resolved numerical simulations of a two-dimensional flow past a circular cylinder at Reynolds numbers $Re=1000$. We note, however, that for realistic control parameters, the stabilizing effect of the new feedback control strategy is not sufficient in the convection-dominated regime. Our second contribution is the development of an adaptive evolve-filter-relax (aEFR) regularization that stabilizes marginally-resolved simulations in the convection-dominated regime and increases the accuracy of the new feedback control in realistic parameter settings. For the finite element setting, we prove that the novel feedback control equipped with the new aEFR method yields accurate results for high Reynolds numbers. Furthermore, our numerical investigation shows that the new strategy yields accurate results for reduced order models that dramatically decrease the size of the feedback control problem.</p></details> |  |
| **[Towards an Efficient Shifted Cholesky QR for Applications in Model Order Reduction using pyMOR](http://arxiv.org/abs/2507.07788v1)** | 2025-07-10 | <details><summary>Show</summary><p>Many model order reduction (MOR) methods rely on the computation of an orthonormal basis of a subspace onto which the large full order model is projected. Numerically, this entails the orthogonalization of a set of vectors. The nature of the MOR process imposes several requirements for the orthogonalization process. Firstly, MOR is oftentimes performed in an adaptive or iterative manner, where the quality of the reduced order model, i.e., the dimension of the reduced subspace, is decided on the fly. Therefore, it is important that the orthogonalization routine can be executed iteratively. Secondly, one possibly has to deal with high-dimensional arrays of abstract vectors that do not allow explicit access to entries, making it difficult to employ so-called `orthogonal triangularization algorithms' such as Householder QR. For these reasons, (modified) Gram-Schmidt-type algorithms are commonly used in MOR applications. These methods belong to the category of `triangular orthogonalization' algorithms that do not rely on elementwise access to the vectors and can be easily updated. Recently, algorithms like shifted Cholesky QR have gained attention. These also belong to the aforementioned category and have proven their aptitude for MOR algorithms in previous studies. A key benefit of these methods is that they are communication-avoiding, leading to vastly superior performance on memory-bandwidth-limited problems and parallel or distributed architectures. This work formulates an efficient updating scheme for Cholesky QR algorithms and proposes an improved shifting strategy for highly ill-conditioned matrices. The proposed algorithmic extensions are validated with numerical experiments on a laptop and computation server.</p></details> | Preprint |
| **[Sparsity-Promoting Dynamic Mode Decomposition Applied to Sea Surface Temperature Fields](http://arxiv.org/abs/2507.05711v2)** | 2025-07-09 | <details><summary>Show</summary><p>In this paper, we leverage Koopman mode decomposition to analyze the nonlinear and high-dimensional climate systems acting on the observed data space. The dynamics of atmospheric systems are assumed to be equation-free, with the linear evolution of observables derived from measured historical long-term time-series data snapshots, such as monthly sea surface temperature records, to construct a purely data-driven climate dynamics. In particular, sparsity-promoting dynamic mode decomposition is exploited to extract the dominant spatial and temporal modes, which are among the most significant coherent structures underlying climate variability, enabling a more efficient, interpretable, and low-dimensional representation of the system dynamics. We hope that the combined use of Koopman modes and sparsity-promoting techniques will provide insights into the significant climate modes, enabling reduced-order modeling of the climate system and offering a potential framework for predicting and controlling weather and climate variability.</p></details> | 8 pages |
| **[A Generalized $\ell_1$-Merit Function SQP Method Using Function Approximations with Tunable Accuracy](http://arxiv.org/abs/2507.06199v1)** | 2025-07-08 | <details><summary>Show</summary><p>This paper develops a generalization of the line-search sequential quadratic programming (SQP) algorithm with $\ell_1$-merit function that uses objective and constraint function approximations with tunable accuracy to solve smooth equality-constrained optimization problems. The evaluation of objective and constraint functions and their gradients is potentially computationally expensive, but it is assumed that one can construct effective, computationally inexpensive models of these functions. This paper specifies how these models can be used to generate new iterates. At each iteration, the models have to satisfy function error and relative gradient error tolerances determined by the algorithm based on its progress. Moreover, bounds for the model errors are used to explore regions where the combined objective function and constraint models are sufficiently accurate. The algorithm has the same first-order global convergence properties as a line-search SQP algorithm with $\ell_1$-merit function, but only uses objective and constraint function models and the model error bounds. The algorithm is applied to a discretized boundary control problem in which the evaluation of the objective and constraint functions requires the solution of the Boussinesq partial differential equation (PDE). The models are constructed from projection-based reduced-order models of the Boussinesq PDE.</p></details> |  |
| **[Model order reduction techniques for the stochastic finite volume method](http://arxiv.org/abs/2507.05091v1)** | 2025-07-07 | <details><summary>Show</summary><p>The stochastic finite volume method (SFV method) is a high-order accurate method for uncertainty quantification (UQ) in hyperbolic conservation laws. However, the computational cost of SFV method increases for high-dimensional stochastic parameter spaces due to the curse of dimensionality. To address this challenge, we incorporate interpolation-based reduced order modeling (ROM) techniques that reduce the cost of computing stochastic integrals in SFV method. Further efficiency gains are achieved through a Q-DEIM hyper-reduction method. Numerical experiments suggest that this approach can lower both computational cost and memory requirements for high-dimensional stochastic parameter spaces.</p></details> | 20 pages, 8 figures |
| **[Physics-Informed Graph Neural Networks to Reconstruct Local Fields Considering Finite Strain Hyperelasticity](http://arxiv.org/abs/2507.05291v1)** | 2025-07-05 | <details><summary>Show</summary><p>We propose a physics-informed machine learning framework called P-DivGNN to reconstruct local stress fields at the micro-scale, in the context of multi-scale simulation given a periodic micro-structure mesh and mean, macro-scale, stress values. This method is based in representing a periodic micro-structure as a graph, combined with a message passing graph neural network. We are able to retrieve local stress field distributions, providing average stress values produced by a mean field reduced order model (ROM) or Finite Element (FE) simulation at the macro-scale. The prediction of local stress fields are of utmost importance considering fracture analysis or the definition of local fatigue criteria. Our model incorporates physical constraints during training to constraint local stress field equilibrium state and employs a periodic graph representation to enforce periodic boundary conditions. The benefits of the proposed physics-informed GNN are evaluated considering linear and non linear hyperelastic responses applied to varying geometries. In the non-linear hyperelastic case, the proposed method achieves significant computational speed-ups compared to FE simulation, making it particularly attractive for large-scale applications.</p></details> | <details><summary>28 pa...</summary><p>28 pages, 17 figures, pre-print</p></details> |
| **[Identifying Large-Scale Linear Parameter Varying Systems with Dynamic Mode Decomposition Methods](http://arxiv.org/abs/2502.02336v2)** | 2025-07-04 | <details><summary>Show</summary><p>Linear Parameter Varying (LPV) Systems are a well-established class of nonlinear systems with a rich theory for stability analysis, control, and analytical response finding, among other aspects. Although there are works on data-driven identification of such systems, the literature is quite scarce in terms of works that tackle the identification of LPV models for large-scale systems. Since large-scale systems are ubiquitous in practice, this work develops a methodology for the local and global identification of large-scale LPV systems based on nonintrusive reduced-order modeling. The developed method is coined as DMD-LPV for being inspired in the Dynamic Mode Decomposition (DMD). To validate the proposed identification method, we identify a system described by a discretized linear diffusion equation, with the diffusion gain defined by a polynomial over a parameter. The experiments show that the proposed method can easily identify a reduced-order LPV model of a given large-scale system without the need to perform identification in the full-order dimension, and with almost no performance decay over performing a reduction, given that the model structure is well-established.</p></details> | <details><summary>45 pa...</summary><p>45 pages, 9 figures. Submitted to Journal of Computational Physics</p></details> |
| **[An Adaptive Port Technique for Synthesising Rotational Components in Component Modal Synthesis Approaches](http://arxiv.org/abs/2507.03276v1)** | 2025-07-04 | <details><summary>Show</summary><p>Component Modal Synthesis (CMS) is a reduced order modelling method widely used for large-scale complex systems. It can effectively approximate system-level models through component synthesis, in which the repetitive geometrical components are modelled once and synthesised together. However, the conventional CMS only applies to systems with stationary components connected by strictly compatible ports, limiting it from modelling systems with moving components. This paper presents an adaptive port (AP) technique to extend CMS approaches for modelling parametric systems with rotational parts. To demonstrate the capability of the AP technique, we apply it to the Static Condensation Reduced Basis Element (SCRBE), one widely used variant of CMS approaches. The AP-based SCRBE (AP-SCRBE) can enforce the synthesis of rotational-stationary components over a shared adaptive port when the connecting surfaces of two components are discretisation-wise incompatible, which happens when one component moves relative to the others. Numerical experiments on the NREL 5MW wind turbine show that, in the context of rotational-stationary component synthesis, the AP-SCRBE can accurately and efficiently model the rotating rotor with pitch rotation of blades. It can produce almost identical results to a high-fidelity finite element model at two to three orders faster speeds.</p></details> |  |
| **[Real-time prediction of plasma instabilities with sparse-grid-accelerated optimized dynamic mode decomposition](http://arxiv.org/abs/2507.03245v1)** | 2025-07-04 | <details><summary>Show</summary><p>Parametric data-driven reduced-order models (ROMs) that embed dependencies in a large number of input parameters are crucial for enabling many-query tasks in large-scale problems. These tasks, including design optimization, control, and uncertainty quantification, are essential for developing digital twins in real-world applications. However, standard training data generation methods are computationally prohibitive due to the curse of dimensionality, as their cost scales exponentially with the number of inputs.This paper investigates efficient training of parametric data-driven ROMs using sparse grid interpolation with (L)-Leja points, specifically targeting scenarios with higher-dimensional input parameter spaces. (L)-Leja points are nested and exhibit slow growth, resulting in sparse grids with low cardinality in low-to-medium dimensional settings, making them ideal for large-scale, computationally expensive problems. Focusing on gyrokinetic simulations of plasma micro-instabilities in fusion experiments as a representative real-world application, we construct parametric ROMs for the full 5D gyrokinetic distribution function via optimized dynamic mode decomposition (optDMD) and sparse grids based on (L)-Leja points. We perform detailed experiments in two scenarios: First, the Cyclone Base Case benchmark assesses optDMD ROM prediction capabilities beyond training time horizons and across variations in the binormal wave number. Second, for a real-world electron temperature gradient driven micro-instability simulation featuring six input parameters, we demonstrate that an accurate parametric optDMD ROM can be constructed at a cost of only $28$ high-fidelity gyrokinetic simulations thanks to sparse grids. In the broader context of fusion research, these results demonstrate the potential of sparse grid-based parametric ROMs to enable otherwise intractable many-query tasks.</p></details> | <details><summary>28 pa...</summary><p>28 pages, 14 figures, 8 tables</p></details> |
| **[Ensemble Kalman Filter for Data Assimilation coupled with low-resolution computations techniques applied in Fluid Dynamics](http://arxiv.org/abs/2507.00539v2)** | 2025-07-02 | <details><summary>Show</summary><p>This paper presents an innovative Reduced-Order Model (ROM) for merging experimental and simulation data using Data Assimilation (DA) to estimate the "True" state of a fluid dynamics system, leading to more accurate predictions. Our methodology introduces a novel approach implementing the Ensemble Kalman Filter (EnKF) within a reduced-dimensional framework, grounded in a robust theoretical foundation and applied to fluid dynamics. To address the substantial computational demands of DA, the proposed ROM employs low-resolution (LR) techniques to drastically reduce computational costs. This approach involves downsampling datasets for DA computations, followed by an advanced reconstruction technique based on low-cost Singular Value Decomposition (lcSVD). The lcSVD method, a key innovation in this paper, has never been applied to DA before and offers a highly efficient way to enhance resolution with minimal computational resources. Our results demonstrate significant reductions in both computation time and RAM usage through the LR techniques without compromising the accuracy of the estimations. For instance, in a turbulent test case, the LR approach with a compression rate of 15.9 can achieve a speed-up of 13.7 and a RAM compression of 90.9% while maintaining a low Relative Root Mean Square Error (RRMSE) of 2.6%, compared to 0.8% in the high-resolution (HR) reference. Furthermore, we highlight the effectiveness of the EnKF in estimating and predicting the state of fluid flow systems based on limited observations and low-fidelity numerical data. This paper highlights the potential of the proposed DA method in fluid dynamics applications, particularly for improving computational efficiency in CFD and related fields. Its ability to balance accuracy with low computational and memory costs makes it suitable for large-scale and real-time applications, such as environmental monitoring or aerospace.</p></details> | <details><summary>artic...</summary><p>article, 49 pages, 29 figures, 4 tables</p></details> |
| **[High order global flux schemes for general steady state preservation of shallow water moment equations with non-conservative products](http://arxiv.org/abs/2507.00573v1)** | 2025-07-01 | <details><summary>Show</summary><p>Shallow water moment equations are reduced-order models for free-surface flows that allow to represent vertical variations of the velocity profile at the expense of additional evolution equations for a number of additional variables, so called moments. This introduces non-linear non-conservative products in the system, which make the analytical characterization of steady states much harder if not impossible. The lack of analytical steady states poses a challenge for the design of well-balanced schemes, which aim at preserving such steady states as crucial in many applications. In this work, we present a family of fully well-balanced, high-order WENO finite volume methods for general hyperbolic balance laws with non-conservative products like the shallow water moment equations, for which no analytical steady states are available. The schemes are based on the flux globalization approach, in which both source terms and non-conservative products are integrated with a tailored high order quadrature in the divergence term. The resulting global flux is then reconstructed instead of the conservative variables to preserve all steady states. Numerical tests show the optimal convergence of the method and a significant error reduction for steady state solutions. Furthermore, we provide a numerical comparison of perturbed steady states for different families of shallow water moment equations, which illustrates the flexibility of our method that is valid for general equations without prior knowledge of steady states.</p></details> |  |
| **[Augmented Physics-Based Li-ion Battery Model via Adaptive Ensemble Sparse Learning and Conformal Prediction](http://arxiv.org/abs/2507.00353v1)** | 2025-07-01 | <details><summary>Show</summary><p>Accurate electrochemical models are essential for the safe and efficient operation of lithium-ion batteries in real-world applications such as electrified vehicles and grid storage. Reduced-order models (ROM) offer a balance between fidelity and computational efficiency but often struggle to capture complex and nonlinear behaviors, such as the dynamics in the cell voltage response under high C-rate conditions. To address these limitations, this study proposes an Adaptive Ensemble Sparse Identification (AESI) framework that enhances the accuracy of reduced-order li-ion battery models by compensating for unpredictable dynamics. The approach integrates an Extended Single Particle Model (ESPM) with an evolutionary ensemble sparse learning strategy to construct a robust hybrid model. In addition, the AESI framework incorporates a conformal prediction method to provide theoretically guaranteed uncertainty quantification for voltage error dynamics, thereby improving the reliability of the model's predictions. Evaluation across diverse operating conditions shows that the hybrid model (ESPM + AESI) improves the voltage prediction accuracy, achieving mean squared error reductions of up to 46% on unseen data. Prediction reliability is further supported by conformal prediction, yielding statistically valid prediction intervals with coverage ratios of 96.85% and 97.41% for the ensemble models based on bagging and stability selection, respectively.</p></details> |  |
| **[Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations](http://arxiv.org/abs/2507.00301v1)** | 2025-06-30 | <details><summary>Show</summary><p>This work presents structure-preserving Lift & Learn, a scientific machine learning method that employs lifting variable transformations to learn structure-preserving reduced-order models for nonlinear partial differential equations (PDEs) with conservation laws. We propose a hybrid learning approach based on a recently developed energy-quadratization strategy that uses knowledge of the nonlinearity at the PDE level to derive an equivalent quadratic lifted system with quadratic system energy. The lifted dynamics obtained via energy quadratization are linear in the old variables, making model learning very effective in the lifted setting. Based on the lifted quadratic PDE model form, the proposed method derives quadratic reduced terms analytically and then uses those derived terms to formulate a constrained optimization problem to learn the remaining linear reduced operators in a structure-preserving way. The proposed hybrid learning approach yields computationally efficient quadratic reduced-order models that respect the underlying physics of the high-dimensional problem. We demonstrate the generalizability of quadratic models learned via the proposed structure-preserving Lift & Learn method through three numerical examples: the one-dimensional wave equation with exponential nonlinearity, the two-dimensional sine-Gordon equation, and the two-dimensional Klein-Gordon-Zakharov equations. The numerical results show that the proposed learning approach is competitive with the state-of-the-art structure-preserving data-driven model reduction method in terms of both accuracy and computational efficiency.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2503.02273</p></details> |
| **[Online model learning with data-assimilated reservoir computers](http://arxiv.org/abs/2504.16767v2)** | 2025-06-30 | <details><summary>Show</summary><p>We propose an online learning framework for forecasting nonlinear spatio-temporal signals (fields). The method integrates (i) dimensionality reduction, here, a simple proper orthogonal decomposition (POD) projection; (ii) a generalized autoregressive model to forecast reduced dynamics, here, a reservoir computer; (iii) online adaptation to update the reservoir computer (the model), here, ensemble sequential data assimilation. We demonstrate the framework on a wake past a cylinder governed by the Navier-Stokes equations, exploring the assimilation of full flow fields (projected onto POD modes) and sparse sensors. Three scenarios are examined: a na\"ive physical state estimation; a two-fold estimation of physical and reservoir states; and a three-fold estimation that also adjusts the model parameters. The two-fold strategy significantly improves ensemble convergence and reduces reconstruction error compared to the na\"ive approach. The three-fold approach enables robust online training of partially-trained reservoir computers, overcoming limitations of a priori training. By unifying data-driven reduced order modelling with Bayesian data assimilation, this work opens new opportunities for scalable online model learning for nonlinear time series forecasting.</p></details> | 8 pages, 5 figures |
| **[Cost-effective Reduced-Order Modeling via Bayesian Active Learning](http://arxiv.org/abs/2506.22645v1)** | 2025-06-27 | <details><summary>Show</summary><p>Machine Learning surrogates have been developed to accelerate solving systems dynamics of complex processes in different science and engineering applications. To faithfully capture governing systems dynamics, these methods rely on large training datasets, hence restricting their applicability in real-world problems. In this work, we propose BayPOD-AL, an active learning framework based on an uncertainty-aware Bayesian proper orthogonal decomposition (POD) approach, which aims to effectively learn reduced-order models from high-fidelity full-order models representing complex systems. Experimental results on predicting the temperature evolution over a rod demonstrate BayPOD-AL's effectiveness in suggesting the informative data and reducing computational cost related to constructing a training dataset compared to other uncertainty-guided active learning strategies. Furthermore, we demonstrate BayPOD-AL's generalizability and efficiency by evaluating its performance on a dataset of higher temporal resolution than the training dataset.</p></details> |  |
| **[Surrogate normal-forms for the numerical bifurcation and stability analysis of navier-stokes flows via machine learning](http://arxiv.org/abs/2506.21275v1)** | 2025-06-26 | <details><summary>Show</summary><p>Inspired by the Equation-Free multiscale modeling approach, we demonstrate how the embed-learn-lift framework enables the construction of surrogate normal-forms, namely minimal-dimensional reduced-order models (ROMs), from high-fidelity Navier-Stokes simulations. These surrogate models are then used for efficient and accurate bifurcation and stability analysis. The framework proceeds in four steps. First, manifold learning reveals the intrinsic latent dimension of the high-dimensional spatio-temporal Navier-Stokes dynamics across parameter space. Second, we construct low-dimensional "normal-form" like ROMs on this latent space using Gaussian Process Regression (GPR), capturing the emergent dynamics. Third, using these models, we apply numerical bifurcation tools to compute bifurcation diagrams and perform stability analysis in the latent space. This includes tracing branches of limit cycles arising from Andronov-Hopf bifurcations - tasks intractable in full space due to computational cost. Finally, solving the pre-image problem allows reconstruction of the bifurcation structure in the original high-dimensional space. We demonstrate the methodology on two canonical flows: wake flow past an infinite circular cylinder and planar sudden-expansion channel flow. These exhibit Andronov-Hopf and pitchfork bifurcations, respectively, as Reynolds number increases. Our method identifies the latent dimensionality and constructs GPR-based surrogate normal-forms that enable the tracing and stability analysis of bifurcating solutions, including limit cycles, their period, and stability via Floquet multipliers.</p></details> | 26 pages, 14 figures |
| **[Exact operator inference with minimal data](http://arxiv.org/abs/2506.01244v2)** | 2025-06-26 | <details><summary>Show</summary><p>This work introduces a novel method to generate snapshot data for operator inference that guarantees the exact reconstruction of intrusive projection-based reduced-order models (ROMs). To ensure exact reconstruction, the operator inference least squares matrix must have full rank, without regularization. Existing works have achieved this full rank using heuristic strategies to generate snapshot data and a-posteriori checks on full rank, but without a guarantee of success. Our novel snapshot data generation method provides this guarantee thanks to two key ingredients: first we identify ROM states that induce full rank, then we generate snapshots corresponding to exactly these states by simulating multiple trajectories for only a single time step. This way, the number of required snapshots is minimal and orders of magnitude lower than typically reported with existing methods. The method avoids non-Markovian terms and does not require re-projection. Since the number of snapshots is minimal, the least squares problem simplifies to a linear system that is numerically more stable. In addition, because the inferred operators are exact, properties of the intrusive ROM operators such as symmetry or skew-symmetry are preserved. Numerical results for differential equations involving 2nd, 3rd and 8th order polynomials demonstrate that the novel snapshot data generation method leads to exact reconstruction of the intrusive reduced order models.</p></details> |  |
| **[Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems](http://arxiv.org/abs/2505.00460v2)** | 2025-06-25 | <details><summary>Show</summary><p>In situations where the solution of a high-fidelity dynamical system needs to be evaluated repeatedly, over a vast pool of parametric configurations and in absence of access to the underlying governing equations, data-driven model reduction techniques are preferable. We propose a novel active learning approach to build a parametric data-driven reduced-order model (ROM) by greedily picking the most important parameter samples from the parameter domain. As a result, during the ROM construction phase, the number of high-fidelity solutions dynamically grow in a principled fashion. The high-fidelity solution snapshots are expressed in several parameter-specific linear subspaces, with the help of proper orthogonal decomposition (POD), and the relative distance between these subspaces is used as a guiding mechanism to perform active learning. For successfully achieving this, we provide a distance measure to evaluate the similarity between pairs of linear subspaces with different dimensions, and also show that this distance measure is a metric. The usability of the proposed subspace-distance-enabled active learning (SDE-AL) framework is demonstrated by augmenting two existing non-intrusive reduced-order modeling approaches, and providing their active-learning-driven (ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN. Furthermore, we report positive results for two parametric physical models, highlighting the efficiency of the proposed SDE-AL approach.</p></details> | <details><summary>31 pa...</summary><p>31 pages, 10 figures, 4 tables; v2: minor improvements</p></details> |
| **[A parametric tensor ROM for the shallow water dam break problem](http://arxiv.org/abs/2506.20007v1)** | 2025-06-24 | <details><summary>Show</summary><p>We develop a variant of a tensor reduced-order model (tROM) for the parameterized shallow-water dam-break problem. This hyperbolic system presents multiple challenges for model reduction, including a slow decay of the Kolmogorov $N$-width of the solution manifold, shock formation, and the loss of smooth solution dependence on parameters. These issues limit the performance of traditional Proper Orthogonal Decomposition based ROMs. Our tROM approach, based on a low-rank tensor decomposition, builds a parameter-to-solution map from high-fidelity snapshots and constructs localized reduced bases via a local POD procedure. We apply this method to both dry-bed and wet-bed problem setups, showing that the non-interpolatory variant of the tROM, combined with Chebyshev sampling near critical parameter values, effectively captures parameter-dependent behavior and significantly outperforms standard POD-ROMs. This is especially evident in the wet-bed case, where POD-ROMs exhibit poor resolution of shock waves and spurious oscillations.</p></details> |  |
| **[Model Reduction of a Flexible Nonsmooth Oscillator Recovers its Entire Bifurcation Structure](http://arxiv.org/abs/2311.17947v4)** | 2025-06-19 | <details><summary>Show</summary><p>We study the reduced order modeling of a piecewise-linear, globally nonlinear flexible oscillator in which a Bernoulli-Euler beam is subjected to a position-triggered kick force and a piecewise restoring force at its tip. The nonsmooth boundary conditions, which determine different regions of a hybrid phase space, can generally be expected to excite many degrees of freedom. With kick strength as parameter, the system's bifurcation diagram is found to exhibit a range of periodic and chaotic behaviors. Proper orthogonal decomposition (POD) is used to obtain a single set of global basis functions spanning all of the hybrid regions. The reduced order model (ROM) dimension is chosen using previously developed energy closure analysis, ensuring approximate energy balance on the reduced subspace. This yields accurate ROMs with 8 degrees of freedom. Remarkably, we find that ROMs formulated using using data from individual periodic steady states can nevertheless be used to reconstruct the entire bifurcation structure of the original system without updating. This demonstrates that, despite being constructed with steady state data, the ROMs model sufficiently small transients with enough accuracy to permit using simple continuation for the bifurcation diagram. We also find ROM subspaces obtained for different values of the bifurcation parameter are essentially identical. Thus, POD augmented with energy closure analysis is found to reliably yield effective dimension estimates and ROMs for this nonlinear, nonsmooth system that are robust across stability transitions, including even period doubling cascades to chaos, thereby greatly reducing data requirements and computational costs.</p></details> | 32 pages, 8 figures |
| **[Reduced-order modeling for Ablowitz-Ladik equation](http://arxiv.org/abs/2207.11130v2)** | 2025-06-19 | <details><summary>Show</summary><p>In this paper, reduced-order models (ROMs) are constructed for the Ablowitz-Ladik equation (ALE), an integrable semi-discretization of the nonlinear Schr\"odinger equation (NLSE) with and without damping. Both ALEs are non-canonical conservative and dissipative Hamiltonian systems with the Poisson matrix depending quadratically on the state variables, and with quadratic Hamiltonian. The full-order solutions are obtained with the energy preserving midpoint rule for the conservative ALE and exponential midpoint rule for the dissipative ALE. The reduced-order solutions are constructed intrusively by preserving the skew-symmetric structure of the reduced non-canonical Hamiltonian system by applying proper orthogonal decomposition (POD) with the Galerkin projection. For an efficient offline-online decomposition of the ROMs, the quadratic nonlinear terms of the Poisson matrix are approximated by the discrete empirical interpolation method (DEIM). The computation of the reduced-order solutions is further accelerated by the use of tensor techniques. Preservation of the Hamiltonian and momentum for the conservative ALE, and preservation of dissipation properties of the dissipative ALE, guarantee the long-term stability of soliton solutions.</p></details> |  |
| **[Investigating Lagrangian Neural Networks for Infinite Horizon Planning in Quadrupedal Locomotion](http://arxiv.org/abs/2506.16079v1)** | 2025-06-19 | <details><summary>Show</summary><p>Lagrangian Neural Networks (LNNs) present a principled and interpretable framework for learning the system dynamics by utilizing inductive biases. While traditional dynamics models struggle with compounding errors over long horizons, LNNs intrinsically preserve the physical laws governing any system, enabling accurate and stable predictions essential for sustainable locomotion. This work evaluates LNNs for infinite horizon planning in quadrupedal robots through four dynamics models: (1) full-order forward dynamics (FD) training and inference, (2) diagonalized representation of Mass Matrix in full order FD, (3) full-order inverse dynamics (ID) training with FD inference, (4) reduced-order modeling via torso centre-of-mass (CoM) dynamics. Experiments demonstrate that LNNs bring improvements in sample efficiency (10x) and superior prediction accuracy (up to 2-10x) compared to baseline methods. Notably, the diagonalization approach of LNNs reduces computational complexity while retaining some interpretability, enabling real-time receding horizon control. These findings highlight the advantages of LNNs in capturing the underlying structure of system dynamics in quadrupeds, leading to improved performance and efficiency in locomotion planning and control. Additionally, our approach achieves a higher control frequency than previous LNN methods, demonstrating its potential for real-world deployment on quadrupeds.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 5 figures, Accepted at Advances in Robotics (AIR) Conference 2025</p></details> |

## Dynamical System
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Neural CRNs: A Natural Implementation of Learning in Chemical Reaction Networks](http://arxiv.org/abs/2409.00034v4)** | 2025-09-08 | <details><summary>Show</summary><p>Molecular circuits capable of autonomous learning could unlock novel applications in fields such as bioengineering and synthetic biology. To this end, existing chemical implementations of neural computing have mainly relied on emulating discrete-layered neural architectures using steady-state computations of mass action kinetics. In contrast, we propose an alternative dynamical systems-based approach in which neural computations are modeled as the time evolution of molecular concentrations. The analog nature of our framework naturally aligns with chemical kinetics-based computation, leading to more compact circuits. We present the advantages of our framework through three key demonstrations. First, we assemble an end-to-end supervised learning pipeline using only two sequential phases, the minimum required number for supervised learning. Then, we show (through appropriate simplifications) that both linear and nonlinear modeling circuits can be implemented solely using unimolecular and bimolecular reactions, avoiding the complexities of higher-order chemistries. Finally, we demonstrate that first-order gradient approximations can be natively incorporated into the framework, enabling nonlinear models to scale linearly rather than combinatorially with input dimensionality. All the circuit constructions are validated through training and inference simulations across various regression and classification tasks. Our work presents a viable pathway toward embedding learning behaviors in synthetic biochemical systems.</p></details> |  |
| **[Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model](http://arxiv.org/abs/2505.10438v3)** | 2025-09-08 | <details><summary>Show</summary><p>Gas turbine engines are complex and highly nonlinear dynamical systems. Deriving their physics-based models can be challenging because it requires performance characteristics that are not always available, often leading to many simplifying assumptions. This paper discusses the limitations of conventional experimental methods used to derive component-level and locally linear parameter-varying models, and addresses these issues by employing identification techniques based on data collected from standard engine operation under closed-loop control. The rotor dynamics are estimated using the sparse identification of nonlinear dynamics. Subsequently, the autonomous part of the dynamics is mapped into an optimally constructed Koopman eigenfunction space. This process involves eigenvalue optimization using metaheuristic algorithms and temporal projection, followed by gradient-based eigenfunction identification. The resulting Koopman model is validated against an in-house reference component-level model. A globally optimal nonlinear feedback controller and a Kalman estimator are then designed within the eigenfunction space and compared to traditional and gain-scheduled proportional-integral controllers, as well as a proposed internal model control approach. The eigenmode structure enables targeting individual modes during optimization, leading to improved performance tuning. Results demonstrate that the Koopman-based controller surpasses other benchmark controllers in both reference tracking and disturbance rejection under sea-level and varying flight conditions, due to its global nature.</p></details> | <details><summary>34 pa...</summary><p>34 pages, 28 figures Under review at Springer Nonlinear Dynamics</p></details> |
| **[Identifiability and Maximum Likelihood Estimation for System Identification of Networks of Dynamical Systems](http://arxiv.org/abs/2506.20628v3)** | 2025-09-08 | <details><summary>Show</summary><p>In this paper we investigate identifiability and maximum likelihood estimation for direct system identification of networks of dynamical systems. We provide necessary and sufficient conditions for network identifiability in terms of Gr\"obner bases. We show that the maximum likelihood approach is both consistent and efficient, which is in contrast to existing prediction error approaches. Moreover, our approach has wider applicability, i.e., it is applicable whenever network identifiability holds. Finally, we show that we can formulate the maximum likelihood problem without the use of a predictor, which is the key to numerically being able to solve it efficiently.</p></details> | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication. Submitted to IEEE Transactions on Automatic Control</p></details> |
| **[Parameter Robustness in Data-Driven Estimation of Dynamical Systems](http://arxiv.org/abs/2509.06534v1)** | 2025-09-08 | <details><summary>Show</summary><p>We study the robustness of system estimation to parametric perturbations in system dynamics and initial conditions. We define the problem of sensitivity-based parametric uncertainty quantification in dynamical system estimation. The main contribution of this paper is the development of a novel robustness metric for estimation of parametrized linear dynamical systems with and without control actions. For the computation of this metric, we delineate the uncertainty contributions arising from control actions, system dynamics, and initial conditions. Furthermore, to validate our theoretical findings, we establish connections between these new results and the existing literature on the robustness of model reduction. This work provides guidance for selecting estimation methods based on tolerable levels of parametric uncertainty and paves the way for new cost functions in data-driven estimation that reward sensitivity to a desired subset of parameters while penalizing others.</p></details> | <details><summary>Submi...</summary><p>Submitted for publication in the IEEE Conference on Decision and Control (CDC) 2025</p></details> |
| **[Gaussian behaviors: representations and data-driven control](http://arxiv.org/abs/2504.15838v2)** | 2025-09-08 | <details><summary>Show</summary><p>We propose a modeling framework for stochastic systems, termed Gaussian behaviors, that describes finite-length trajectories of a system as a Gaussian process. The proposed model naturally quantifies the uncertainty in the trajectories, yet it is simple enough to allow for tractable formulations. We relate the proposed model to existing descriptions of dynamical systems including deterministic and stochastic behaviors, and linear time-invariant (LTI) state-space models with Gaussian noise. Gaussian behaviors can be estimated directly from observed data as the empirical sample covariance. The distribution of future outputs conditioned on inputs and past outputs provides a predictive model that can be incorporated in predictive control frameworks. We show that subspace predictive control is a certainty-equivalence control formulation with the estimated Gaussian behavior. Furthermore, the regularized data-enabled predictive control (DeePC) method is shown to be a distributionally optimistic formulation that optimistically accounts for uncertainty in the Gaussian behavior. To mitigate the excessive optimism of DeePC, we propose a novel distributionally robust control formulation, and provide a convex reformulation allowing for efficient implementation.</p></details> | <details><summary>Exten...</summary><p>Extended version of the paper accepted to the 64th IEEE Conference on Decision and Control</p></details> |
| **[Predicting Steady-State Behavior in Complex Networks with Graph Neural Networks](http://arxiv.org/abs/2502.01693v3)** | 2025-09-08 | <details><summary>Show</summary><p>In complex systems, information propagation can be defined as diffused or delocalized, weakly localized, and strongly localized. This study investigates the application of graph neural network models to learn the behavior of a linear dynamical system on networks. A graph convolution and attention-based neural network framework has been developed to identify the steady-state behavior of the linear dynamical system. We reveal that our trained model distinguishes the different states with high accuracy. Furthermore, we have evaluated model performance with real-world data. In addition, to understand the explainability of our model, we provide an analytical derivation for the forward and backward propagation of our framework.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 15 figures (including Appendix)</p></details> |
| **[A High-order Backpropagation Algorithm for Neural Stochastic Differential Equation Model](http://arxiv.org/abs/2509.06292v1)** | 2025-09-08 | <details><summary>Show</summary><p>Neural stochastic differential equation model with a Brownian motion term can capture epistemic uncertainty of deep neural network from the perspective of a dynamical system. The goal of this paper is to improve the convergence rate of the sample-wise backpropagation algorithm in neural stochastic differential equation model which has been proposed in [Archibald et al., SIAM Journal on Numerical Analysis, 62 (2024), pp. 593-621]. It is necessary to emphasize that, improving the convergence order of the algorithm consisting of forward backward stochastic differential equations remains challenging, due to the loss of information of Z term in backward equations under sample-wise approximation and the limitations of the forward network form. In this paper, we develop a high-order backpropagation algorithm to improve the training accuracy. Under the convexity assumption, the result indicates that the first-order convergence is achieved when the number of training steps is proportional to the cubic number of layers. Finally, numerical examples illustrate our theoretical results.</p></details> | 23 pages, 4 figures |
| **[Statistical Inference for Misspecified Contextual Bandits](http://arxiv.org/abs/2509.06287v1)** | 2025-09-08 | <details><summary>Show</summary><p>Contextual bandit algorithms have transformed modern experimentation by enabling real-time adaptation for personalized treatment and efficient use of data. Yet these advantages create challenges for statistical inference due to adaptivity. A fundamental property that supports valid inference is policy convergence, meaning that action-selection probabilities converge in probability given the context. Convergence ensures replicability of adaptive experiments and stability of online algorithms. In this paper, we highlight a previously overlooked issue: widely used algorithms such as LinUCB may fail to converge when the reward model is misspecified, and such non-convergence creates fundamental obstacles for statistical inference. This issue is practically important, as misspecified models -- such as linear approximations of complex dynamic system -- are often employed in real-world adaptive experiments to balance bias and variance. Motivated by this insight, we propose and analyze a broad class of algorithms that are guaranteed to converge even under model misspecification. Building on this guarantee, we develop a general inference framework based on an inverse-probability-weighted Z-estimator (IPW-Z) and establish its asymptotic normality with a consistent variance estimator. Simulation studies confirm that the proposed method provides robust and data-efficient confidence intervals, and can outperform existing approaches that exist only in the special case of offline policy evaluation. Taken together, our results underscore the importance of designing adaptive algorithms with built-in convergence guarantees to enable stable experimentation and valid statistical inference in practice.</p></details> |  |
| **[Neural Port-Hamiltonian Differential Algebraic Equations for Compositional Learning of Electrical Networks](http://arxiv.org/abs/2412.11215v3)** | 2025-09-06 | <details><summary>Show</summary><p>We develop compositional learning algorithms for coupled dynamical systems, with a particular focus on electrical networks. While deep learning has proven effective at modeling complex relationships from data, compositional couplings between system components typically introduce algebraic constraints on state variables, posing challenges to many existing data-driven approaches to modeling dynamical systems. Towards developing deep learning models for constrained dynamical systems, we introduce neural port-Hamiltonian differential algebraic equations (N-PHDAEs), which use neural networks to parameterize unknown terms in both the differential and algebraic components of a port-Hamiltonian DAE. To train these models, we propose an algorithm that uses automatic differentiation to perform index reduction, automatically transforming the neural DAE into an equivalent system of neural ordinary differential equations (N-ODEs), for which established model inference and backpropagation methods exist. Experiments simulating the dynamics of nonlinear circuits exemplify the benefits of our approach: the proposed N-PHDAE model achieves an order of magnitude improvement in prediction accuracy and constraint satisfaction when compared to a baseline N-ODE over long prediction time horizons. We also validate the compositional capabilities of our approach through experiments on a simulated DC microgrid: we train individual N-PHDAE models for separate grid components, before coupling them to accurately predict the behavior of larger-scale networks.</p></details> |  |
| **[Select, then Balance: A Plug-and-Play Framework for Exogenous-Aware Spatio-Temporal Forecasting](http://arxiv.org/abs/2509.05779v1)** | 2025-09-06 | <details><summary>Show</summary><p>Spatio-temporal forecasting aims to predict the future state of dynamic systems and plays an important role in multiple fields. However, existing solutions only focus on modeling using a limited number of observed target variables. In real-world scenarios, exogenous variables can be integrated into the model as additional input features and associated with the target signal to promote forecast accuracy. Although promising, this still encounters two challenges: the inconsistent effects of different exogenous variables to the target system, and the imbalance effects between historical variables and future variables. To address these challenges, this paper introduces \model, a novel framework for modeling \underline{exo}genous variables in \underline{s}patio-\underline{t}emporal forecasting, which follows a ``select, then balance'' paradigm. Specifically, we first construct a latent space gated expert module, where fused exogenous information is projected into a latent space to dynamically select and recompose salient signals via specialized sub-experts. Furthermore, we design a siamese network architecture in which recomposed representations of past and future exogenous variables are fed into dual-branch spatio-temporal backbones to capture dynamic patterns. The outputs are integrated through a context-aware weighting mechanism to achieve dynamic balance during the modeling process. Extensive experiments on real-world datasets demonstrate the effectiveness, generality, robustness, and efficiency of our proposed framework.</p></details> | 16 pages, 11 figures |
| **[The Ground Cost for Optimal Transport of Angular Velocity](http://arxiv.org/abs/2504.03190v2)** | 2025-09-06 | <details><summary>Show</summary><p>We revisit the optimal transport problem over angular velocity dynamics given by the controlled Euler equation. The solution of this problem enables stochastic guidance of spin states of a rigid body (e.g., spacecraft) over a hard deadline constraint by transferring a given initial state statistics to a desired terminal state statistics. This is an instance of generalized optimal transport over a nonlinear dynamical system. While prior work has reported existence-uniqueness and numerical solution of this dynamical optimal transport problem, here we present structural results about the equivalent Kantorovich a.k.a. optimal coupling formulation. Specifically, we focus on deriving the ground cost for the associated Kantorovich optimal coupling formulation. The ground cost is equal to the cost of transporting unit amount of mass from a specific realization of the initial or source joint probability measure to a realization of the terminal or target joint probability measure, and determines the Kantorovich formulation. Finding the ground cost leads to solving a structured deterministic nonlinear optimal control problem, which is shown to be amenable to an analysis technique pioneered by Athans et al. We show that such techniques have broader applicability in determining the ground cost (thus Kantorovich formulation) for a class of generalized optimal mass transport problems involving nonlinear dynamics with translated norm-invariant drift.</p></details> |  |
| **[Flash STU: Fast Spectral Transform Units](http://arxiv.org/abs/2409.10489v5)** | 2025-09-06 | <details><summary>Show</summary><p>Recent advances in state-space model architectures have shown great promise for efficient sequence modeling, but challenges remain in balancing computational efficiency with model expressiveness. We propose the Flash STU architecture, a hybrid model that interleaves spectral state space model layers with sliding window attention, enabling scalability to billions of parameters for language modeling while maintaining a near-linear time complexity. We evaluate the Flash STU and its variants on diverse sequence prediction tasks, including linear dynamical systems, robotics control, and language modeling. We find that, given a fixed parameter budget, the Flash STU architecture consistently outperforms the Transformer and other leading state-space models such as S4 and Mamba-2.</p></details> |  |
| **[Robust Feedback Optimization with Model Uncertainty: A Regularization Approach](http://arxiv.org/abs/2503.24151v2)** | 2025-09-06 | <details><summary>Show</summary><p>Feedback optimization optimizes the steady state of a dynamical system by implementing optimization iterations in closed loop with the plant. It relies on online measurements and limited model information, namely, the input-output sensitivity. In practice, various issues including inaccurate modeling, lack of observation, or changing conditions can lead to sensitivity mismatches, causing closed-loop sub-optimality or even instability. To handle such uncertainties, we pursue robust feedback optimization, where we optimize the closed-loop performance against all possible sensitivities lying in specific uncertainty sets. We provide tractable reformulations for the corresponding min-max problems via regularizations and characterize the online closed-loop performance through the tracking error in case of time-varying optimal solutions. Simulations on a distribution grid illustrate the effectiveness of our robust feedback optimization controller in addressing sensitivity mismatches in a non-stationary environment.</p></details> | <details><summary>Proc....</summary><p>Proc. 64th IEEE Conference on Decision and Control</p></details> |
| **[Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities](http://arxiv.org/abs/2411.10868v5)** | 2025-09-05 | <details><summary>Show</summary><p>Social influence plays a significant role in shaping individual sentiments and actions, particularly in a world of ubiquitous digital interconnection. The rapid development of generative AI has engendered well-founded concerns regarding the potential scalable implementation of radicalization techniques in social media. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on a simple social network. We employ Taylor's classic model of social influence and tools from robust control theory (most notably the Dynamical Structure Function (DSF)), to identify perturbations that qualitatively alter the system's behavior while remaining as unobtrusive as possible. We examine two such scenarios: perturbations to an existing link and perturbations that introduce a new link to the network. In each case, we identify destabilizing perturbations of minimal norm and simulate their effects. Remarkably, we find that small but targeted alterations to network structure may lead to the radicalization of all agents, exhibiting the potential for large-scale shifts in collective behavior to be triggered by comparatively minuscule adjustments in social influence. Given that this method of identifying perturbations that are innocuous yet destabilizing applies to any suitable dynamical system, our findings emphasize a need for similar analyses to be carried out on real systems (e.g., real social networks), to identify the places where such dynamics may already exist.</p></details> |  |
| **[State Estimation for Linear Systems with Non-Gaussian Measurement Noise via Dynamic Programming](http://arxiv.org/abs/2509.05482v1)** | 2025-09-05 | <details><summary>Show</summary><p>We propose a new recursive estimator for linear dynamical systems under Gaussian process noise and non-Gaussian measurement noise. Specifically, we develop an approximate maximum a posteriori (MAP) estimator using dynamic programming and tools from convex analysis. Our approach does not rely on restrictive noise assumptions and employs a Bellman-like update instead of a Bayesian update. Our proposed estimator is computationally efficient, with only modest overhead compared to a standard Kalman filter. Simulations demonstrate that our estimator achieves lower root mean squared error (RMSE) than the Kalman filter and has comparable performance to state-of-the-art estimators, while requiring significantly less computational power.</p></details> |  |
| **[Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees](http://arxiv.org/abs/2508.21001v2)** | 2025-09-05 | <details><summary>Show</summary><p>Kinodynamic motion planning is concerned with computing collision-free trajectories while abiding by the robot's dynamic constraints. This critical problem is often tackled using sampling-based planners (SBPs) that explore the robot's high-dimensional state space by constructing a search tree via action propagations. Although SBPs can offer global guarantees on completeness and solution quality, their performance is often hindered by slow exploration due to uninformed action sampling. Learning-based approaches can yield significantly faster runtimes, yet they fail to generalize to out-of-distribution (OOD) scenarios and lack critical guarantees, e.g., safety, thus limiting their deployment on physical robots. We present Diffusion Tree (DiTree): a provably-generalizable framework leveraging diffusion policies (DPs) as informed samplers to efficiently guide state-space search within SBPs. DiTree combines DP's ability to model complex distributions of expert trajectories, conditioned on local observations, with the completeness of SBPs to yield provably-safe solutions within a few action propagation iterations for complex dynamical systems. We demonstrate DiTree's power with an implementation combining the popular RRT planner with a DP action sampler trained on a single environment. In comprehensive evaluations on OOD scenarios, DiTree achieves on average a 30% higher success rate compared to standalone DP or SBPs, on a dynamic car and Mujoco's ant robot settings (for the latter, SBPs fail completely). Beyond simulation, real-world car experiments confirm DiTree's applicability, demonstrating superior trajectory quality and robustness even under severe sim-to-real gaps. Project webpage: https://sites.google.com/view/ditree.</p></details> | <details><summary>Accep...</summary><p>Accepted to CoRL 2025, Project page: https://sites.google.com/view/ditree. v2: Abstract updated</p></details> |
| **[Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning](http://arxiv.org/abs/2509.05193v1)** | 2025-09-05 | <details><summary>Show</summary><p>Low-rank structure is a common implicit assumption in many modern reinforcement learning (RL) algorithms. For instance, reward-free and goal-conditioned RL methods often presume that the successor measure admits a low-rank representation. In this work, we challenge this assumption by first remarking that the successor measure itself is not low-rank. Instead, we demonstrate that a low-rank structure naturally emerges in the shifted successor measure, which captures the system dynamics after bypassing a few initial transitions. We provide finite-sample performance guarantees for the entry-wise estimation of a low-rank approximation of the shifted successor measure from sampled entries. Our analysis reveals that both the approximation and estimation errors are primarily governed by the so-called spectral recoverability of the corresponding matrix. To bound this parameter, we derive a new class of functional inequalities for Markov chains that we call Type II Poincar\'e inequalities and from which we can quantify the amount of shift needed for effective low-rank approximation and estimation. This analysis shows in particular that the required shift depends on decay of the high-order singular values of the shifted successor measure and is hence typically small in practice. Additionally, we establish a connection between the necessary shift and the local mixing properties of the underlying dynamical system, which provides a natural way of selecting the shift. Finally, we validate our theoretical findings with experiments, and demonstrate that shifting the successor measure indeed leads to improved performance in goal-conditioned RL.</p></details> | 67 pages, 11 figures |
| **[Feedback Linearisation with State Constraints](http://arxiv.org/abs/2509.05191v1)** | 2025-09-05 | <details><summary>Show</summary><p>Feedback Linearisation (FBL) is a widely used technique that applies feedback laws to transform input-affine nonlinear dynamical systems into linear dynamical systems, allowing for the use of linear controller design methods such as pole placement. However, for problems with state constraints, controlling the linear system induced by FBL can be more challenging than controlling the original system. This is because simple state constraints in the original nonlinear system become complex nonlinear constraints in the FBL induced linearised system, thereby diminishing the advantages of linearisation. To avoid increasing the complexity of state constraints under FBL, this paper introduces a method to first augment system dynamics to capture state constraints before applying FBL. We show that our proposed augmentation method leads to ill-defined relative degrees at state constraint boundaries. However, we show that ill-defined relative degrees can be overcome by using a switching FBL controller. Numerical experiments illustrate the capabilities of this method for handling state constraints within the FBL framework.</p></details> |  |
| **[Barrier Certificates for Unknown Systems with Latent States and Polynomial Dynamics using Bayesian Inference](http://arxiv.org/abs/2504.01807v2)** | 2025-09-05 | <details><summary>Show</summary><p>Certifying safety in dynamical systems is crucial, but barrier certificates - widely used to verify that system trajectories remain within a safe region - typically require explicit system models. When dynamics are unknown, data-driven methods can be used instead, yet obtaining a valid certificate requires rigorous uncertainty quantification. For this purpose, existing methods usually rely on full-state measurements, limiting their applicability. This paper proposes a novel approach for synthesizing barrier certificates for unknown systems with latent states and polynomial dynamics. A Bayesian framework is employed, where a prior in state-space representation is updated using output data via a targeted marginal Metropolis-Hastings sampler. The resulting samples are used to construct a barrier certificate through a sum-of-squares program. Probabilistic guarantees for its validity with respect to the true, unknown system are obtained by testing on an additional set of posterior samples. The approach and its probabilistic guarantees are illustrated through a numerical simulation.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in the Proceedings of the 64th IEEE Conference on Decision and Control</p></details> |
| **[Error-In-Variables Methods for Efficient System Identification with Finite-Sample Guarantees](http://arxiv.org/abs/2504.09057v2)** | 2025-09-05 | <details><summary>Show</summary><p>This paper addresses the problem of learning linear dynamical systems from noisy observations. In this setting, existing algorithms either yield biased parameter estimates or have large sample complexities. We resolve these issues by adapting the instrumental variable method and the bias compensation method, originally proposed for error-in-variables models, to our setting. We provide refined non-asymptotic analysis for both methods. Under mild conditions, our algorithms achieve superior sample complexities that match the best-known sample complexity for learning a fully observable system without observation noise.</p></details> |  |
| **[Echoes Before Collapse: Deep Learning Detection of Flickering in Complex Systems](http://arxiv.org/abs/2509.04683v1)** | 2025-09-04 | <details><summary>Show</summary><p>Deep learning offers powerful tools for anticipating tipping points in complex systems, yet its potential for detecting flickering (noise-driven switching between coexisting stable states) remains unexplored. Flickering is a hallmark of reduced resilience in climate systems, ecosystems, financial markets, and other systems. It can precede critical regime shifts that are highly impactful but difficult to predict. Here we show that convolutional long short-term memory (CNN LSTM) models, trained on synthetic time series generated from simple polynomial functions with additive noise, can accurately identify flickering patterns. Despite being trained on simplified dynamics, our models generalize to diverse stochastic systems and reliably detect flickering in empirical datasets, including dormouse body temperature records and palaeoclimate proxies from the African Humid Period. These findings demonstrate that deep learning can extract early warning signals from noisy, nonlinear time series, providing a flexible framework for identifying instability across a wide range of dynamical systems.</p></details> |  |
| **[$\mathcal{L}_1$-DRAC: Distributionally Robust Adaptive Control](http://arxiv.org/abs/2509.04619v1)** | 2025-09-04 | <details><summary>Show</summary><p>Data-driven machine learning methodologies have attracted considerable attention for the control and estimation of dynamical systems. However, such implementations suffer from a lack of predictability and robustness. Thus, adoption of data-driven tools has been minimal for safety-aware applications despite their impressive empirical results. While classical tools like robust adaptive control can ensure predictable performance, their consolidation with data-driven methods remains a challenge and, when attempted, leads to conservative results. The difficulty of consolidation stems from the inherently different `spaces' that robust control and data-driven methods occupy. Data-driven methods suffer from the distribution-shift problem, which current robust adaptive controllers can only tackle if using over-simplified learning models and unverifiable assumptions. In this paper, we present $\mathcal{L}_1$ distributionally robust adaptive control ($\mathcal{L}_1$-DRAC): a control methodology for uncertain stochastic processes that guarantees robustness certificates in terms of uniform (finite-time) and maximal distributional deviation. We leverage the $\mathcal{L}_1$ adaptive control methodology to ensure the existence of Wasserstein ambiguity set around a nominal distribution, which is guaranteed to contain the true distribution. The uniform ambiguity set produces an ambiguity tube of distributions centered on the nominal temporally-varying nominal distribution. The designed controller generates the ambiguity tube in response to both epistemic (model uncertainties) and aleatoric (inherent randomness and disturbances) uncertainties.</p></details> |  |
| **[Distance Between Stochastic Linear Systems](http://arxiv.org/abs/2509.04014v1)** | 2025-09-04 | <details><summary>Show</summary><p>This manuscript proposes a distance measure between stochastic linear dynamical systems. While the existing stochastic control theory is well equipped to handle dynamical systems with stochastic uncertainties, a paradigm shift using distance measure based decision making is required for the effective further exploration of the field. As a first step, a distance measure between two linear time invariant stochastic dynamical systems is proposed here, extending the existing distance metrics between deterministic linear dynamical systems. Distance measure for stochastic systems is proposed for the frequency domain setting as the worst-case point-wise in frequency Wasserstein distance between distributions characterising the uncertainties using inverse stereographic projection on the Riemann sphere. For the time domain setting, the proposed distance corresponds to the gap metric induced type-$q$ Wasserstein distance between the push-forward measures under both systems' corresponding measurable maps from the parameter space to their respective space of system plants. It is proved and demonstrated using numerical simulation that the proposed frequency domain distance measure shall never exceed the proposed time domain distance measure counterpart. Lower and upper bounds are provided for the proposed distance measures in both frequency and time domain settings. The proposed distance measures induce a topology in the corresponding (frequency/time) domain space of stochastic dynamical systems and will facilitate the provision of probabilistic guarantees on system robustness and controller performances.</p></details> | <details><summary>Submi...</summary><p>Submitted to SIAM Journal on Control and Optimization. 27 Pages in total</p></details> |
| **[Divergence-Kernel method for linear responses and diffusion models](http://arxiv.org/abs/2509.03992v1)** | 2025-09-04 | <details><summary>Show</summary><p>We derive the divergence-kernel formula for the linear response (parameter-derivative of marginal or stationary distributions) of random dynamical systems, and formally pass to the continuous-time limit. Our formula works for multiplicative and parameterized noise over any period of time; it does not require hyperbolicity. Then we derive a pathwise Monte-Carlo algorithm for linear responses. With this, we propose a forward-only diffusion generative model and test on simple problems.</p></details> |  |
| **[Sample Efficient Certification of Discrete-Time Control Barrier Functions](http://arxiv.org/abs/2509.03899v1)** | 2025-09-04 | <details><summary>Show</summary><p>Control Invariant (CI) sets are instrumental in certifying the safety of dynamical systems. Control Barrier Functions (CBFs) are effective tools to compute such sets, since the zero sublevel sets of CBFs are CI sets. However, computing CBFs generally involves addressing a complex robust optimization problem, which can be intractable. Scenario-based methods have been proposed to simplify this computation. Then, one needs to verify if the CBF actually satisfies the robust constraints. We present an approach to perform this verification that relies on Lipschitz arguments, and forms the basis of a certification algorithm designed for sample efficiency. Through a numerical example, we validated the efficiency of the proposed procedure.</p></details> | <details><summary>8 pag...</summary><p>8 pages, accepted for publication in proceedings of IEEE CDC 2025</p></details> |
| **[Reservoir Predictive Path Integral Control for Unknown Nonlinear Dynamics](http://arxiv.org/abs/2509.03839v1)** | 2025-09-04 | <details><summary>Show</summary><p>Neural networks capable of approximating complex nonlinearities have found extensive application in data-driven control of nonlinear dynamical systems. However, fast online identification and control of unknown dynamics remain central challenges. This paper integrates echo-state networks (ESNs) -- reservoir computing models implemented with recurrent neural networks -- and model predictive path integral (MPPI) control -- sampling-based variants of model predictive control -- to meet these challenges. The proposed reservoir predictive path integral (RPPI) enables fast learning of nonlinear dynamics with ESN and exploits the learned nonlinearities directly in parallelized MPPI control computation without linearization approximations. The framework is further extended to uncertainty-aware RPPI (URPPI), which leverages ESN uncertainty to balance exploration and exploitation: exploratory inputs dominate during early learning, while exploitative inputs prevail as model confidence grows. Experiments on controlling the Duffing oscillator and four-tank systems demonstrate that URPPI improves control performance, reducing control costs by up to 60% compared to traditional quadratic programming-based model predictive control methods.</p></details> | <details><summary>Submi...</summary><p>Submitted to IEEE for possible publication, 13 pages, 7 figures</p></details> |
| **[A Learning With Errors based encryption scheme for dynamic controllers that discloses residue signal for anomaly detection](http://arxiv.org/abs/2404.02574v2)** | 2025-09-03 | <details><summary>Show</summary><p>Although encrypted control systems ensure confidentiality of private data, it is challenging to detect anomalies without the secret key as all signals remain encrypted. To address this issue, we propose a homomorphic encryption scheme for dynamic controllers that automatically discloses the residue signal for anomaly detection, while keeping all other signals private. To this end, we characterize the zero-dynamics of an encrypted dynamic system over a finite field of integers and incorporate it into a Learning With Errors (LWE) based scheme. We then present a method to further utilize the disclosed residue signal for implementing dynamic controllers over encrypted data, which does not involve re-encryption even when they have non-integer state matrices.</p></details> | 11 pages, 4 figures |
| **[Deficiency of equation-finding approach to data-driven modeling of dynamical systems](http://arxiv.org/abs/2509.03769v1)** | 2025-09-03 | <details><summary>Show</summary><p>Finding the governing equations from data by sparse optimization has become a popular approach to deterministic modeling of dynamical systems. Considering the physical situations where the data can be imperfect due to disturbances and measurement errors, we show that for many chaotic systems, widely used sparse-optimization methods for discovering governing equations produce models that depend sensitively on the measurement procedure, yet all such models generate virtually identical chaotic attractors, leading to a striking limitation that challenges the conventional notion of equation-based modeling in complex dynamical systems. Calculating the Koopman spectra, we find that the different sets of equations agree in their large eigenvalues and the differences begin to appear when the eigenvalues are smaller than an equation-dependent threshold. The results suggest that finding the governing equations of the system and attempting to interpret them physically may lead to misleading conclusions. It would be more useful to work directly with the available data using, e.g., machine-learning methods.</p></details> | 6 pages, 3 figures |
| **[Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems](http://arxiv.org/abs/2509.03340v1)** | 2025-09-03 | <details><summary>Show</summary><p>Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models struggle to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we propose a generative framework based on flow matching to model the full probability distribution over bifurcation outcomes. Our method enables direct sampling of multiple valid solutions while preserving system symmetries through equivariant modeling. We introduce a symmetric matching strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from toy models to complex physical problems such as buckling beams and the Allen-Cahn equation. Our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations, offering a principled and scalable solution for modeling multistability in high-dimensional systems.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 7 figures including appendices</p></details> |
| **[FlowKac: An Efficient Neural Fokker-Planck solver using Temporal Normalizing Flows and the Feynman-Kac Formula](http://arxiv.org/abs/2503.11427v2)** | 2025-09-03 | <details><summary>Show</summary><p>Solving the Fokker-Planck equation for high-dimensional complex dynamical systems remains a pivotal yet challenging task due to the intractability of analytical solutions and the limitations of traditional numerical methods. In this work, we present FlowKac, a novel approach that reformulates the Fokker-Planck equation using the Feynman-Kac formula, allowing to query the solution at a given point via the expected values of stochastic paths. A key innovation of FlowKac lies in its adaptive stochastic sampling scheme which significantly reduces the computational complexity while maintaining high accuracy. This sampling technique, coupled with a time-indexed normalizing flow, designed for capturing time-evolving probability densities, enables robust sampling of collocation points, resulting in a flexible and mesh-free solver. This formulation mitigates the curse of dimensionality and enhances computational efficiency and accuracy, which is particularly crucial for applications that inherently require dimensions beyond the conventional three. We validate the robustness and scalability of our method through various experiments on a range of stochastic differential equations, demonstrating significant improvements over existing techniques.</p></details> |  |
| **[Task and Motion Planning of Dynamic Systems using Hyperproperties for Signal Temporal Logics](http://arxiv.org/abs/2509.02184v2)** | 2025-09-03 | <details><summary>Show</summary><p>We investigate the task and motion planning problem for dynamical systems under signal temporal logic (STL) specifications. Existing works on STL control synthesis mainly focus on generating plans that satisfy properties over a single executed trajectory. In this work, we consider the planning problem for hyperproperties evaluated over a set of possible trajectories, which naturally arise in information-flow control problems. Specifically, we study discrete-time dynamical systems and employ the recently developed temporal logic HyperSTL as the new objective for planning. To solve this problem, we propose a novel recursive counterexample-guided synthesis approach capable of effectively handling HyperSTL specifications with multiple alternating quantifiers. The proposed method is not only applicable to planning but also extends to HyperSTL model checking for discrete-time dynamical systems. Finally, we present case studies on security-preserving planning and ambiguity-free planning to demonstrate the effectiveness of the proposed HyperSTL planning framework.</p></details> |  |
| **[A Hoare Logic for Symmetry Properties](http://arxiv.org/abs/2509.00587v2)** | 2025-09-03 | <details><summary>Show</summary><p>Many natural program correctness properties can be stated in terms of symmetries, but existing formal methods have little support for reasoning about such properties. We consider how to formally verify a broad class of symmetry properties expressed in terms of group actions. To specify these properties, we design a syntax for group actions, supporting standard constructions and a natural notion of entailment. Then, we develop a Hoare-style logic for verifying symmetry properties of imperative programs, where group actions take the place of the typical pre- and post-condition assertions. Finally, we develop a prototype tool SymVerif, and use it to verify symmetry properties on a series of handcrafted benchmarks. Our tool uncovered an error in a model of a dynamical system described by \citet{McLachlan_Quispel_2002}.</p></details> | <details><summary>Accep...</summary><p>Accepted to OOPSLA '25</p></details> |
| **[An overview of Koopman-based control: From error bounds to closed-loop guarantees](http://arxiv.org/abs/2509.02839v1)** | 2025-09-02 | <details><summary>Show</summary><p>Controlling nonlinear dynamical systems remains a central challenge in a wide range of applications, particularly when accurate first-principle models are unavailable. Data-driven approaches offer a promising alternative by designing controllers directly from observed trajectories. A wide range of data-driven methods relies on the Koopman-operator framework that enables linear representations of nonlinear dynamics via lifting into higher-dimensional observable spaces. Finite-dimensional approximations, such as extended dynamic mode decomposition (EDMD) and its controlled variants, make prediction and feedback control tractable but introduce approximation errors that must be accounted for to provide rigorous closed-loop guarantees. This survey provides a systematic overview of Koopman-based control, emphasizing the connection between data-driven surrogate models generated from finite data, approximation errors, controller design, and closed-loop guarantees. We review theoretical foundations, error bounds, and both linear and bilinear EDMD-based control schemes, highlighting robust strategies that ensure stability and performance. Finally, we discuss open challenges and future directions at the interface of operator theory, approximation theory, and nonlinear control.</p></details> |  |
| **[Hybrid dynamical systems modeling of power systems](http://arxiv.org/abs/2509.02822v1)** | 2025-09-02 | <details><summary>Show</summary><p>The increasing integration of renewable energy sources has introduced complex dynamic behavior in power systems that challenge the adequacy of traditional continuous-time modeling approaches. These developments call for modeling frameworks that can capture the intricate interplay between continuous dynamics and discrete events characterizing modern grid operations. Hybrid dynamical systems offer a rigorous foundation for representing such mixed dynamics and have emerged as a valuable tool in power system analysis. Despite their potential, existing studies remain focused on isolated applications or case-specific implementations, offering limited generalizability and guidance for model selection. This paper addresses that gap by providing a comprehensive overview of hybrid modeling approaches relevant to power systems. It critically examines key formalisms, including hybrid automata, switched systems, and piecewise affine models, evaluating their respective strengths, limitations, and suitability across control, stability, and system design tasks. In doing so, the paper identifies open challenges and outlines future research directions to support the systematic application of hybrid methods in renewable-rich, converter-dominated power systems</p></details> |  |
| **[Efficient State Estimation of a Networked FlipIt Model](http://arxiv.org/abs/2504.01096v2)** | 2025-09-02 | <details><summary>Show</summary><p>The Boolean Kalman Filter and associated Boolean Dynamical System Theory have been proposed to study the spread of infection on computer networks. Such models feature a network where attacks propagate through, an intrusion detection system that provides noisy signals of the true state of the network, and the capability of the defender to clean a subset of computers at any time. The Boolean Kalman Filter has been used to solve the optimal estimation problem, by estimating the hidden true state given the attack-defense dynamics and noisy observations. However, this algorithm is intractable because it runs in exponential time and space with respect to the network size. We address this feasibility problem by proposing a mean-field estimation approach, which is inspired by the epidemic modeling literature. Although our approach is heuristic, we prove that our estimator exactly matches the optimal estimator in certain non-trivial cases. We conclude by using simulations to show both the run-time improvement and estimation accuracy of our approach.</p></details> |  |
| **[Principled model selection for stochastic dynamics](http://arxiv.org/abs/2501.10339v3)** | 2025-09-02 | <details><summary>Show</summary><p>Complex dynamical systems, from macromolecules to ecosystems, are often modeled by stochastic differential equations. To learn such models from data, a common approach involves sparse selection among a large function library. However, we show that overfitting arises not just from individual model complexity, but also from the combinatorial growth of possible models. To address this, we introduce Parsimonious Stochastic Inference (PASTIS), a principled method combining likelihood-estimation statistics with extreme value theory to suppress superfluous parameters. PASTIS outperforms existing methods and reliably identifies minimal models, even with low sampling rates or measurement error. It extends to stochastic partial differential equations, and applies to ecological networks and reaction-diffusion dynamics.</p></details> |  |
| **[Data-Driven Abstraction and Synthesis for Stochastic Systems with Unknown Dynamics](http://arxiv.org/abs/2508.15543v2)** | 2025-09-02 | <details><summary>Show</summary><p>We study the automated abstraction-based synthesis of correct-by-construction control policies for stochastic dynamical systems with unknown dynamics. Our approach is to learn an abstraction from sampled data, which is represented in the form of a finite Markov decision process (MDP). In this paper, we present a data-driven technique for constructing finite-state interval MDP (IMDP) abstractions of stochastic systems with unknown nonlinear dynamics. As a distinguishing and novel feature, our technique only requires (1) noisy state-input-state observations and (2) an upper bound on the system's Lipschitz constant. Combined with standard model-checking techniques, our IMDP abstractions enable the synthesis of policies that satisfy probabilistic temporal properties (such as "reach-while-avoid") with a predefined confidence. Our experimental results show the effectiveness and robustness of our approach.</p></details> |  |
| **[On Word-of-Mouth and Private-Prior Sequential Social Learning](http://arxiv.org/abs/2504.02913v4)** | 2025-09-02 | <details><summary>Show</summary><p>Social learning constitutes a fundamental framework for studying interactions among rational agents who observe each other's actions but lack direct access to individual beliefs. This paper investigates a specific social learning paradigm known as Word-of-Mouth (WoM), where a series of agents seeks to estimate the state of a dynamical system. The first agent receives noisy measurements of the state, while each subsequent agent relies solely on a degraded version of her predecessor's estimate. A defining feature of WoM is that the final agent's belief is publicly broadcast and subsequently adopted by all agents, in place of their own. We analyze this setting theoretically and through numerical simulations, noting that some agents benefit from using the belief of the last agent, while others experience performance deterioration.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication at the 64th Conference on Decision and Control (CDC)</p></details> |
| **[Breaking Free: Decoupling Forced Systems with Laplace Neural Networks](http://arxiv.org/abs/2503.13158v2)** | 2025-09-02 | <details><summary>Show</summary><p>Modelling forced dynamical systems - where an external input drives the system state - is critical across diverse domains such as engineering, finance, and the natural sciences. In this work, we propose Laplace-Net, a decoupled, solver-free neural framework for learning forced and delay-aware systems. It leverages a Laplace transform-based approach to decompose internal dynamics, external inputs, and initial values into established theoretical concepts, enhancing interpretability. Laplace-Net promotes transferability since the system can be rapidly re-trained or fine-tuned for new forcing signals, providing flexibility in applications ranging from controller adaptation to long-horizon forecasting. Experimental results on eight benchmark datasets - including linear, non-linear, and delayed systems - demonstrate the method's improved accuracy and robustness compared to state-of-the-art approaches, particularly in handling complex and previously unseen inputs.</p></details> | <details><summary>Prepr...</summary><p>Preprint - Accepted to the Research Track of ECML PKDD 2025</p></details> |
| **[Inference in Spreading Processes with Neural-Network Priors](http://arxiv.org/abs/2509.02073v1)** | 2025-09-02 | <details><summary>Show</summary><p>Stochastic processes on graphs are a powerful tool for modelling complex dynamical systems such as epidemics. A recent line of work focused on the inference problem where one aims to estimate the state of every node at every time, starting from partial observation of a subset of nodes at a subset of times. In these works, the initial state of the process was assumed to be random i.i.d. over nodes. Such an assumption may not be realistic in practice, where one may have access to a set of covariate variables for every node that influence the initial state of the system. In this work, we will assume that the initial state of a node is an unknown function of such covariate variables. Given that functions can be represented by neural networks, we will study a model where the initial state is given by a simple neural network -- notably the single-layer perceptron acting on the known node-wise covariate variables. Within a Bayesian framework, we study how such neural-network prior information enhances the recovery of initial states and spreading trajectories. We derive a hybrid belief propagation and approximate message passing (BP-AMP) algorithm that handles both the spreading dynamics and the information included in the node covariates, and we assess its performance against the estimators that either use only the spreading information or use only the information from the covariate variables. We show that in some regimes, the model can exhibit first-order phase transitions when using a Rademacher distribution for the neural-network weights. These transitions create a statistical-to-computational gap where even the BP-AMP algorithm, despite the theoretical possibility of perfect recovery, fails to achieve it.</p></details> | 26 pages, 13 figures |
| **[Solving "pseudo-injective" polynomial equations over finite dynamical systems](http://arxiv.org/abs/2504.06986v2)** | 2025-09-02 | <details><summary>Show</summary><p>We consider the semiring of abstract finite dynamical systems up to isomorphism, with the operations of alternative and synchronous execution. We continue searching for efficient algorithms for solving polynomial equations of the form $P(X) = B$, with a constant side B, with the goal of decomposing complex behaviors into simpler systems. Taking inspiration from the characterization of injective polynomials P over dynamical systems, which is based on a condition on the lengths of limit cycles of their coefficients, we introduce a more general notion of pseudo-injectivity by relaxing this constraint. We prove that the associated equations can be solved efficiently, even in certain cases where the input is encoded in an exponentially more compact way.</p></details> |  |
| **[Optimal information injection and transfer mechanisms for active matter reservoir computing](http://arxiv.org/abs/2509.01799v1)** | 2025-09-01 | <details><summary>Show</summary><p>Reservoir computing (RC) is a state-of-the-art machine learning method that makes use of the power of dynamical systems (the reservoir) for real-time inference. When using biological complex systems as reservoir substrates, it serves as a testbed for basic questions about bio-inspired computation -- of how self-organization generates proper spatiotemporal patterning. Here, we use a simulation of an active matter system, driven by a chaotically moving input signal, as a reservoir. So far, it has been unclear whether such complex systems possess the capacity to process information efficiently and independently of the method by which it was introduced. We find that when switching from a repulsive to an attractive driving force, the system completely changes the way it computes, while the predictive performance landscapes remain nearly identical. The nonlinearity of the driver's injection force improves computation by decoupling the single-agent dynamics from that of the driver. Triggered are the (re-)growth, deformation, and active motion of smooth structural boundaries (interfaces), and the emergence of coherent gradients in speed -- features found in many soft materials and biological systems. The nonlinear driving force activates emergent regulatory mechanisms, which manifest enhanced morphological and dynamic diversity -- arguably improving fading memory, nonlinearity, expressivity, and thus, performance. We further perform RC in a broad variety of non-equilibrium active matter phases that arise when tuning internal (repulsive) forces for information transfer. Overall, we find that active matter agents forming liquid droplets are particularly well suited for RC. The consistently convex shape of the predictive performance landscapes, together with the observed phenomenological richness, conveys robustness and adaptivity.</p></details> | <details><summary>53 pa...</summary><p>53 pages, 23 figures. Supplementary Videos: https://doi.org/10.18419/DARUS-4806. Replication Data: https://doi.org/10.18419/DARUS-4805</p></details> |
| **[Maximally Resilient Controllers under Temporal Logic Specifications](http://arxiv.org/abs/2509.01777v1)** | 2025-09-01 | <details><summary>Show</summary><p>In this paper, we consider the notion of resilience of a dynamical system, defined by the maximum disturbance a controlled dynamical system can withstand while satisfying given temporal logic specifications. Given a dynamical system and a specification, the objective is to synthesize the controller such that the closed-loop system satisfies this specification while maximizing its resilience. The problem is formulated as a robust optimization program where the objective is to compute the maximum resilience while simultaneously synthesizing the corresponding controller parameters. For linear systems and linear controllers, exact solutions are provided for the class of time-varying polytopic specifications. For the case of nonlinear systems, nonlinear controllers and more general specifications, we leverage tools from the scenario optimization approach, offering a probabilistic guarantee of the solution as well as computational feasibility. Different case studies are presented to illustrate the theoretical results.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 4 figures, conference</p></details> |
| **[Constrained Decoding for Robotics Foundation Models](http://arxiv.org/abs/2509.01728v1)** | 2025-09-01 | <details><summary>Show</summary><p>Recent advances in the development of robotic foundation models have led to promising end-to-end and general-purpose capabilities in robotic systems. These models are pretrained on vast datasets of robot trajectories to process multi-modal inputs and directly output a sequence of action that the system then executes in the real world. Although this approach is attractive from the perspective of improved generalization across diverse tasks, these models are still data-driven and, therefore, lack explicit notions of behavioral correctness and safety constraints. We address these limitations by introducing a constrained decoding framework for robotics foundation models that enforces logical constraints on action trajectories in dynamical systems. Our method ensures that generated actions provably satisfy signal temporal logic (STL) specifications at runtime without retraining, while remaining agnostic of the underlying foundation model. We perform comprehensive evaluation of our approach across state-of-the-art navigation foundation models and we show that our decoding-time interventions are useful not only for filtering unsafe actions but also for conditional action-generation. Videos available on our website: https://constrained-robot-fms.github.io</p></details> |  |
| **[Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation](http://arxiv.org/abs/2507.02608v2)** | 2025-09-01 | <details><summary>Show</summary><p>The steep computational cost of diffusion models at inference hinders their use as fast physics emulators. In the context of image and video generation, this computational drawback has been addressed by generating in the latent space of an autoencoder instead of the pixel space. In this work, we investigate whether a similar strategy can be effectively applied to the emulation of dynamical systems and at what cost. We find that the accuracy of latent-space emulation is surprisingly robust to a wide range of compression rates (up to 1000x). We also show that diffusion-based emulators are consistently more accurate than non-generative counterparts and compensate for uncertainty in their predictions with greater diversity. Finally, we cover practical design choices, spanning from architectures to optimizers, that we found critical to train latent-space emulators.</p></details> |  |
| **[Multitask Battery Management with Flexible Pretraining](http://arxiv.org/abs/2509.01323v1)** | 2025-09-01 | <details><summary>Show</summary><p>Industrial-scale battery management involves various types of tasks, such as estimation, prediction, and system-level diagnostics. Each task employs distinct data across temporal scales, sensor resolutions, and data channels. Building task-specific methods requires a great deal of data and engineering effort, which limits the scalability of intelligent battery management. Here we present the Flexible Masked Autoencoder (FMAE), a flexible pretraining framework that can learn with missing battery data channels and capture inter-correlations across data snippets. FMAE learns unified battery representations from heterogeneous data and can be adopted by different tasks with minimal data and engineering efforts. Experimentally, FMAE consistently outperforms all task-specific methods across five battery management tasks with eleven battery datasets. On remaining life prediction tasks, FMAE uses 50 times less inference data while maintaining state-of-the-art results. Moreover, when real-world data lack certain information, such as system voltage, FMAE can still be applied with marginal performance impact, achieving comparable results with the best hand-crafted features. FMAE demonstrates a practical route to a flexible, data-efficient model that simplifies real-world multi-task management of dynamical systems.</p></details> |  |
| **[Design, Modelling and Analysis of a Bio-inspired Spiking Temperature Regulator](http://arxiv.org/abs/2509.01300v1)** | 2025-09-01 | <details><summary>Show</summary><p>In biology, homeostasis is the process of maintaining a stable internal environment, which is crucial for optimal functioning of organisms. One of the key homeostatic mechanisms is thermoregulation that allows the organism to maintain its core temperature within tight bounds despite being exposed to a wide range of varying external temperatures. Instrumental in thermoregulation is the presence of thermosensitive neurons at multiple places throughout the body, including muscles, the spinal cord, and the brain, which provide spiking sensory signals for the core temperature. In response to these signals, thermoeffectors are activated, creating a negative spiking feedback loop. Additionally, a feedforward signal is provided by warmth and cold-sensitive neurons in the skin, offering a measure for the external temperature. This paper presents an electronic circuit-based architecture design to replicate the biological process of thermoregulation, combined with a formal mathematical analysis. The considered architecture consists of four temperature sensitive neurons and a single actuator, configured in a negative feedback loop with feedforward control. To model the overall system mathematically, hybrid dynamical system descriptions are proposed that are used to analyze and simulate the performance of the design. The analysis and numerical case study illustrate the crucial role of feedforward control in reducing the dependency on the external temperature.</p></details> |  |
| **[Harnessing the edge of chaos for combinatorial optimization](http://arxiv.org/abs/2508.17655v3)** | 2025-09-01 | <details><summary>Show</summary><p>Nonlinear dynamical systems with continuous variables can be used for solving combinatorial optimization problems with discrete variables. In particular, numerical simulations of them can be used as heuristic algorithms with a desirable property, namely, parallelizability, which allows us to execute them in a massively parallel manner using cutting-edge many-core processors, leading to ultrafast performance. However, the dynamical-system approaches with continuous variables are usually less accurate than conventional approaches with discrete variables such as simulated annealing. To improve the solution accuracy of a representative dynamical system-based algorithm called simulated bifurcation (SB), which was found from classical simulation of a quantum nonlinear oscillator network exhibiting quantum bifurcation, here we generalize it by introducing nonlinear control of individual bifurcation parameters and show that the generalized SB (GSB) can achieve almost 100% success probabilities for some large-scale problems. As a result, the time to solution for a 2,000-variable problem is shortened to 10 ms by a GSB-based machine, which is two orders of magnitude shorter than the best known value, 1.3 s, previously obtained by an SB-based machine. To examine the reason for the ultrahigh performance, we investigated chaos in the GSB changing the nonlinear-control strength and found that the dramatic increase of success probabilities happens near the edge of chaos. That is, the GSB can find a solution with high probability by harnessing the edge of chaos. This finding suggests that dynamical-system approaches to combinatorial optimization will be enhanced by harnessing the edge of chaos, opening a broad possibility to tackle intractable combinatorial optimization problems by nature-inspired approaches.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 4 figures, 3 tables</p></details> |
| **[On a closed-loop identification challenge in feedback optimization](http://arxiv.org/abs/2509.01188v1)** | 2025-09-01 | <details><summary>Show</summary><p>Feedback optimization has emerged as an effective strategy for steady-state optimization of dynamical systems. By exploiting models of the steady-state input-output sensitivity, methods of this type are often sample efficient, and their use of feedback ensures that they are robust against model error. Still, this robustness has its limitations, and the dependence on a model may hinder convergence in settings with high model error. We investigate here the effect of a particular type of model error: bias due to identifying the model from closed-loop data. Our main results are a sufficient convergence condition, and a converse divergence condition. The convergence condition requires a matrix which depends on the closed-loop sensitivity and a noise-to-signal ratio of the data generating system to be positive definite. The negative definiteness of the same matrix characterizes an extreme case where the bias due to closed-loop data results in divergence of model-based feedback optimization.</p></details> | 7 pages, 1 figure |
| **[Formal Verification of Isothermal Chemical Reactors](http://arxiv.org/abs/2509.01130v1)** | 2025-09-01 | <details><summary>Show</summary><p>Chemical reactors are dynamic systems that can be described by systems of ordinary differential equations (ODEs). Reactor safety, regulatory compliance, and economics depend on whether certain states are reachable by the reactor, and are generally assessed using numerical simulation. In this work, we show how differential dynamic logic (dL), as implemented in the automated theorem prover KeYmaera X, can be used to symbolically determine reachability in isothermal chemical reactors, providing mathematical guarantees that certain conditions are satisfied (for example, that an outlet concentration never exceeds a regulatory threshold). First, we apply dL to systems whose dynamics can be solved in closed form, such as first-order reactions in batch reactors, proving that such reactors cannot exceed specified concentration limits. We extend this method to reaction models as complex as Michaelis-Menten kinetics, whose dynamics require approximations or numerical solutions. In all cases, proofs are facilitated by identification of invariants; we find that conservation of mass is both a principle proved from the ODEs describing mass action kinetics as well as a useful relationship for proving other properties. Useful invariants for continuous stirred tank reactors (CSTRs) were not found, which limited the complexity of reaction networks that could be proved with dL. While dL provides an interesting symbolic logic approach for reachability in chemical reactions, the bounds we obtained are quite broad relative to those typically achieved via numerical reachability analyses.</p></details> |  |

## Graph Neural Networks
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Asynchronous Message Passing for Addressing Oversquashing in Graph Neural Networks](http://arxiv.org/abs/2509.06777v1)** | 2025-09-08 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) suffer from Oversquashing, which occurs when tasks require long-range interactions. The problem arises from the presence of bottlenecks that limit the propagation of messages among distant nodes. Recently, graph rewiring methods modify edge connectivity and are expected to perform well on long-range tasks. Yet, graph rewiring compromises the inductive bias, incurring significant information loss in solving the downstream task. Furthermore, increasing channel capacity may overcome information bottlenecks but enhance the parameter complexity of the model. To alleviate these shortcomings, we propose an efficient model-agnostic framework that asynchronously updates node features, unlike traditional synchronous message passing GNNs. Our framework creates node batches in every layer based on the node centrality values. The features of the nodes belonging to these batches will only get updated. Asynchronous message updates process information sequentially across layers, avoiding simultaneous compression into fixed-capacity channels. We also theoretically establish that our proposed framework maintains higher feature sensitivity bounds compared to standard synchronous approaches. Our framework is applied to six standard graph datasets and two long-range datasets to perform graph classification and achieves impressive performances with a $5\%$ and $4\%$ improvements on REDDIT-BINARY and Peptides-struct, respectively.</p></details> |  |
| **[A Composite-Loss Graph Neural Network for the Multivariate Post-Processing of Ensemble Weather Forecasts](http://arxiv.org/abs/2509.02784v2)** | 2025-09-08 | <details><summary>Show</summary><p>Ensemble forecasting systems have advanced meteorology by providing probabilistic estimates of future states. Nonetheless, systematic biases often persist, making statistical post-processing essential. Traditional parametric post-processing techniques and machine learning-based methods can produce calibrated predictive distributions at specific locations and lead times, yet often struggle to capture dependencies across forecast dimensions. To address this, multivariate post-processing methods-such as ensemble copula coupling and the Schaake shuffle-are widely applied in a second step to restore realistic inter-variable or spatio-temporal dependencies. The aim of this study is the multivariate post-processing of ensemble forecasts using a graph neural network (dualGNN) trained with a composite loss function that combines the energy score (ES) and the variogram score (VS). The method is evaluated on two datasets: WRF-based solar irradiance forecasts over northern Chile and ECMWF visibility forecasts for Central Europe. The dualGNN consistently outperforms all empirical copula-based post-processed forecasts and shows significant improvements compared to graph neural networks trained solely on either the continuous ranked probability score or the ES, according to the evaluated multivariate verification metrics. Furthermore, for the WRF forecasts, the rank-order structure of the dualGNN forecasts captures valuable dependency information, enabling a more effective restoration of spatial relationships than either the raw numerical weather prediction ensemble or historical observational rank structures. Notably, incorporating VS into the loss function improved the univariate performance for both target variables compared to training on ES alone. Moreover, for the visibility forecasts, the ES-VS combination even outperformed the strongest calibrated reference in terms of univariate performance.</p></details> | <details><summary>30 pa...</summary><p>30 pages, 16 figures, 3 tables</p></details> |
| **[VariSAC: V2X Assured Connectivity in RIS-Aided ISAC via GNN-Augmented Reinforcement Learning](http://arxiv.org/abs/2509.06763v1)** | 2025-09-08 | <details><summary>Show</summary><p>The integration of Reconfigurable Intelligent Surfaces (RIS) and Integrated Sensing and Communication (ISAC) in vehicular networks enables dynamic spatial resource management and real-time adaptation to environmental changes. However, the coexistence of distinct vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) connectivity requirements, together with highly dynamic and heterogeneous network topologies, presents significant challenges for unified reliability modeling and resource optimization. To address these issues, we propose VariSAC, a graph neural network (GNN)-augmented deep reinforcement learning framework for assured, time-continuous connectivity in RIS-assisted, ISAC-enabled vehicle-to-everything (V2X) systems. Specifically, we introduce the Continuous Connectivity Ratio (CCR), a unified metric that characterizes the sustained temporal reliability of V2I connections and the probabilistic delivery guarantees of V2V links, thus unifying their continuous reliability semantics. Next, we employ a GNN with residual adapters to encode complex, high-dimensional system states, capturing spatial dependencies among vehicles, base stations (BS), and RIS nodes. These representations are then processed by a Soft Actor-Critic (SAC) agent, which jointly optimizes channel allocation, power control, and RIS configurations to maximize CCR-driven long-term rewards. Extensive experiments on real-world urban datasets demonstrate that VariSAC consistently outperforms existing baselines in terms of continuous V2I ISAC connectivity and V2V delivery reliability, enabling persistent connectivity in highly dynamic vehicular environments.</p></details> |  |
| **[Long-Range Graph Wavelet Networks](http://arxiv.org/abs/2509.06743v1)** | 2025-09-08 | <details><summary>Show</summary><p>Modeling long-range interactions, the propagation of information across distant parts of a graph, is a central challenge in graph machine learning. Graph wavelets, inspired by multi-resolution signal processing, provide a principled way to capture both local and global structures. However, existing wavelet-based graph neural networks rely on finite-order polynomial approximations, which limit their receptive fields and hinder long-range propagation. We propose Long-Range Graph Wavelet Networks (LR-GWN), which decompose wavelet filters into complementary local and global components. Local aggregation is handled with efficient low-order polynomials, while long-range interactions are captured through a flexible spectral domain parameterization. This hybrid design unifies short- and long-distance information flow within a principled wavelet framework. Experiments show that LR-GWN achieves state-of-the-art performance among wavelet-based methods on long-range benchmarks, while remaining competitive on short-range datasets.</p></details> |  |
| **[Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks](http://arxiv.org/abs/2410.17118v2)** | 2025-09-08 | <details><summary>Show</summary><p>Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a promising paradigm of heterogeneous network (HetNet), attributed to the complementary physical properties of optical spectra and radio frequency. However, the current development of such HetNets is mostly bottlenecked by the existing transmission control protocol (TCP), which restricts the user equipment (UE) to connecting one access point (AP) at a time. While the ongoing investigation on multipath TCP (MPTCP) can bring significant benefits, it complicates the network topology of HetNets, making the existing load balancing (LB) learning models less effective. Driven by this, we propose a graph neural network (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets, which results in a partial mesh topology. Such a topology can be modeled as a graph, with the channel state information and data rate requirement embedded as node features, while the LB solutions are deemed as edge labels. Compared to the conventional deep neural network (DNN), the proposed GNN-based model exhibits two key strengths: i) it can better interpret a complex network topology; and ii) it can handle various numbers of APs and UEs with a single trained model. Simulation results show that against the traditional optimisation method, the proposed learning model can achieve near-optimal throughput within a gap of 11.5%, while reducing the inference time by 4 orders of magnitude. In contrast to the DNN model, the new method can improve the network throughput by up to 21.7%, at a similar inference time level.</p></details> | <details><summary>We wo...</summary><p>We would like to withdraw this submission because it contains several errors that need substantial revision. We plan to prepare a corrected and improved version, which will be submitted as a new manuscript at a later stage</p></details> |
| **[AnalysisGNN: Unified Music Analysis with Graph Neural Networks](http://arxiv.org/abs/2509.06654v1)** | 2025-09-08 | <details><summary>Show</summary><p>Recent years have seen a boom in computational approaches to music analysis, yet each one is typically tailored to a specific analytical domain. In this work, we introduce AnalysisGNN, a novel graph neural network framework that leverages a data-shuffling strategy with a custom weighted multi-task loss and logit fusion between task-specific classifiers to integrate heterogeneously annotated symbolic datasets for comprehensive score analysis. We further integrate a Non-Chord-Tone prediction module, which identifies and excludes passing and non-functional notes from all tasks, thereby improving the consistency of label signals. Experimental evaluations demonstrate that AnalysisGNN achieves performance comparable to traditional static-dataset approaches, while showing increased resilience to domain shifts and annotation inconsistencies across multiple heterogeneous corpora.</p></details> | <details><summary>Accep...</summary><p>Accepted at the 17th International Symposium on Computer Music Multidisciplinary Research (CMMR) 2025</p></details> |
| **[PAC-Bayesian Generalization Bounds for Graph Convolutional Networks on Inductive Node Classification](http://arxiv.org/abs/2509.06600v1)** | 2025-09-08 | <details><summary>Show</summary><p>Graph neural networks (GNNs) have achieved remarkable success in processing graph-structured data across various applications. A critical aspect of real-world graphs is their dynamic nature, where new nodes are continually added and existing connections may change over time. Previous theoretical studies, largely based on the transductive learning framework, fail to adequately model such temporal evolution and structural dynamics. In this paper, we presents a PAC-Bayesian theoretical analysis of graph convolutional networks (GCNs) for inductive node classification, treating nodes as dependent and non-identically distributed data points. We derive novel generalization bounds for one-layer GCNs that explicitly incorporate the effects of data dependency and non-stationarity, and establish sufficient conditions under which the generalization gap converges to zero as the number of nodes increases. Furthermore, we extend our analysis to two-layer GCNs, and reveal that it requires stronger assumptions on graph topology to guarantee convergence. This work establishes a theoretical foundation for understanding and improving GNN generalization in dynamic graph environments.</p></details> |  |
| **[Topological Regularization for Force Prediction in Active Particle Suspension with EGNN and Persistent Homology](http://arxiv.org/abs/2509.06574v1)** | 2025-09-08 | <details><summary>Show</summary><p>Capturing the dynamics of active particles, i.e., small self-propelled agents that both deform and are deformed by a fluid in which they move is a formidable problem as it requires coupling fine scale hydrodynamics with large scale collective effects. So we present a multi-scale framework that combines the three learning-driven tools to learn in concert within one pipeline. We use high-resolution Lattice Boltzmann snapshots of fluid velocity and particle stresses in a periodic box as input to the learning pipeline. the second step takes the morphology and positions orientations of particles to predict pairwise interaction forces between them with a E(2)-equivariant graph neural network that necessarily respect flat symmetries. Then, a physics-informed neural network further updates these local estimates by summing over them with a stress data using Fourier feature mappings and residual blocks that is additionally regularized with a topological term (introduced by persistent homology) to penalize unrealistically tangled or spurious connections. In concert, these stages deliver an holistic highly-data driven full force network prediction empathizing on the physical underpinnings together with emerging multi-scale structure typical for active matter.</p></details> |  |
| **[Rethinking GNN Expressive Power from a Distributed Computational Model Perspective](http://arxiv.org/abs/2410.01308v4)** | 2025-09-08 | <details><summary>Show</summary><p>The success of graph neural networks (GNNs) has motivated theoretical studies on their expressive power, often through alignments with the Weisfeiler-Lehman (WL) tests. However, such analyses typically focus on the ability of GNNs to distinguish between graph structures, rather than to compute or approximate specific function classes. The latter is more commonly studied in machine learning theory, including results such as the Turing completeness of recurrent networks and the universal approximation property of feedforward networks. We argue that using well-defined computational models, such as a modified CONGEST model with clearly specified preprocessing and postprocessing, offers a more sound framework for analyzing GNN expressiveness. Within this framework, we show that allowing unrestricted preprocessing or incorporating externally computed features, while claiming that these precomputations enhance the expressiveness, can sometimes lead to problems. We also show that the lower bound on a GNN's capacity (depth multiplied by width) to simulate one iteration of the WL test actually grows nearly linearly with graph size, indicating that the WL test is not locally computable and is misaligned with message-passing GNNs. Despite these negative results, we also present positive results that characterize the effects of virtual nodes and edges from a computational model perspective. Finally, we highlight several open problems regarding GNN expressiveness for further exploration.</p></details> |  |
| **[Graph Neural Networks for Resource Allocation in Interference-limited Multi-Channel Wireless Networks with QoS Constraints](http://arxiv.org/abs/2509.06395v1)** | 2025-09-08 | <details><summary>Show</summary><p>Meeting minimum data rate constraints is a significant challenge in wireless communication systems, particularly as network complexity grows. Traditional deep learning approaches often address these constraints by incorporating penalty terms into the loss function and tuning hyperparameters empirically. However, this heuristic treatment offers no theoretical convergence guarantees and frequently fails to satisfy QoS requirements in practical scenarios. Building upon the structure of the WMMSE algorithm, we first extend it to a multi-channel setting with QoS constraints, resulting in the enhanced WMMSE (eWMMSE) algorithm, which is provably convergent to a locally optimal solution when the problem is feasible. To further reduce computational complexity and improve scalability, we develop a GNN-based algorithm, JCPGNN-M, capable of supporting simultaneous multi-channel allocation per user. To overcome the limitations of traditional deep learning methods, we propose a principled framework that integrates GNN with a Lagrangian-based primal-dual optimization method. By training the GNN within the Lagrangian framework, we ensure satisfaction of QoS constraints and convergence to a stationary point. Extensive simulations demonstrate that JCPGNN-M matches the performance of eWMMSE while offering significant gains in inference speed, generalization to larger networks, and robustness under imperfect channel state information. This work presents a scalable and theoretically grounded solution for constrained resource allocation in future wireless networks.</p></details> |  |
| **[Predicting Steady-State Behavior in Complex Networks with Graph Neural Networks](http://arxiv.org/abs/2502.01693v3)** | 2025-09-08 | <details><summary>Show</summary><p>In complex systems, information propagation can be defined as diffused or delocalized, weakly localized, and strongly localized. This study investigates the application of graph neural network models to learn the behavior of a linear dynamical system on networks. A graph convolution and attention-based neural network framework has been developed to identify the steady-state behavior of the linear dynamical system. We reveal that our trained model distinguishes the different states with high accuracy. Furthermore, we have evaluated model performance with real-world data. In addition, to understand the explainability of our model, we provide an analytical derivation for the forward and backward propagation of our framework.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 15 figures (including Appendix)</p></details> |
| **[A Spatio-Temporal Graph Neural Networks Approach for Predicting Silent Data Corruption inducing Circuit-Level Faults](http://arxiv.org/abs/2509.06289v1)** | 2025-09-08 | <details><summary>Show</summary><p>Silent Data Errors (SDEs) from time-zero defects and aging degrade safety-critical systems. Functional testing detects SDE-related faults but is expensive to simulate. We present a unified spatio-temporal graph convolutional network (ST-GCN) for fast, accurate prediction of long-cycle fault impact probabilities (FIPs) in large sequential circuits, supporting quantitative risk assessment. Gate-level netlists are modeled as spatio-temporal graphs to capture topology and signal timing; dedicated spatial and temporal encoders predict multi-cycle FIPs efficiently. On ISCAS-89 benchmarks, the method reduces simulation time by more than 10x while maintaining high accuracy (mean absolute error 0.024 for 5-cycle predictions). The framework accepts features from testability metrics or fault simulation, allowing efficiency-accuracy trade-offs. A test-point selection study shows that choosing observation points by predicted FIPs improves detection of long-cycle, hard-to-detect faults. The approach scales to SoC-level test strategy optimization and fits downstream electronic design automation flows.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 9 figures, plan to submit to ACM TODAES</p></details> |
| **[RecMind: LLM-Enhanced Graph Neural Networks for Personalized Consumer Recommendations](http://arxiv.org/abs/2509.06286v1)** | 2025-09-08 | <details><summary>Show</summary><p>Personalization is a core capability across consumer technologies, streaming, shopping, wearables, and voice, yet it remains challenged by sparse interactions, fast content churn, and heterogeneous textual signals. We present RecMind, an LLM-enhanced graph recommender that treats the language model as a preference prior rather than a monolithic ranker. A frozen LLM equipped with lightweight adapters produces text-conditioned user/item embeddings from titles, attributes, and reviews; a LightGCN backbone learns collaborative embeddings from the user-item graph. We align the two views with a symmetric contrastive objective and fuse them via intra-layer gating, allowing language to dominate in cold/long-tail regimes and graph structure to stabilize rankings elsewhere. On Yelp and Amazon-Electronics, RecMind attains the best results on all eight reported metrics, with relative improvements up to +4.53\% (Recall@40) and +4.01\% (NDCG@40) over strong baselines. Ablations confirm both the necessity of cross-view alignment and the advantage of gating over late fusion and LLM-only variants.</p></details> |  |
| **[Data-Efficient Time-Dependent PDE Surrogates: Graph Neural Simulators vs Neural Operators](http://arxiv.org/abs/2509.06154v1)** | 2025-09-07 | <details><summary>Show</summary><p>Neural operators (NOs) approximate mappings between infinite-dimensional function spaces but require large datasets and struggle with scarce training data. Many NO formulations don't explicitly encode causal, local-in-time structure of physical evolution. While autoregressive models preserve causality by predicting next time-steps, they suffer from rapid error accumulation. We employ Graph Neural Simulators (GNS) - a message-passing graph neural network framework - with explicit numerical time-stepping schemes to construct accurate forward models that learn PDE solutions by modeling instantaneous time derivatives. We evaluate our framework on three canonical PDE systems: (1) 2D Burgers' scalar equation, (2) 2D coupled Burgers' vector equation, and (3) 2D Allen-Cahn equation. Rigorous evaluations demonstrate GNS significantly improves data efficiency, achieving higher generalization accuracy with substantially fewer training trajectories compared to neural operator baselines like DeepONet and FNO. GNS consistently achieves under 1% relative L2 errors with only 30 training samples out of 1000 (3% of available data) across all three PDE systems. It substantially reduces error accumulation over extended temporal horizons: averaged across all cases, GNS reduces autoregressive error by 82.48% relative to FNO AR and 99.86% relative to DON AR. We introduce a PCA+KMeans trajectory selection strategy enhancing low-data performance. Results indicate combining graph-based local inductive biases with conventional time integrators yields accurate, physically consistent, and scalable surrogate models for time-dependent PDEs.</p></details> | <details><summary>21 pa...</summary><p>21 pages including references. Supplementary Information provided</p></details> |
| **[Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities](http://arxiv.org/abs/2509.06041v1)** | 2025-09-07 | <details><summary>Show</summary><p>Buoyancy-driven heat transfer in closed cavities serves as a canonical testbed for thermal design High-fidelity CFD modelling yields accurate thermal field solutions, yet its reliance on expert-crafted physics models, fine meshes, and intensive computation limits rapid iteration. Recent developments in data-driven modeling, especially Graph Neural Networks (GNNs), offer new alternatives for learning thermal-fluid behavior directly from simulation data, particularly on irregular mesh structures. However, conventional GNNs often struggle to capture long-range dependencies in high-resolution graph structures. To overcome this limitation, we propose a novel multi-stage GNN architecture that leverages hierarchical pooling and unpooling operations to progressively model global-to-local interactions across multiple spatial scales. We evaluate the proposed model on our newly developed CFD dataset simulating natural convection within a rectangular cavities with varying aspect ratios where the bottom wall is isothermal hot, the top wall is isothermal cold, and the two vertical walls are adiabatic. Experimental results demonstrate that the proposed model achieves higher predictive accuracy, improved training efficiency, and reduced long-term error accumulation compared to state-of-the-art (SOTA) GNN baselines. These findings underscore the potential of the proposed multi-stage GNN approach for modeling complex heat transfer in mesh-based fluid dynamics simulations.</p></details> |  |
| **[GRACE: Graph-Guided Repository-Aware Code Completion through Hierarchical Code Fusion](http://arxiv.org/abs/2509.05980v1)** | 2025-09-07 | <details><summary>Show</summary><p>LLMs excel in localized code completion but struggle with repository-level tasks due to limited context windows and complex semantic and structural dependencies across codebases. While Retrieval-Augmented Generation (RAG) mitigates context scarcity by retrieving relevant code snippets, current approaches face significant limitations. They overly rely on textual similarity for retrieval, neglecting structural relationships such as call chains and inheritance hierarchies, and lose critical structural information by naively concatenating retrieved snippets into text sequences for LLM input. To address these shortcomings, GRACE constructs a multi-level, multi-semantic code graph that unifies file structures, abstract syntax trees, function call graphs, class hierarchies, and data flow graphs to capture both static and dynamic code semantics. For retrieval, GRACE employs a Hybrid Graph Retriever that integrates graph neural network-based structural similarity with textual retrieval, refined by a graph attention network-based re-ranker to prioritize topologically relevant subgraphs. To enhance context, GRACE introduces a structural fusion mechanism that merges retrieved subgraphs with the local code context and preserves essential dependencies like function calls and inheritance. Extensive experiments on public repository-level benchmarks demonstrate that GRACE significantly outperforms state-of-the-art methods across all metrics. Using DeepSeek-V3 as the backbone LLM, GRACE surpasses the strongest graph-based RAG baselines by 8.19% EM and 7.51% ES points on every dataset. The code is available at https://anonymous.4open.science/r/grace_icse-C3D5.</p></details> |  |
| **[DRDCAE-STGNN: An End-to-End Discrimina-tive Autoencoder with Spatio-Temporal Graph Learning for Motor Imagery Classification](http://arxiv.org/abs/2509.05943v1)** | 2025-09-07 | <details><summary>Show</summary><p>Motor imagery (MI) based brain-computer interfaces (BCIs) hold significant potential for assistive technologies and neurorehabilitation. However, the precise and efficient decoding of MI remains challenging due to their non-stationary nature and low signal-to-noise ratio. This paper introduces a novel end-to-end deep learning framework of Discriminative Residual Dense Convolutional Autoencoder with Spatio-Temporal Graph Neural Network (DRDCAE-STGNN) to enhance the MI feature learning and classification. Specifically, the DRDCAE module leverages residual-dense connections to learn discriminative latent representations through joint reconstruction and classifica-tion, while the STGNN module captures dynamic spatial dependencies via a learnable graph adjacency matrix and models temporal dynamics using bidirectional long short-term memory (LSTM). Extensive evaluations on BCI Competition IV 2a, 2b, and PhysioNet datasets demonstrate state-of-the-art performance, with average accuracies of 95.42%, 97.51%, and 90.15%, respectively. Ablation studies confirm the contribution of each component, and interpreta-bility analysis reveals neurophysiologically meaningful connectivity patterns. Moreover, despite its complexity, the model maintains a feasible parameter count and an inference time of 0.32 ms per sample. These results indicate that our method offers a robust, accurate, and interpretable solution for MI-EEG decoding, with strong generalizability across subjects and tasks and meeting the requirements for potential real-time BCI applications.</p></details> | <details><summary>Submi...</summary><p>Submit to IEEE Journal</p></details> |
| **[Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures](http://arxiv.org/abs/2508.07423v3)** | 2025-09-06 | <details><summary>Show</summary><p>As the particle physics community needs higher and higher precisions in order to test our current model of the subatomic world, larger and larger datasets are necessary. With upgrades scheduled for the detectors of colliding-beam experiments around the world, and specifically at the Large Hadron Collider at CERN, more collisions and more complex interactions are expected. This directly implies an increase in data produced and consequently in the computational resources needed to process them. At CERN, the amount of data produced is gargantuan. This is why the data have to be heavily filtered and selected in real time before being permanently stored. This data can then be used to perform physics analyses, in order to expand our current understanding of the universe and improve the Standard Model of physics. This real-time filtering, known as triggering, involves complex processing happening often at frequencies as high as 40 MHz. This thesis contributes to understanding how machine learning models can be efficiently deployed in such environments, in order to maximize throughput and minimize energy consumption. Inevitably, modern hardware designed for such tasks and contemporary algorithms are needed in order to meet the challenges posed by the stringent, high-frequency data rates. In this work, I present our graph neural network-based pipeline, developed for charged particle track reconstruction at the LHCb experiment at CERN. The pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely on GPUs. Its performance was compared against the classical tracking algorithms currently in production at LHCb. The pipeline was also accelerated on the FPGA architecture, and its performance in terms of power consumption and processing speed was compared against the GPU implementation.</p></details> | <details><summary>PhD t...</summary><p>PhD thesis, Chapters 8 and 9 include results from work performed in collaboration with Anthony Correia</p></details> |
| **[Pruning Spurious Subgraphs for Graph Out-of-Distribution Generalization](http://arxiv.org/abs/2506.05957v4)** | 2025-09-06 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) often encounter significant performance degradation under distribution shifts between training and test data, hindering their applicability in real-world scenarios. Recent studies have proposed various methods to address the out-of-distribution generalization challenge, with many methods in the graph domain focusing on directly identifying an invariant subgraph that is predictive of the target label. However, we argue that identifying the edges from the invariant subgraph directly is challenging and error-prone, especially when some spurious edges exhibit strong correlations with the targets. In this paper, we propose PrunE, the first pruning-based graph OOD method that eliminates spurious edges to improve OOD generalizability. By pruning spurious edges, PrunE retains the invariant subgraph more comprehensively, which is critical for OOD generalization. Specifically, PrunE employs two regularization terms to prune spurious edges: 1) graph size constraint to exclude uninformative spurious edges, and 2) $\epsilon$-probability alignment to further suppress the occurrence of spurious edges. Through theoretical analysis and extensive experiments, we show that PrunE achieves superior OOD performance and outperforms previous state-of-the-art methods significantly. Codes are available at: \href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.</p></details> | 26 pages, 8 figures |
| **[MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions](http://arxiv.org/abs/2509.05685v1)** | 2025-09-06 | <details><summary>Show</summary><p>Transforming road network data into vector representations using deep learning has proven effective for road network analysis. However, urban road networks' heterogeneous and hierarchical nature poses challenges for accurate representation learning. Graph neural networks, which aggregate features from neighboring nodes, often struggle due to their homogeneity assumption and focus on a single structural scale. To address these issues, this paper presents MSRFormer, a novel road network representation learning framework that integrates multi-scale spatial interactions by addressing their flow heterogeneity and long-distance dependencies. It uses spatial flow convolution to extract small-scale features from large trajectory datasets, and identifies scale-dependent spatial interaction regions to capture the spatial structure of road networks and flow heterogeneity. By employing a graph transformer, MSRFormer effectively captures complex spatial dependencies across multiple scales. The spatial interaction features are fused using residual connections, which are fed to a contrastive learning algorithm to derive the final road network representation. Validation on two real-world datasets demonstrates that MSRFormer outperforms baseline methods in two road network analysis tasks. The performance gains of MSRFormer suggest the traffic-related task benefits more from incorporating trajectory data, also resulting in greater improvements in complex road network structures with up to 16% improvements compared to the most competitive baseline method. This research provides a practical framework for developing task-agnostic road network representation models and highlights distinct association patterns of the interplay between scale effects and flow heterogeneity of spatial interactions.</p></details> |  |
| **[TreeGPT: A Novel Hybrid Architecture for Abstract Syntax Tree Processing with Global Parent-Child Aggregation](http://arxiv.org/abs/2509.05550v1)** | 2025-09-06 | <details><summary>Show</summary><p>We introduce TreeGPT, a novel neural architecture that combines transformer-based attention mechanisms with global parent-child aggregation for processing Abstract Syntax Trees (ASTs) in neural program synthesis tasks. Unlike traditional approaches that rely solely on sequential processing or graph neural networks, TreeGPT employs a hybrid design that leverages both self-attention for capturing local dependencies and a specialized Tree Feed-Forward Network (TreeFFN) for modeling hierarchical tree structures through iterative message passing. The core innovation lies in our Global Parent-Child Aggregation mechanism, formalized as: $$h_i^{(t+1)} = \sigma \Big( h_i^{(0)} + W_{pc} \sum_{(p,c) \in E_i} f(h_p^{(t)}, h_c^{(t)}) + b \Big)$$ where $h_i^{(t)}$ represents the hidden state of node $i$ at iteration $t$, $E_i$ denotes all parent-child edges involving node $i$, and $f(h_p, h_c)$ is an edge aggregation function. This formulation enables each node to progressively aggregate information from the entire tree structure through $T$ iterations. Our architecture integrates optional enhancements including gated aggregation with learnable edge weights, residual connections for gradient stability, and bidirectional propagation for capturing both bottom-up and top-down dependencies. We evaluate TreeGPT on the ARC Prize 2025 dataset, a challenging visual reasoning benchmark requiring abstract pattern recognition and rule inference. Experimental results demonstrate that TreeGPT achieves 96\% accuracy, significantly outperforming transformer baselines (1.3\%), large-scale models like Grok-4 (15.9\%), and specialized program synthesis methods like SOAR (52\%) while using only 1.5M parameters. Our comprehensive ablation study reveals that edge projection is the most critical component, with the combination of edge projection and gating achieving optimal performance.</p></details> | <details><summary>Code ...</summary><p>Code available at: https://github.com/lizixi-0x2F/TreeGPT</p></details> |
| **[Distributed Link Sparsification for Scalable Scheduling Using Graph Neural Networks (Journal Version)](http://arxiv.org/abs/2509.05447v1)** | 2025-09-05 | <details><summary>Show</summary><p>In wireless networks characterized by dense connectivity, the significant signaling overhead generated by distributed link scheduling algorithms can exacerbate issues like congestion, energy consumption, and radio footprint expansion. To mitigate these challenges, we propose a distributed link sparsification scheme employing graph neural networks (GNNs) to reduce scheduling overhead for delay-tolerant traffic while maintaining network capacity. A GNN module is trained to adjust contention thresholds for individual links based on traffic statistics and network topology, enabling links to withdraw from scheduling contention when they are unlikely to succeed. Our approach is facilitated by a novel offline constrained {unsupervised} learning algorithm capable of balancing two competing objectives: minimizing scheduling overhead while ensuring that total utility meets the required level. In simulated wireless multi-hop networks with up to 500 links, our link sparsification technique effectively alleviates network congestion and reduces radio footprints across four distinct distributed link scheduling protocols.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 18 figures, accepted to IEEE Transactions on Wireless Communications. This is the extended journal version of the conference paper arXiv:2203.14339 (Z. Zhao, A. Swami and S. Segarra, "Distributed Link Sparsification for Scalable Scheduling using Graph Neural Networks," IEEE ICASSP 2022, pp. 5308-5312, doi: 10.1109/ICASSP43922.2022.9747437 )</p></details> |
| **[Safeguarding Graph Neural Networks against Topology Inference Attacks](http://arxiv.org/abs/2509.05429v1)** | 2025-09-05 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have emerged as powerful models for learning from graph-structured data. However, their widespread adoption has raised serious privacy concerns. While prior research has primarily focused on edge-level privacy, a critical yet underexplored threat lies in topology privacy - the confidentiality of the graph's overall structure. In this work, we present a comprehensive study on topology privacy risks in GNNs, revealing their vulnerability to graph-level inference attacks. To this end, we propose a suite of Topology Inference Attacks (TIAs) that can reconstruct the structure of a target training graph using only black-box access to a GNN model. Our findings show that GNNs are highly susceptible to these attacks, and that existing edge-level differential privacy mechanisms are insufficient as they either fail to mitigate the risk or severely compromise model accuracy. To address this challenge, we introduce Private Graph Reconstruction (PGR), a novel defense framework designed to protect topology privacy while maintaining model accuracy. PGR is formulated as a bi-level optimization problem, where a synthetic training graph is iteratively generated using meta-gradients, and the GNN model is concurrently updated based on the evolving graph. Extensive experiments demonstrate that PGR significantly reduces topology leakage with minimal impact on model accuracy. Our code is anonymously available at https://github.com/JeffffffFu/PGR.</p></details> | <details><summary>Accte...</summary><p>Acctepted by ACM CCS'25</p></details> |
| **[Learning to accelerate distributed ADMM using graph neural networks](http://arxiv.org/abs/2509.05288v1)** | 2025-09-05 | <details><summary>Show</summary><p>Distributed optimization is fundamental in large-scale machine learning and control applications. Among existing methods, the Alternating Direction Method of Multipliers (ADMM) has gained popularity due to its strong convergence guarantees and suitability for decentralized computation. However, ADMM often suffers from slow convergence and sensitivity to hyperparameter choices. In this work, we show that distributed ADMM iterations can be naturally represented within the message-passing framework of graph neural networks (GNNs). Building on this connection, we propose to learn adaptive step sizes and communication weights by a graph neural network that predicts the hyperparameters based on the iterates. By unrolling ADMM for a fixed number of iterations, we train the network parameters end-to-end to minimize the final iterates error for a given problem class, while preserving the algorithm's convergence properties. Numerical experiments demonstrate that our learned variant consistently improves convergence speed and solution quality compared to standard ADMM. The code is available at https://github.com/paulhausner/learning-distributed-admm.</p></details> | <details><summary>Under...</summary><p>Under review, the first two authors contributed equally</p></details> |
| **[Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability](http://arxiv.org/abs/2509.03547v2)** | 2025-09-05 | <details><summary>Show</summary><p>This study introduces MatterVial, an innovative hybrid framework for feature-based machine learning in materials science. MatterVial expands the feature space by integrating latent representations from a diverse suite of pretrained graph neural network (GNN) models including: structure-based (MEGNet), composition-based (ROOST), and equivariant (ORB) graph networks, with computationally efficient, GNN-approximated descriptors and novel features from symbolic regression. Our approach combines the chemical transparency of traditional feature-based models with the predictive power of deep learning architectures. When augmenting the feature-based model MODNet on Matbench tasks, this method yields significant error reductions and elevates its performance to be competitive with, and in several cases superior to, state-of-the-art end-to-end GNNs, with accuracy increases exceeding 40% for multiple tasks. An integrated interpretability module, employing surrogate models and symbolic regression, decodes the latent GNN-derived descriptors into explicit, physically meaningful formulas. This unified framework advances materials informatics by providing a high-performance, transparent tool that aligns with the principles of explainable AI, paving the way for more targeted and autonomous materials discovery.</p></details> |  |
| **[RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks](http://arxiv.org/abs/2509.05207v1)** | 2025-09-05 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have become popular across a diverse set of tasks in exploring structural relationships between entities. However, due to the highly connected structure of the datasets, distributed training of GNNs on large-scale graphs poses significant challenges. Traditional sampling-based approaches mitigate the computational loads, yet the communication overhead remains a challenge. This paper presents RapidGNN, a distributed GNN training framework with deterministic sampling-based scheduling to enable efficient cache construction and prefetching of remote features. Evaluation on benchmark graph datasets demonstrates RapidGNN's effectiveness across different scales and topologies. RapidGNN improves end-to-end training throughput by 2.46x to 3.00x on average over baseline methods across the benchmark datasets, while cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further demonstrates near-linear scalability with an increasing number of computing units efficiently. Furthermore, it achieves increased energy efficiency over the baseline methods for both CPU and GPU by 44% and 32%, respectively.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2505.10806</p></details> |
| **[RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](http://arxiv.org/abs/2509.05397v1)** | 2025-09-05 | <details><summary>Show</summary><p>Modern robotic manufacturing requires collision-free coordination of multiple robots to complete numerous tasks in shared, obstacle-rich workspaces. Although individual tasks may be simple in isolation, automated joint task allocation, scheduling, and motion planning under spatio-temporal constraints remain computationally intractable for classical methods at real-world scales. Existing multi-arm systems deployed in the industry rely on human intuition and experience to design feasible trajectories manually in a labor-intensive process. To address this challenge, we propose a reinforcement learning (RL) framework to achieve automated task and motion planning, tested in an obstacle-rich environment with eight robots performing 40 reaching tasks in a shared workspace, where any robot can perform any task in any order. Our approach builds on a graph neural network (GNN) policy trained via RL on procedurally-generated environments with diverse obstacle layouts, robot configurations, and task distributions. It employs a graph representation of scenes and a graph policy neural network trained through reinforcement learning to generate trajectories of multiple robots, jointly solving the sub-problems of task allocation, scheduling, and motion planning. Trained on large randomly generated task sets in simulation, our policy generalizes zero-shot to unseen settings with varying robot placements, obstacle geometries, and task poses. We further demonstrate that the high-speed capability of our solution enables its use in workcell layout optimization, improving solution times. The speed and scalability of our planner also open the door to new capabilities such as fault-tolerant planning and online perception-based re-planning, where rapid adaptation to dynamic task sets is required.</p></details> | <details><summary>Publi...</summary><p>Published in Science Robotics</p></details> |
| **[Hybrid Matrix Factorization Based Graph Contrastive Learning for Recommendation System](http://arxiv.org/abs/2509.05115v1)** | 2025-09-05 | <details><summary>Show</summary><p>In recent years, methods that combine contrastive learning with graph neural networks have emerged to address the challenges of recommendation systems, demonstrating powerful performance and playing a significant role in this domain. Contrastive learning primarily tackles the issue of data sparsity by employing data augmentation strategies, effectively alleviating this problem and showing promising results. Although existing research has achieved favorable outcomes, most current graph contrastive learning methods are based on two types of data augmentation strategies: the first involves perturbing the graph structure, such as by randomly adding or removing edges; and the second applies clustering techniques. We believe that the interactive information obtained through these two strategies does not fully capture the user-item interactions. In this paper, we propose a novel method called HMFGCL (Hybrid Matrix Factorization Based Graph Contrastive Learning), which integrates two distinct matrix factorization techniques-low-rank matrix factorization (MF) and singular value decomposition (SVD)-to complementarily acquire global collaborative information, thereby constructing enhanced views. Experimental results on multiple public datasets demonstrate that our model outperforms existing baselines, particularly on small-scale datasets.</p></details> |  |
| **[Graph Unlearning: Efficient Node Removal in Graph Neural Networks](http://arxiv.org/abs/2509.04785v1)** | 2025-09-05 | <details><summary>Show</summary><p>With increasing concerns about privacy attacks and potential sensitive information leakage, researchers have actively explored methods to efficiently remove sensitive training data and reduce privacy risks in graph neural network (GNN) models. Node unlearning has emerged as a promising technique for protecting the privacy of sensitive nodes by efficiently removing specific training node information from GNN models. However, existing node unlearning methods either impose restrictions on the GNN structure or do not effectively utilize the graph topology for node unlearning. Some methods even compromise the graph's topology, making it challenging to achieve a satisfactory performance-complexity trade-off. To address these issues and achieve efficient unlearning for training node removal in GNNs, we propose three novel node unlearning methods: Class-based Label Replacement, Topology-guided Neighbor Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among these methods, Topology-guided Neighbor Mean Posterior Probability and Class-consistent Neighbor Node Filtering effectively leverage the topological features of the graph, resulting in more effective node unlearning. To validate the superiority of our proposed methods in node unlearning, we conducted experiments on three benchmark datasets. The evaluation criteria included model utility, unlearning utility, and unlearning efficiency. The experimental results demonstrate the utility and efficiency of the proposed methods and illustrate their superiority compared to state-of-the-art node unlearning methods. Overall, the proposed methods efficiently remove sensitive training nodes and protect the privacy information of sensitive nodes in GNNs. The findings contribute to enhancing the privacy and security of GNN models and provide valuable insights into the field of node unlearning.</p></details> |  |
| **[Inferring the Graph Structure of Images for Graph Neural Networks](http://arxiv.org/abs/2509.04677v1)** | 2025-09-04 | <details><summary>Show</summary><p>Image datasets such as MNIST are a key benchmark for testing Graph Neural Network (GNN) architectures. The images are traditionally represented as a grid graph with each node representing a pixel and edges connecting neighboring pixels (vertically and horizontally). The graph signal is the values (intensities) of each pixel in the image. The graphs are commonly used as input to graph neural networks (e.g., Graph Convolutional Neural Networks (Graph CNNs) [1, 2], Graph Attention Networks (GAT) [3], GatedGCN [4]) to classify the images. In this work, we improve the accuracy of downstream graph neural network tasks by finding alternative graphs to the grid graph and superpixel methods to represent the dataset images, following the approach in [5, 6]. We find row correlation, column correlation, and product graphs for each image in MNIST and Fashion-MNIST using correlations between the pixel values building on the method in [5, 6]. Experiments show that using these different graph representations and features as input into downstream GNN models improves the accuracy over using the traditional grid graph and superpixel methods in the literature.</p></details> |  |
| **[Comment on "A Note on Over-Smoothing for Graph Neural Networks"](http://arxiv.org/abs/2509.04178v1)** | 2025-09-04 | <details><summary>Show</summary><p>We comment on Cai and Wang (2020, arXiv:2006.13318), who analyze over-smoothing in GNNs via Dirichlet energy. We show that under mild spectral conditions (including with Leaky-ReLU), the Dirichlet energy of node embeddings decreases exponentially with depth; we further extend the result to spectral polynomial filters and provide a short proof for the Leaky-ReLU case. Experiments on edge deletion and weight amplification illustrate when Dirichlet energy increases, hinting at practical ways to relieve over-smoothing.</p></details> | <details><summary>Comme...</summary><p>Comment on arXiv:2006.13318 (Cai & Wang, 2020). Revisits their Dirichlet-energy analysis of over-smoothing and extends it to Leaky-ReLU and spectral polynomial filters; includes Proposition 7.1 and a new proof of Lemma 3.3 for Leaky-ReLU. 7 pages</p></details> |
| **[Plugging Attention into Power Grids: Towards Transparent Forecasting](http://arxiv.org/abs/2507.03690v2)** | 2025-09-04 | <details><summary>Show</summary><p>Reliable prediction of electricity demand plays a key role in safeguarding grid stability and guiding generation decisions, a need that grows with the decentralization and complexity of modern systems. While classical approaches such as Generalized Additive Models (GAMs) remain widely used, they often fail to capture the spatial dependencies inherent in energy networks. Graph Neural Networks (GNNs) offer a principled framework to incorporate this structure by directly leveraging graph topologies. In this work, we evaluate a broad set of GNN architectures -- including GCN, GraphSAGE, ChebConv, TAG, APPNP, TransformerConv, and Graph Attention Networks (GAT and GATv2) -- on two real-world electricity consumption datasets from France and the UK. Our results show that simpler models such as GCN, SAGE, or APPNP often outperform more complex alternatives in low-data regimes, while GAT ranks among the strongest architectures in our benchmarks, combining high accuracy with valuable interpretability. We perform a temporal analysis of attention weights, revealing evolving patterns of regional interaction linked to seasonal and meteorological variability. These results highlight that, although attention is not universally superior, it provides valuable explanatory power when spatial dependencies are prominent. Additionally, we demonstrate that ensemble-based expert aggregation strategies, particularly bottom-up combinations, significantly improve robustness and yield state-of-the-art performance across both datasets. These findings highlight the dual promise of GNNs for accurate and interpretable forecasting, and suggest that architectural simplicity coupled with ensemble methods can provide a practical path forward for transparent energy analytics.</p></details> | <details><summary>16 pa...</summary><p>16 pages, ECML PKDD 2025 Workshop paper</p></details> |
| **[Topotein: Topological Deep Learning for Protein Representation Learning](http://arxiv.org/abs/2509.03885v1)** | 2025-09-04 | <details><summary>Show</summary><p>Protein representation learning (PRL) is crucial for understanding structure-function relationships, yet current sequence- and graph-based methods fail to capture the hierarchical organization inherent in protein structures. We introduce Topotein, a comprehensive framework that applies topological deep learning to PRL through the novel Protein Combinatorial Complex (PCC) and Topology-Complete Perceptron Network (TCPNet). Our PCC represents proteins at multiple hierarchical levels -- from residues to secondary structures to complete proteins -- while preserving geometric information at each level. TCPNet employs SE(3)-equivariant message passing across these hierarchical structures, enabling more effective capture of multi-scale structural patterns. Through extensive experiments on four PRL tasks, TCPNet consistently outperforms state-of-the-art geometric graph neural networks. Our approach demonstrates particular strength in tasks such as fold classification which require understanding of secondary structure arrangements, validating the importance of hierarchical topological features for protein analysis.</p></details> |  |
| **[EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection](http://arxiv.org/abs/2509.01153v2)** | 2025-09-04 | <details><summary>Show</summary><p>Auscultation is a key method for early diagnosis of respiratory and pulmonary diseases, relying on skilled healthcare professionals. However, the process is often subjective, with variability between experts. As a result, numerous deep learning-based automatic classification methods have emerged, most of which focus on respiratory sound classification. In contrast, research on respiratory sound event detection remains limited. Existing sound event detection methods typically rely on frame-level predictions followed by post-processing to generate event-level outputs, making interval boundaries challenging to learn directly. Furthermore, many approaches can only handle fixed-length audio, limiting their applicability to variable-length respiratory sounds. Additionally, the impact of respiratory sound location information on detection performance has not been extensively explored. To address these issues, we propose a graph neural network-based framework with anchor intervals, capable of handling variable-length audio and providing more precise temporal localization for abnormal respiratory sound events. Our method improves both the flexibility and applicability of respiratory sound detection. Experiments on the SPRSound 2024 and HF Lung V1 datasets demonstrate the effectiveness of the proposed approach, and incorporating respiratory position information enhances the discrimination between abnormal sounds. The reference implementation is available at https://github.com/chumingqian/EzhouNet.</p></details> |  |
| **[Graph neural networks for learning liquid simulations in dynamic scenes containing kinematic objects](http://arxiv.org/abs/2509.03446v1)** | 2025-09-03 | <details><summary>Show</summary><p>Simulating particle dynamics with high fidelity is crucial for solving real-world interaction and control tasks involving liquids in design, graphics, and robotics. Recently, data-driven approaches, particularly those based on graph neural networks (GNNs), have shown progress in tackling such problems. However, these approaches are often limited to learning fluid behavior in static free-fall environments or simple manipulation settings involving primitive objects, often overlooking complex interactions with dynamically moving kinematic rigid bodies. Here, we propose a GNN-based framework designed from the ground up to learn the dynamics of liquids under rigid body interactions and active manipulations, where particles are represented as graph nodes and particle-object collisions are handled using surface representations with the bounding volume hierarchy (BVH) algorithm. This approach enables the network to model complex interactions between liquid particles and intricate surface geometries. Our model accurately captures fluid behavior in dynamic settings and can also function as a simulator in static free-fall environments. Despite being trained on a single-object manipulation task of pouring, our model generalizes effectively to environments with unseen objects and novel manipulation tasks such as stirring and scooping. Finally, we show that the learned dynamics can be leveraged to solve control and manipulation tasks using gradient-based optimization methods.</p></details> |  |
| **[Exploring a Graph-based Approach to Offline Reinforcement Learning for Sepsis Treatment](http://arxiv.org/abs/2509.03393v1)** | 2025-09-03 | <details><summary>Show</summary><p>Sepsis is a serious, life-threatening condition. When treating sepsis, it is challenging to determine the correct amount of intravenous fluids and vasopressors for a given patient. While automated reinforcement learning (RL)-based methods have been used to support these decisions with promising results, previous studies have relied on relational data. Given the complexity of modern healthcare data, representing data as a graph may provide a more natural and effective approach. This study models patient data from the well-known MIMIC-III dataset as a heterogeneous graph that evolves over time. Subsequently, we explore two Graph Neural Network architectures - GraphSAGE and GATv2 - for learning patient state representations, adopting the approach of decoupling representation learning from policy learning. The encoders are trained to produce latent state representations, jointly with decoders that predict the next patient state. These representations are then used for policy learning with the dBCQ algorithm. The results of our experimental evaluation confirm the potential of a graph-based approach, while highlighting the complexity of representation learning in this domain.</p></details> | <details><summary>18th ...</summary><p>18th European Workshop on Reinforcement Learning (EWRL 2025)</p></details> |
| **[Transformer-Guided Content-Adaptive Graph Learning for Hyperspectral Unmixing](http://arxiv.org/abs/2509.03376v1)** | 2025-09-03 | <details><summary>Show</summary><p>Hyperspectral unmixing (HU) targets to decompose each mixed pixel in remote sensing images into a set of endmembers and their corresponding abundances. Despite significant progress in this field using deep learning, most methods fail to simultaneously characterize global dependencies and local consistency, making it difficult to preserve both long-range interactions and boundary details. This letter proposes a novel transformer-guided content-adaptive graph unmixing framework (T-CAGU), which overcomes these challenges by employing a transformer to capture global dependencies and introducing a content-adaptive graph neural network to enhance local relationships. Unlike previous work, T-CAGU integrates multiple propagation orders to dynamically learn the graph structure, ensuring robustness against noise. Furthermore, T-CAGU leverages a graph residual mechanism to preserve global information and stabilize training. Experimental results demonstrate its superiority over the state-of-the-art methods. Our code is available at https://github.com/xianchaoxiu/T-CAGU.</p></details> |  |
| **[Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP](http://arxiv.org/abs/2508.08005v2)** | 2025-09-03 | <details><summary>Show</summary><p>Extensive experiments and prior studies show that no single maximum clique algorithm consistently performs best across all instances, highlighting the importance of selecting suitable algorithms based on instance features. Through an extensive analysis of relevant studies, it is found that there is a lack of research work concerning algorithm selection oriented toward the Maximum Clique Problem (MCP). In this work, we propose a learning-based framework that integrates both traditional machine learning and graph neural networks to address this gap. We construct a labeled dataset by running four exact MCP algorithms on a diverse collection of graph instances, accompanied by structural and global statistical features extracted from each graph. We first evaluate four conventional classifiers: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple dataset variants. Experimental results show that RF consistently shows strong performance across metrics and dataset variants, making it a reliable baseline. In addition, feature importance analysis indicates that connectivity and topological structure are strong predictors of algorithm performance. Building on these findings, we develop a dual-channel model named GAT-MLP, which combines a Graph Attention Network (GAT) for local structural encoding with a Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model shows strong and consistent performance across all metrics. Our results highlight the effectiveness of dual-channel architectures and the promise of graph neural networks in combinatorial algorithm selection.</p></details> | 10 pages, 6 figures |
| **[Temporal social network modeling of mobile connectivity data with graph neural networks](http://arxiv.org/abs/2509.03319v1)** | 2025-09-03 | <details><summary>Show</summary><p>Graph neural networks (GNNs) have emerged as a state-of-the-art data-driven tool for modeling connectivity data of graph-structured complex networks and integrating information of their nodes and edges in space and time. However, as of yet, the analysis of social networks using the time series of people's mobile connectivity data has not been extensively investigated. In the present study, we investigate four snapshot - based temporal GNNs in predicting the phone call and SMS activity between users of a mobile communication network. In addition, we develop a simple non - GNN baseline model using recently proposed EdgeBank method. Our analysis shows that the ROLAND temporal GNN outperforms the baseline model in most cases, whereas the other three GNNs perform on average worse than the baseline. The results show that GNN based approaches hold promise in the analysis of temporal social networks through mobile connectivity data. However, due to the relatively small performance margin between ROLAND and the baseline model, further research is required on specialized GNN architectures for temporal social network analysis.</p></details> | 22 pages, 7 figures |
| **[Can Large Language Models Act as Ensembler for Multi-GNNs?](http://arxiv.org/abs/2410.16822v5)** | 2025-09-03 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have emerged as powerful models for learning from graph-structured data. However, GNNs lack the inherent semantic understanding capability of rich textual node attributes, limiting their effectiveness in applications. On the other hand, we empirically observe that for existing GNN models, no one can consistently outperforms others across diverse datasets. In this paper, we study whether LLMs can act as an ensembler for multi-GNNs and propose the LensGNN model. The model first aligns multiple GNNs, mapping the representations of different GNNs into the same space. Then, through LoRA fine-tuning, it aligns the space between the GNN and the LLM, injecting graph tokens and textual information into LLMs. This allows LensGNN to ensemble multiple GNNs and take advantage of the strengths of LLM, leading to a deeper understanding of both textual semantic information and graph structural information. The experimental results show that LensGNN outperforms existing models. This research advances text-attributed graph ensemble learning by providing a robust and superior solution for integrating semantic and structural information. We provide our code and data here: https://github.com/AquariusAQ/LensGNN.</p></details> |  |
| **[Rashomon in the Streets: Explanation Ambiguity in Scene Understanding](http://arxiv.org/abs/2509.03169v1)** | 2025-09-03 | <details><summary>Show</summary><p>Explainable AI (XAI) is essential for validating and trusting models in safety-critical applications like autonomous driving. However, the reliability of XAI is challenged by the Rashomon effect, where multiple, equally accurate models can offer divergent explanations for the same prediction. This paper provides the first empirical quantification of this effect for the task of action prediction in real-world driving scenes. Using Qualitative Explainable Graphs (QXGs) as a symbolic scene representation, we train Rashomon sets of two distinct model classes: interpretable, pair-based gradient boosting models and complex, graph-based Graph Neural Networks (GNNs). Using feature attribution methods, we measure the agreement of explanations both within and between these classes. Our results reveal significant explanation disagreement. Our findings suggest that explanation ambiguity is an inherent property of the problem, not just a modeling artifact.</p></details> | <details><summary>AAAI ...</summary><p>AAAI 2025 Fall Symposium: AI Trustworthiness and Risk Assessment for Challenged Contexts (ATRACC)</p></details> |
| **[Memorization in Graph Neural Networks](http://arxiv.org/abs/2508.19352v3)** | 2025-09-03 | <details><summary>Show</summary><p>Deep neural networks (DNNs) have been shown to memorize their training data, yet similar analyses for graph neural networks (GNNs) remain largely under-explored. We introduce NCMemo (Node Classification Memorization), the first framework to quantify label memorization in semi-supervised node classification. We first establish an inverse relationship between memorization and graph homophily, i.e., the property that connected nodes share similar labels/features. We find that lower homophily significantly increases memorization, indicating that GNNs rely on memorization to learn less homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the increased memorization in low homophily graphs is tightly coupled to the GNNs' implicit bias on using graph structure during learning. In low homophily regimes, this structure is less informative, hence inducing memorization of the node labels to minimize training loss. Finally, we show that nodes with higher label inconsistency in their feature-space neighborhood are significantly more prone to memorization. Building on our insights into the link between graph homophily and memorization, we investigate graph rewiring as a means to mitigate memorization. Our results demonstrate that this approach effectively reduces memorization without compromising model performance. Moreover, we show that it lowers the privacy risk for previously memorized data points in practice. Thus, our work not only advances understanding of GNN learning but also supports more privacy-preserving GNN deployment.</p></details> | <details><summary>Versi...</summary><p>Version3, updated affiliation</p></details> |
| **[TRELLIS-Enhanced Surface Features for Comprehensive Intracranial Aneurysm Analysis](http://arxiv.org/abs/2509.03095v1)** | 2025-09-03 | <details><summary>Show</summary><p>Intracranial aneurysms pose a significant clinical risk yet are difficult to detect, delineate and model due to limited annotated 3D data. We propose a cross-domain feature-transfer approach that leverages the latent geometric embeddings learned by TRELLIS, a generative model trained on large-scale non-medical 3D datasets, to augment neural networks for aneurysm analysis. By replacing conventional point normals or mesh descriptors with TRELLIS surface features, we systematically enhance three downstream tasks: (i) classifying aneurysms versus healthy vessels in the Intra3D dataset, (ii) segmenting aneurysm and vessel regions on 3D meshes, and (iii) predicting time-evolving blood-flow fields using a graph neural network on the AnXplore dataset. Our experiments show that the inclusion of these features yields strong gains in accuracy, F1-score and segmentation quality over state-of-the-art baselines, and reduces simulation error by 15\%. These results illustrate the broader potential of transferring 3D representations from general-purpose generative models to specialized medical tasks.</p></details> |  |
| **[Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference](http://arxiv.org/abs/2505.16893v2)** | 2025-09-03 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have gained prominence for their ability to process graph-structured data across various domains. However, interpreting GNN decisions remains a significant challenge, leading to the adoption of saliency maps for identifying salient subgraphs composed of influential nodes and edges. Despite their utility, the reliability of GNN saliency maps has been questioned, particularly in terms of their robustness to input noise. In this study, we propose a statistical testing framework to rigorously evaluate the significance of saliency maps. Our main contribution lies in addressing the inflation of the Type I error rate caused by double-dipping of data, leveraging the framework of Selective Inference. Our method provides statistically valid $p$-values while controlling the Type I error rate, ensuring that identified salient subgraphs contain meaningful information rather than random artifacts. The method is applicable to a variety of saliency methods with piecewise linearity (e.g., Class Activation Mapping). We validate our method on synthetic and real-world datasets, demonstrating its capability in assessing the reliability of GNN interpretations.</p></details> |  |
| **[Unsupervised Learning of Local Updates for Maximum Independent Set in Dynamic Graphs](http://arxiv.org/abs/2505.13754v2)** | 2025-09-03 | <details><summary>Show</summary><p>We present the first unsupervised learning model for finding Maximum Independent Sets (MaxIS) in dynamic graphs where edges change over time. Our method combines structural learning from graph neural networks (GNNs) with a learned distributed update mechanism that, given an edge addition or deletion event, modifies nodes' internal memories and infers their MaxIS membership in a single, parallel step. We parameterize our model by the update mechanism's radius and investigate the resulting performance-runtime tradeoffs for various dynamic graph topologies. We evaluate our model against a mixed integer programming solver and the state-of-the-art learning-based methods for MaxIS on static graphs (ICML 2020; NeurIPS 2020, 2023). Across synthetic and empirical dynamic graphs of 50-1,000 nodes, our model achieves competitive approximation ratios with excellent scalability; on large graphs, it significantly outperforms the state-of-the-art learning methods in solution quality, runtime, and memory usage. When generalizing to graphs of 10,000 nodes (100x larger than the ones used for training), our model produces MaxIS solutions 1.05-1.18x larger than any other learning method, even while maintaining competitive runtimes.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 2 figures, 2 tables, 3 algorithms</p></details> |
| **[RankGraph: Unified Heterogeneous Graph Learning for Cross-Domain Recommendation](http://arxiv.org/abs/2509.02942v1)** | 2025-09-03 | <details><summary>Show</summary><p>Cross-domain recommendation systems face the challenge of integrating fine-grained user and item relationships across various product domains. To address this, we introduce RankGraph, a scalable graph learning framework designed to serve as a core component in recommendation foundation models (FMs). By constructing and leveraging graphs composed of heterogeneous nodes and edges across multiple products, RankGraph enables the integration of complex relationships between users, posts, ads, and other entities. Our framework employs a GPU-accelerated Graph Neural Network and contrastive learning, allowing for dynamic extraction of subgraphs such as item-item and user-user graphs to support similarity-based retrieval and real-time clustering. Furthermore, RankGraph integrates graph-based pretrained representations as contextual tokens into FM sequence models, enriching them with structured relational knowledge. RankGraph has demonstrated improvements in click (+0.92%) and conversion rates (+2.82%) in online A/B tests, showcasing its effectiveness in cross-domain recommendation scenarios.</p></details> | RecSys 2025 |
| **[PDRL: Post-hoc Descriptor-based Residual Learning for Uncertainty-Aware Machine Learning Potentials](http://arxiv.org/abs/2509.02927v1)** | 2025-09-03 | <details><summary>Show</summary><p>Ensemble method is considered the gold standard for uncertainty quantification (UQ) for machine learning interatomic potentials (MLIPs). However, their high computational cost can limit its practicality. Alternative techniques, such as Monte Carlo dropout and deep kernel learning, have been proposed to improve computational efficiency; however, some of these methods cannot be applied to already trained models and may affect the prediction accuracy. In this paper, we propose a simple and efficient post-hoc framework for UQ that leverages the descriptor of a trained graph neural network potential to estimate residual errors. We refer to this method as post-hoc descriptor-based residual-based learning (PDRL). PDRL models the discrepancy between MLIP predictions and ground truth values, allowing these residuals to act as proxies for prediction uncertainty. We explore multiple variants of PDRL and benchmark them against established UQ methods, evaluating both their effectiveness and limitations.</p></details> |  |
| **[FedGraph: A Research Library and Benchmark for Federated Graph Learning](http://arxiv.org/abs/2410.06340v4)** | 2025-09-02 | <details><summary>Show</summary><p>Federated graph learning is an emerging field with significant practical challenges. While algorithms have been proposed to improve the accuracy of training graph neural networks, such as node classification on federated graphs, the system performance is often overlooked, despite it is crucial for real-world deployment. To bridge this gap, we introduce FedGraph, a research library designed for practical distributed training and comprehensive benchmarking of FGL algorithms. FedGraph supports a range of state-of-the-art graph learning methods and includes a monitoring class that evaluates system performance, with a particular focus on communication and computation costs during training. Unlike existing federated learning platforms, FedGraph natively integrates homomorphic encryption to enhance privacy preservation and supports scalable deployment across multiple physical machines with system-level performance evaluation to guide the system design of future algorithms. To enhance efficiency and privacy, we propose a low-rank communication scheme for algorithms like FedGCN that require pre-training communication, accelerating both the pre-training and training phases. Extensive experiments benchmark FGL algorithms on three major graph learning tasks and demonstrate FedGraph as the first efficient FGL framework to support encrypted low-rank communication and scale to graphs with 100 million nodes.</p></details> | <details><summary>https...</summary><p>https://github.com/FedGraph/fedgraph</p></details> |
| **[Power Grid Control with Graph-Based Distributed Reinforcement Learning](http://arxiv.org/abs/2509.02861v1)** | 2025-09-02 | <details><summary>Show</summary><p>The necessary integration of renewable energy sources, combined with the expanding scale of power networks, presents significant challenges in controlling modern power grids. Traditional control systems, which are human and optimization-based, struggle to adapt and to scale in such an evolving context, motivating the exploration of more dynamic and distributed control strategies. This work advances a graph-based distributed reinforcement learning framework for real-time, scalable grid management. The proposed architecture consists of a network of distributed low-level agents acting on individual power lines and coordinated by a high-level manager agent. A Graph Neural Network (GNN) is employed to encode the network's topological information within the single low-level agent's observation. To accelerate convergence and enhance learning stability, the framework integrates imitation learning and potential-based reward shaping. In contrast to conventional decentralized approaches that decompose only the action space while relying on global observations, this method also decomposes the observation space. Each low-level agent acts based on a structured and informative local view of the environment constructed through the GNN. Experiments on the Grid2Op simulation environment show the effectiveness of the approach, which consistently outperforms the standard baseline commonly adopted in the field. Additionally, the proposed model proves to be much more computationally efficient than the simulation-based Expert method.</p></details> |  |
| **[Learning Laplacian Eigenvectors: a Pre-training Method for Graph Neural Networks](http://arxiv.org/abs/2509.02803v1)** | 2025-09-02 | <details><summary>Show</summary><p>We propose a novel framework for pre-training Graph Neural Networks (GNNs) by inductively learning Laplacian eigenvectors. Traditional Message Passing Neural Networks (MPNNs) often struggle to capture global and regional graph structure due to over-smoothing risk as network depth increases. Because the low-frequency eigenvectors of the graph Laplacian matrix encode global information, pre-training GNNs to predict these eigenvectors encourages the network to naturally learn large-scale structural patterns over each graph. Empirically, we show that models pre-trained via our framework outperform baseline models on a variety of graph structure-based tasks. While most existing pre-training methods focus on domain-specific tasks like node or edge feature reconstruction, our self-supervised pre-training framework is structure-based and highly flexible. Eigenvector-learning can be applied to all graph-based datasets, and can be used with synthetic features when task-specific data is sparse.</p></details> |  |
| **[Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification](http://arxiv.org/abs/2305.04228v4)** | 2025-09-02 | <details><summary>Show</summary><p>Code classification is a difficult issue in program understanding and automatic coding. Due to the elusive syntax and complicated semantics in programs, most existing studies use techniques based on abstract syntax tree (AST) and graph neural networks (GNN) to create code representations for code classification. These techniques utilize the structure and semantic information of the code, but they only take into account pairwise associations and neglect the high-order data correlations that already exist between nodes of the same field or called attribute in the AST, which may result in the loss of code structural information. On the other hand, while a general hypergraph can encode high-order data correlations, it is homogeneous and undirected which will result in a lack of semantic and structural information such as node types, edge types, and directions between child nodes and parent nodes when modeling AST. In this study, we propose a heterogeneous directed hypergraph (HDHG) to represent AST and a heterogeneous directed hypergraph neural network (HDHGN) to process the graph for code classification. Our method improves code understanding and can represent high-order data correlations beyond paired interactions. We assess our heterogeneous directed hypergraph neural network (HDHGN) on public datasets of Python and Java programs. Our method outperforms previous AST-based and GNN-based methods, which demonstrates the capability of our model.</p></details> | <details><summary>Publi...</summary><p>Published in the 35th International Conference on Software Engineering and Knowledge Engineering (SEKE 2023) as a regular paper</p></details> |
| **[HydroGAT: Distributed Heterogeneous Graph Attention Transformer for Spatiotemporal Flood Prediction](http://arxiv.org/abs/2509.02481v1)** | 2025-09-02 | <details><summary>Show</summary><p>Accurate flood forecasting remains a challenge for water-resource management, as it demands modeling of local, time-varying runoff drivers (e.g., rainfall-induced peaks, baseflow trends) and complex spatial interactions across a river network. Traditional data-driven approaches, such as convolutional networks and sequence-based models, ignore topological information about the region. Graph Neural Networks (GNNs) propagate information exactly along the river network, which is ideal for learning hydrological routing. However, state-of-the-art GNN-based flood prediction models collapse pixels to coarse catchment polygons as the cost of training explodes with graph size and higher resolution. Furthermore, most existing methods treat spatial and temporal dependencies separately, either applying GNNs solely on spatial graphs or transformers purely on temporal sequences, thus failing to simultaneously capture spatiotemporal interactions critical for accurate flood prediction. We introduce a heterogenous basin graph where every land and river pixel is a node connected by physical hydrological flow directions and inter-catchment relationships. We propose HydroGAT, a spatiotemporal network that adaptively learns local temporal importance and the most influential upstream locations. Evaluated in two Midwestern US basins and across five baseline architectures, our model achieves higher NSE (up to 0.97), improved KGE (up to 0.96), and low bias (PBIAS within $\pm$5%) in hourly discharge prediction, while offering interpretable attention maps that reveal sparse, structured intercatchment influences. To support high-resolution basin-scale training, we develop a distributed data-parallel pipeline that scales efficiently up to 64 NVIDIA A100 GPUs on NERSC Perlmutter supercomputer, demonstrating up to 15x speedup across machines. Our code is available at https://github.com/swapp-lab/HydroGAT.</p></details> | <details><summary>Accep...</summary><p>Accepted to The 33rd ACM International Conference on Advances in Geographic Information Systems (SIGSPATIAL 25)</p></details> |
| **[Automating Traffic Monitoring with SHM Sensor Networks via Vision-Supervised Deep Learning](http://arxiv.org/abs/2506.19023v2)** | 2025-09-02 | <details><summary>Show</summary><p>Bridges, as critical components of civil infrastructure, are increasingly affected by deterioration, making reliable traffic monitoring essential for assessing their remaining service life. Among operational loads, traffic load plays a pivotal role, and recent advances in deep learning - particularly in computer vision (CV) - have enabled progress toward continuous, automated monitoring. However, CV-based approaches suffer from limitations, including privacy concerns and sensitivity to lighting conditions, while traditional non-vision-based methods often lack flexibility in deployment and validation. To bridge this gap, we propose a fully automated deep-learning pipeline for continuous traffic monitoring using structural health monitoring (SHM) sensor networks. Our approach integrates CV-assisted high-resolution dataset generation with supervised training and inference, leveraging graph neural networks (GNNs) to capture the spatial structure and interdependence of sensor data. By transferring knowledge from CV outputs to SHM sensors, the proposed framework enables sensor networks to achieve comparable accuracy of vision-based systems, with minimal human intervention. Applied to accelerometer and strain gauge data in a real-world case study, the model achieves state-of-the-art performance, with classification accuracies of 99% for light vehicles and 94% for heavy vehicles.</p></details> |  |
| **[NOOUGAT: Towards Unified Online and Offline Multi-Object Tracking](http://arxiv.org/abs/2509.02111v1)** | 2025-09-02 | <details><summary>Show</summary><p>The long-standing division between \textit{online} and \textit{offline} Multi-Object Tracking (MOT) has led to fragmented solutions that fail to address the flexible temporal requirements of real-world deployment scenarios. Current \textit{online} trackers rely on frame-by-frame hand-crafted association strategies and struggle with long-term occlusions, whereas \textit{offline} approaches can cover larger time gaps, but still rely on heuristic stitching for arbitrarily long sequences. In this paper, we introduce NOOUGAT, the first tracker designed to operate with arbitrary temporal horizons. NOOUGAT leverages a unified Graph Neural Network (GNN) framework that processes non-overlapping subclips, and fuses them through a novel Autoregressive Long-term Tracking (ALT) layer. The subclip size controls the trade-off between latency and temporal context, enabling a wide range of deployment scenarios, from frame-by-frame to batch processing. NOOUGAT achieves state-of-the-art performance across both tracking regimes, improving \textit{online} AssA by +2.3 on DanceTrack, +9.2 on SportsMOT, and +5.0 on MOT20, with even greater gains in \textit{offline} mode.</p></details> |  |
| **[Second-Order Tensorial Partial Differential Equations on Graphs](http://arxiv.org/abs/2509.02015v1)** | 2025-09-02 | <details><summary>Show</summary><p>Processing data that lies on multiple interacting (product) graphs is increasingly important in practical applications, yet existing methods are mostly restricted to discrete graph filtering. Tensorial partial differential equations on graphs (TPDEGs) offer a principled framework for modeling such multidomain data in a continuous setting. However, current continuous approaches are limited to first-order derivatives, which tend to dampen high-frequency signals and slow down information propagation. This makes these TPDEGs-based approaches less effective for capturing complex, multi-scale, and heterophilic structures. In this paper, we introduce second-order TPDEGs (So-TPDEGs) and propose the first theoretically grounded framework for second-order continuous product graph neural networks. Our approach leverages the separability of cosine kernels in Cartesian product graphs to implement efficient spectral decomposition, while naturally preserving high-frequency information. We provide rigorous theoretical analyses of stability under graph perturbations and over-smoothing behavior regarding spectral properties. Our theoretical results establish a robust foundation for advancing continuous graph learning across multiple practical domains.</p></details> | 12 pages, 1 figure |
| **[Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems](http://arxiv.org/abs/2509.01972v1)** | 2025-09-02 | <details><summary>Show</summary><p>Simulating ecohydrological processes is essential for understanding complex environmental systems and guiding sustainable management amid accelerating climate change and human pressures. Process-based models provide physical realism but can suffer from structural rigidity, high computational costs, and complex calibration, while machine learning (ML) methods are efficient and flexible yet often lack interpretability and transferability. We propose a unified three-phase framework that integrates process-based models with ML and progressively embeds them into artificial intelligence (AI) through knowledge distillation. Phase I, behavioral distillation, enhances process models via surrogate learning and model simplification to capture key dynamics at lower computational cost. Phase II, structural distillation, reformulates process equations as modular components within a graph neural network (GNN), enabling multiscale representation and seamless integration with ML models. Phase III, cognitive distillation, embeds expert reasoning and adaptive decision-making into intelligent modeling agents using the Eyes-Brain-Hands-Mouth architecture. Demonstrations for the Samish watershed highlight the framework's applicability to ecohydrological modeling, showing that it can reproduce process-based model outputs, improve predictive accuracy, and support scenario-based decision-making. The framework offers a scalable and transferable pathway toward next-generation intelligent ecohydrological modeling systems, with the potential extension to other process-based domains.</p></details> | 25 pages, 6 figures |
| **[Causal representation learning from network data](http://arxiv.org/abs/2509.01916v1)** | 2025-09-02 | <details><summary>Show</summary><p>Causal disentanglement from soft interventions is identifiable under the assumptions of linear interventional faithfulness and availability of both observational and interventional data. Previous research has looked into this problem from the perspective of i.i.d. data. Here, we develop a framework, GraCE-VAE, for non-i.i.d. settings, in which structured context in the form of network data is available. GraCE-VAE integrates discrepancy-based variational autoencoders with graph neural networks to jointly recover the true latent causal graph and intervention effects. We show that the theoretical results of identifiability from i.i.d. data hold in our setup. We also empirically evaluate GraCE-VAE against state-of-the-art baselines on three genetic perturbation datasets to demonstrate the impact of leveraging structured context for causal disentanglement.</p></details> |  |
| **[Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](http://arxiv.org/abs/2508.05025v2)** | 2025-09-02 | <details><summary>Show</summary><p>Augmented Reality (AR) systems, while enhancing task performance through real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on virtual content that compromises situational awareness (SA) in safety-critical scenarios. This paper investigates SA in AR-guided cardiopulmonary resuscitation (CPR), where responders must balance effective compressions with vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth and rate) and conducted a user study with simulated unexpected incidents (e.g., bleeding) to evaluate SA, in which SA metrics were collected via observation and questionnaires administered during freeze-probe events. Eye tracking analysis revealed that higher SA levels were associated with greater saccadic amplitude and velocity, and with reduced proportion and frequency of fixations on virtual content. To predict SA, we propose FixGraphPool, a graph neural network that structures gaze events (fixations, saccades) into spatiotemporal graphs, effectively capturing dynamic attentional patterns. Our model achieved 83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and state-of-the-art time-series models by leveraging domain knowledge and spatial-temporal information encoded in ET data. These findings demonstrate the potential of eye tracking for SA modeling in AR and highlight its utility in designing AR systems that ensure user safety and situational awareness.</p></details> |  |
| **[Enhanced Single-Cell RNA-seq Embedding through Gene Expression and Data-Driven Gene-Gene Interaction Integration](http://arxiv.org/abs/2509.02639v1)** | 2025-09-01 | <details><summary>Show</summary><p>Single-cell RNA sequencing (scRNA-seq) provides unprecedented insights into cellular heterogeneity, enabling detailed analysis of complex biological systems at single-cell resolution. However, the high dimensionality and technical noise inherent in scRNA-seq data pose significant analytical challenges. While current embedding methods focus primarily on gene expression levels, they often overlook crucial gene-gene interactions that govern cellular identity and function. To address this limitation, we present a novel embedding approach that integrates both gene expression profiles and data-driven gene-gene interactions. Our method first constructs a Cell-Leaf Graph (CLG) using random forest models to capture regulatory relationships between genes, while simultaneously building a K-Nearest Neighbor Graph (KNNG) to represent expression similarities between cells. These graphs are then combined into an Enriched Cell-Leaf Graph (ECLG), which serves as input for a graph neural network to compute cell embeddings. By incorporating both expression levels and gene-gene interactions, our approach provides a more comprehensive representation of cellular states. Extensive evaluation across multiple datasets demonstrates that our method enhances the detection of rare cell populations and improves downstream analyses such as visualization, clustering, and trajectory inference. This integrated approach represents a significant advance in single-cell data analysis, offering a more complete framework for understanding cellular diversity and dynamics.</p></details> | <details><summary>33 pa...</summary><p>33 pages, 9 figures, article</p></details> |
| **[TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring](http://arxiv.org/abs/2509.01640v1)** | 2025-09-01 | <details><summary>Show</summary><p>Essay writing is a critical component of student assessment, yet manual scoring is labor-intensive and inconsistent. Automated Essay Scoring (AES) offers a promising alternative, but current approaches face limitations. Recent studies have incorporated Graph Neural Networks (GNNs) into AES using static word embeddings that fail to capture contextual meaning, especially for polysemous words. Additionally, many methods rely on holistic scoring, overlooking specific writing aspects such as grammar, vocabulary, and cohesion. To address these challenges, this study proposes TransGAT, a novel approach that integrates fine-tuned Transformer models with GNNs for analytic scoring. TransGAT combines the contextual understanding of Transformers with the relational modeling strength of Graph Attention Networks (GAT). It performs two-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa, and DeBERTaV3) with a separate GAT. In each pair, the first stream generates essay-level predictions, while the second applies GAT to Transformer token embeddings, with edges constructed from syntactic dependencies. The model then fuses predictions from both streams to produce the final analytic score. Experiments on the ELLIPSE dataset show that TransGAT outperforms baseline models, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all analytic scoring dimensions. These findings highlight the potential of TransGAT to advance AES systems.</p></details> |  |
| **[Graph Contrastive Learning versus Untrained Baselines: The Role of Dataset Size](http://arxiv.org/abs/2509.01541v1)** | 2025-09-01 | <details><summary>Show</summary><p>Graph Contrastive Learning (GCL) has emerged as a leading paradigm for self-supervised learning on graphs, with strong performance reported on standardized datasets and growing applications ranging from genomics to drug discovery. We ask a basic question: does GCL actually outperform untrained baselines? We find that GCL's advantage depends strongly on dataset size and task difficulty. On standard datasets, untrained Graph Neural Networks (GNNs), simple multilayer perceptrons, and even handcrafted statistics can rival or exceed GCL. On the large molecular dataset ogbg-molhiv, we observe a crossover: GCL lags at small scales but pulls ahead beyond a few thousand graphs, though this gain eventually plateaus. On synthetic datasets, GCL accuracy approximately scales with the logarithm of the number of graphs and its performance gap (compared with untrained GNNs) varies with respect to task complexity. Moving forward, it is crucial to identify the role of dataset size in benchmarks and applications, as well as to design GCL algorithms that avoid performance plateaus.</p></details> | 12 pages, 5 figures |
| **[Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory](http://arxiv.org/abs/2509.05337v1)** | 2025-09-01 | <details><summary>Show</summary><p>Detecting and preventing falls in humans is a critical component of assistive robotic systems. While significant progress has been made in detecting falls, the prediction of falls before they happen, and analysis of the transient state between stability and an impending fall remain unexplored. In this paper, we propose a anticipatory fall detection method that utilizes a hybrid model combining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory (LSTM) networks that decoupled the motion prediction and gait classification tasks to anticipate falls with high accuracy. Our approach employs real-time skeletal features extracted from video sequences as input for the proposed model. The DGNN acts as a classifier, distinguishing between three gait states: stable, transient, and fall. The LSTM-based network then predicts human movement in subsequent time steps, enabling early detection of falls. The proposed model was trained and validated using the OUMVLP-Pose and URFD datasets, demonstrating superior performance in terms of prediction error and recognition accuracy compared to models relying solely on DGNN and models from literature. The results indicate that decoupling prediction and classification improves performance compared to addressing the unified problem using only the DGNN. Furthermore, our method allows for the monitoring of the transient state, offering valuable insights that could enhance the functionality of advanced assistance systems.</p></details> | <details><summary>Prese...</summary><p>Presented at IEEE RO-MAN 2025</p></details> |
| **[ADMP-GNN: Adaptive Depth Message Passing GNN](http://arxiv.org/abs/2509.01170v1)** | 2025-09-01 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have proven to be highly effective in various graph learning tasks. A key characteristic of GNNs is their use of a fixed number of message-passing steps for all nodes in the graph, regardless of each node's diverse computational needs and characteristics. Through empirical real-world data analysis, we demonstrate that the optimal number of message-passing layers varies for nodes with different characteristics. This finding is further supported by experiments conducted on synthetic datasets. To address this, we propose Adaptive Depth Message Passing GNN (ADMP-GNN), a novel framework that dynamically adjusts the number of message passing layers for each node, resulting in improved performance. This approach applies to any model that follows the message passing scheme. We evaluate ADMP-GNN on the node classification task and observe performance improvements over baseline GNN models.</p></details> |  |
| **[Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning](http://arxiv.org/abs/2509.00975v1)** | 2025-08-31 | <details><summary>Show</summary><p>Forecasting future links is a central task in temporal graph (TG) reasoning, requiring models to leverage historical interactions to predict upcoming ones. Traditional neural approaches, such as temporal graph neural networks, achieve strong performance but lack explainability and cannot be applied to unseen graphs without retraining. Recent studies have begun to explore using large language models (LLMs) for graph reasoning, but most of them are constrained to static graphs or small synthetic TGs and lack the evaluation of the quality of reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that fine-tunes LLMs to perform explainable link forecasting on real-world TGs. ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning strategies from graph structure and to produce explanations that directly justify their predictions. To enable evaluation on LLM-generated reasoning traces, we propose a new evaluation protocol combining ranking metrics with an LLM-as-a-Judge system that assesses both the quality of reasoning and the impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning Qwen3-4B under our framework, show that it outperforms much larger frontier LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality explanations confirmed by both the LLM judge and human evaluation.</p></details> |  |
| **[Superposition in Graph Neural Networks](http://arxiv.org/abs/2509.00928v1)** | 2025-08-31 | <details><summary>Show</summary><p>Interpreting graph neural networks (GNNs) is difficult because message passing mixes signals and internal channels rarely align with human concepts. We study superposition, the sharing of directions by multiple features, directly in the latent space of GNNs. Using controlled experiments with unambiguous graph concepts, we extract features as (i) class-conditional centroids at the graph level and (ii) linear-probe directions at the node level, and then analyze their geometry with simple basis-invariant diagnostics. Across GCN/GIN/GAT we find: increasing width produces a phase pattern in overlap; topology imprints overlap onto node-level features that pooling partially remixes into task-aligned graph axes; sharper pooling increases axis alignment and reduces channel sharing; and shallow models can settle into metastable low-rank embeddings. These results connect representational geometry with concrete design choices (width, pooling, and final-layer activations) and suggest practical approaches for more interpretable GNNs.</p></details> |  |
| **[Towards a Unified Textual Graph Framework for Spectral Reasoning via Physical and Chemical Information Fusion](http://arxiv.org/abs/2506.17761v2)** | 2025-08-31 | <details><summary>Show</summary><p>Motivated by the limitations of current spectral analysis methods-such as reliance on single-modality data, limited generalizability, and poor interpretability-we propose a novel multi-modal spectral analysis framework that integrates prior knowledge graphs with Large Language Models. Our method explicitly bridges physical spectral measurements and chemical structural semantics by representing them in a unified Textual Graph format, enabling flexible, interpretable, and generalizable spectral understanding. Raw spectra are first transformed into TAGs, where nodes and edges are enriched with textual attributes describing both spectral properties and chemical context. These are then merged with relevant prior knowledge-including functional groups and molecular graphs-to form a Task Graph that incorporates "Prompt Nodes" supporting LLM-based contextual reasoning. A Graph Neural Network further processes this structure to complete downstream tasks. This unified design enables seamless multi-modal integration and automated feature decoding with minimal manual annotation. Our framework achieves consistently high performance across multiple spectral analysis tasks, including node-level, edge-level, and graph-level classification. It demonstrates robust generalization in both zero-shot and few-shot settings, highlighting its effectiveness in learning from limited data and supporting in-context reasoning. This work establishes a scalable and interpretable foundation for LLM-driven spectral analysis, unifying physical and chemical modalities for scientific applications.</p></details> | <details><summary>We ne...</summary><p>We need to further modify and supplement the experiment</p></details> |
| **[UQGNN: Uncertainty Quantification of Graph Neural Networks for Multivariate Spatiotemporal Prediction](http://arxiv.org/abs/2508.08551v2)** | 2025-08-31 | <details><summary>Show</summary><p>Spatiotemporal prediction plays a critical role in numerous real-world applications such as urban planning, transportation optimization, disaster response, and pandemic control. In recent years, researchers have made significant progress by developing advanced deep learning models for spatiotemporal prediction. However, most existing models are deterministic, i.e., predicting only the expected mean values without quantifying uncertainty, leading to potentially unreliable and inaccurate outcomes. While recent studies have introduced probabilistic models to quantify uncertainty, they typically focus on a single phenomenon (e.g., taxi, bike, crime, or traffic crashes), thereby neglecting the inherent correlations among heterogeneous urban phenomena. To address the research gap, we propose a novel Graph Neural Network with Uncertainty Quantification, termed UQGNN for multivariate spatiotemporal prediction. UQGNN introduces two key innovations: (i) an Interaction-aware Spatiotemporal Embedding Module that integrates a multivariate diffusion graph convolutional network and an interaction-aware temporal convolutional network to effectively capture complex spatial and temporal interaction patterns, and (ii) a multivariate probabilistic prediction module designed to estimate both expected mean values and associated uncertainties. Extensive experiments on four real-world multivariate spatiotemporal datasets from Shenzhen, New York City, and Chicago demonstrate that UQGNN consistently outperforms state-of-the-art baselines in both prediction accuracy and uncertainty quantification. For example, on the Shenzhen dataset, UQGNN achieves a 5% improvement in both prediction accuracy and uncertainty quantification.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 7 figures, SIGSPATIAL 2025</p></details> |
| **[FIT-GNN: Faster Inference Time for GNNs that 'FIT' in Memory Using Coarsening](http://arxiv.org/abs/2410.15001v3)** | 2025-08-31 | <details><summary>Show</summary><p>Scalability of Graph Neural Networks (GNNs) remains a significant challenge. To tackle this, methods like coarsening, condensation, and computation trees are used to train on a smaller graph, resulting in faster computation. Nonetheless, prior research has not adequately addressed the computational costs during the inference phase. This paper presents a novel approach to improve the scalability of GNNs by reducing computational burden during the inference phase using graph coarsening. We demonstrate two different methods -- Extra Nodes and Cluster Nodes. Our study extends the application of graph coarsening for graph-level tasks, including graph classification and graph regression. We conduct extensive experiments on multiple benchmark datasets to evaluate the performance of our approach. Our results show that the proposed method achieves orders of magnitude improvements in single-node inference time compared to traditional approaches. Furthermore, it significantly reduces memory consumption for node and graph classification and regression tasks, enabling efficient training and inference on low-resource devices where conventional methods are impractical. Notably, these computational advantages are achieved while maintaining competitive performance relative to baseline models.</p></details> |  |
| **[Flow Matters: Directional and Expressive GNNs for Heterophilic Graphs](http://arxiv.org/abs/2509.00772v1)** | 2025-08-31 | <details><summary>Show</summary><p>In heterophilic graphs, where neighboring nodes often belong to different classes, conventional Graph Neural Networks (GNNs) struggle due to their reliance on local homophilous neighborhoods. Prior studies suggest that modeling edge directionality in such graphs can increase effective homophily and improve classification performance. Simultaneously, recent work on polynomially expressive GNNs shows promise in capturing higher-order interactions among features. In this work, we study the combined effect of edge directionality and expressive message passing on node classification in heterophilic graphs. Specifically, we propose two architectures: (1) a polynomially expressive GAT baseline (Poly), and (2) a direction-aware variant (Dir-Poly) that separately aggregates incoming and outgoing edges. Both models are designed to learn permutation-equivariant high-degree polynomials over input features, while remaining scalable with no added time complexity. Experiments on five benchmark heterophilic datasets show that our Poly model consistently outperforms existing baselines, and that Dir-Poly offers additional gains on graphs with inherent directionality (e.g., Roman Empire), achieving state-of-the-art results. Interestingly, on undirected graphs, introducing artificial directionality does not always help, suggesting that the benefit of directional message passing is context-dependent. Our findings highlight the complementary roles of edge direction and expressive feature modeling in heterophilic graph learning.</p></details> |  |
| **[From Anchors to Answers: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models](http://arxiv.org/abs/2410.10743v2)** | 2025-08-31 | <details><summary>Show</summary><p>Enabling large language models (LLMs) to effectively process and reason with graph-structured data remains a significant challenge despite their remarkable success in natural language tasks. Current approaches either convert graph structures into verbose textual descriptions, consuming substantial computational resources, or employ complex graph neural networks as tokenizers, which introduce significant training overhead. To bridge this gap, we present NT-LLM, a novel framework with an anchor-based positional encoding scheme for graph representation. Our approach strategically selects reference nodes as anchors and encodes each node's position relative to these anchors, capturing essential topological information without the computational burden of existing methods. Notably, we identify and address a fundamental issue: the inherent misalignment between discrete hop-based distances in graphs and continuous distances in embedding spaces. By implementing a rank-preserving objective for positional encoding pretraining, NT-LLM achieves superior performance across diverse graph tasks ranging from basic structural analysis to complex reasoning scenarios. Our comprehensive evaluation demonstrates that this lightweight yet powerful approach effectively enhances LLMs' ability to understand and reason with graph-structured information, offering an efficient solution for graph-based applications of language models.</p></details> | <details><summary>Accep...</summary><p>Accepted by CIKM 2025</p></details> |
| **[Robust Spatiotemporal Forecasting Using Adaptive Deep-Unfolded Variational Mode Decomposition](http://arxiv.org/abs/2509.00703v1)** | 2025-08-31 | <details><summary>Show</summary><p>Accurate spatiotemporal forecasting is critical for numerous complex systems but remains challenging due to complex volatility patterns and spectral entanglement in conventional graph neural networks (GNNs). While decomposition-integrated approaches like variational mode graph convolutional network (VMGCN) improve accuracy through signal decomposition, they suffer from computational inefficiency and manual hyperparameter tuning. To address these limitations, we propose the mode adaptive graph network (MAGN) that transforms iterative variational mode decomposition (VMD) into a trainable neural module. Our key innovations include (1) an unfolded VMD (UVMD) module that replaces iterative optimization with a fixed-depth network to reduce the decomposition time (by 250x for the LargeST benchmark), and (2) mode-specific learnable bandwidth constraints ({\alpha}k ) adapt spatial heterogeneity and eliminate manual tuning while preventing spectral overlap. Evaluated on the LargeST benchmark (6,902 sensors, 241M observations), MAGN achieves an 85-95% reduction in the prediction error over VMGCN and outperforms state-of-the-art baselines.</p></details> | <details><summary>Under...</summary><p>Under review in IEEE Signal Processing Letter</p></details> |
| **[Decomposing heterogeneous dynamical systems with graph neural networks](http://arxiv.org/abs/2407.19160v2)** | 2025-08-31 | <details><summary>Show</summary><p>Natural physical, chemical, and biological dynamical systems are often complex, with heterogeneous components interacting in diverse ways. We show how simple graph neural networks can be designed to jointly learn the interaction rules and the latent heterogeneity from observable dynamics. The learned latent heterogeneity and dynamics can be used to virtually decompose the complex system which is necessary to infer and parameterize the underlying governing equations. We tested the approach with simulation experiments of interacting moving particles, vector fields, and signaling networks. While our current aim is to better understand and validate the approach with simulated data, we anticipate it to become a generally applicable tool to uncover the governing rules underlying complex dynamics observed in nature.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 4 figures, 2 pages appendix, 2 supplementary tables, 18 supplementary figures, 14 videos linked to YouTube</p></details> |
| **[Semantic Parsing for Question Answering over Knowledge Graphs](http://arxiv.org/abs/2401.06772v3)** | 2025-08-30 | <details><summary>Show</summary><p>In this paper, we propose a novel method for question answering over knowledge graphs based on graph-to-segment mapping, designed to improve the understanding of natural language questions. Our approach is grounded in semantic parsing, a key technique for interpreting question utterances. The main challenges arise from handling implicit entities and relations, as well as complex constraints such as temporal conditions, ordinality, and aggregation within the context of a knowledge graph. To address these issues, our framework integrates both rule-based and neural methods to parse and construct accurate, comprehensive semantic segment sequences. These sequences are then assembled into semantic query graphs, providing precise representations of question utterances. We formulate question semantic parsing as a sequence generation task, employing an encoder-decoder neural network to map natural language questions into semantic segments. Furthermore, to enhance the identification of implicit entities and relations, we incorporate a graph neural network that leverages knowledge graph context to enrich question representations. Experimental evaluations on two benchmark datasets demonstrate the effectiveness and superior performance of our model in semantic parsing for knowledge graph question answering.</p></details> |  |
| **[An Efficient GNNs-to-KANs Distillation via Self-Attention Dynamic Sampling with Potential for Consumer Electronics Edge Deployment](http://arxiv.org/abs/2509.00560v1)** | 2025-08-30 | <details><summary>Show</summary><p>Knowledge distillation (KD) is crucial for deploying deep learning models in resource-constrained edge environments, particularly within the consumer electronics sector, including smart home devices, wearable technology, and mobile terminals. These applications place higher demands on model compression and inference speed, necessitating the transfer of knowledge from Graph Neural Networks (GNNs) to more efficient Multi-Layer Perceptron (MLP) models. However, due to their fixed activation functions and fully connected architecture, MLPs face challenges in rapidly capturing the complex neighborhood dependencies learned by GNNs, thereby limiting their performance in edge environments. To address these limitations, this paper introduces an innovative from GNNs to Kolmogorov-Arnold Networks (KANs) knowledge distillation framework-Self Attention Dynamic Sampling Distillation (SA-DSD). This study improved Fourier KAN (FR-KAN) and replaced MLP with the improved FR-KAN+ as the student model. Through the incorporation of learnable frequency bases and phase-shift mechanisms, along with algorithmic optimization, FR-KAN significantly improves its nonlinear fitting capability while effectively reducing computational complexity. Building on this, a margin-level sampling probability matrix, based on teacher-student prediction consistency, is constructed, and an adaptive weighted loss mechanism is designed to mitigate performance degradation in the student model due to the lack of explicit neighborhood aggregation. Extensive experiments conducted on six real-world datasets demonstrate that SA-DSD achieves performance improvements of 3.05%-3.62% over three GNN teacher models and 15.61% over the FR-KAN+ model. Moreover, when compared with key benchmark models, SA-DSD achieves a 16.96x reduction in parameter count and a 55.75% decrease in inference time.</p></details> |  |
| **[Curriculum Guided Personalized Subgraph Federated Learning](http://arxiv.org/abs/2509.00402v1)** | 2025-08-30 | <details><summary>Show</summary><p>Subgraph Federated Learning (FL) aims to train Graph Neural Networks (GNNs) across distributed private subgraphs, but it suffers from severe data heterogeneity. To mitigate data heterogeneity, weighted model aggregation personalizes each local GNN by assigning larger weights to parameters from clients with similar subgraph characteristics inferred from their current model states. However, the sparse and biased subgraphs often trigger rapid overfitting, causing the estimated client similarity matrix to stagnate or even collapse. As a result, aggregation loses effectiveness as clients reinforce their own biases instead of exploiting diverse knowledge otherwise available. To this end, we propose a novel personalized subgraph FL framework called Curriculum guided personalized sUbgraph Federated Learning (CUFL). On the client side, CUFL adopts Curriculum Learning (CL) that adaptively selects edges for training according to their reconstruction scores, exposing each GNN first to easier, generic cross-client substructures and only later to harder, client-specific ones. This paced exposure prevents early overfitting to biased patterns and enables gradual personalization. By regulating personalization, the curriculum also reshapes server aggregation from exchanging generic knowledge to propagating client-specific knowledge. Further, CUFL improves weighted aggregation by estimating client similarity using fine-grained structural indicators reconstructed on a random reference graph. Extensive experiments on six benchmark datasets confirm that CUFL achieves superior performance compared to relevant baselines. Code is available at https://github.com/Kang-Min-Ku/CUFL.git.</p></details> | <details><summary>Accep...</summary><p>Accepted to the CIKM 2025. This is an extended version of the original submission</p></details> |
| **[Unifying Adversarial Perturbation for Graph Neural Networks](http://arxiv.org/abs/2509.00387v1)** | 2025-08-30 | <details><summary>Show</summary><p>This paper studies the vulnerability of Graph Neural Networks (GNNs) to adversarial attacks on node features and graph structure. Various methods have implemented adversarial training to augment graph data, aiming to bolster the robustness and generalization of GNNs. These methods typically involve applying perturbations to the node feature, weights, or graph structure and subsequently minimizing the loss by learning more robust graph model parameters under the adversarial perturbations. Despite the effectiveness of adversarial training in enhancing GNNs' robustness and generalization abilities, its application has been largely confined to specific datasets and GNN types. In this paper, we propose a novel method, PerturbEmbedding, that integrates adversarial perturbation and training, enhancing GNNs' resilience to such attacks and improving their generalization ability. PerturbEmbedding performs perturbation operations directly on every hidden embedding of GNNs and provides a unified framework for most existing perturbation strategies/methods. We also offer a unified perspective on the forms of perturbations, namely random and adversarial perturbations. Through experiments on various datasets using different backbone models, we demonstrate that PerturbEmbedding significantly improves both the robustness and generalization abilities of GNNs, outperforming existing methods. The rejection of both random (non-targeted) and adversarial (targeted) perturbations further enhances the backbone model's performance.</p></details> |  |
| **[The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](http://arxiv.org/abs/2508.21816v1)** | 2025-08-29 | <details><summary>Show</summary><p>Context recognition (SR) is a fundamental task in computer vision that aims to extract structured semantic summaries from images by identifying key events and their associated entities. Specifically, given an input image, the model must first classify the main visual events (verb classification), then identify the participating entities and their semantic roles (semantic role labeling), and finally localize these entities in the image (semantic role localization). Existing methods treat verb classification as a single-label problem, but we show through a comprehensive analysis that this formulation fails to address the inherent ambiguity in visual event recognition, as multiple verb categories may reasonably describe the same image. This paper makes three key contributions: First, we reveal through empirical analysis that verb classification is inherently a multi-label problem due to the ubiquitous semantic overlap between verb categories. Second, given the impracticality of fully annotating large-scale datasets with multiple labels, we propose to reformulate verb classification as a single positive multi-label learning (SPMLL) problem - a novel perspective in SR research. Third, we design a comprehensive multi-label evaluation benchmark for SR that is carefully designed to fairly evaluate model performance in a multi-label setting. To address the challenges of SPMLL, we futher develop the Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to capture label correlations and adversarial training to optimize decision boundaries. Extensive experiments on real-world datasets show that our approach achieves more than 3\% MAP improvement while remaining competitive on traditional top-1 and top-5 accuracy metrics.</p></details> | <details><summary>Accep...</summary><p>Accepted by ICDM 2025</p></details> |
| **[On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature](http://arxiv.org/abs/2508.21513v1)** | 2025-08-29 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have recently shown promise as solvers for Boolean Satisfiability Problems (SATs) by operating on graph representations of logical formulas. However, their performance degrades sharply on harder instances, raising the question of whether this reflects fundamental architectural limitations. In this work, we provide a geometric explanation through the lens of graph Ricci Curvature (RC), which quantifies local connectivity bottlenecks. We prove that bipartite graphs derived from random k-SAT formulas are inherently negatively curved, and that this curvature decreases with instance difficulty. Building on this, we show that GNN-based SAT solvers are affected by oversquashing, a phenomenon where long-range dependencies become impossible to compress into fixed-length representations. We validate our claims empirically across different SAT benchmarks and confirm that curvature is both a strong indicator of problem complexity and can be used to predict performance. Finally, we connect our findings to design principles of existing solvers and outline promising directions for future work.</p></details> | Preprint |
| **[TorchCP: A Python Library for Conformal Prediction](http://arxiv.org/abs/2402.12683v4)** | 2025-08-29 | <details><summary>Show</summary><p>Conformal prediction (CP) is a powerful statistical framework that generates prediction intervals or sets with guaranteed coverage probability. While CP algorithms have evolved beyond traditional classifiers and regressors to sophisticated deep learning models like deep neural networks (DNNs), graph neural networks (GNNs), and large language models (LLMs), existing CP libraries often lack the model support and scalability for large-scale DL scenarios. This paper introduces TorchCP, a PyTorch-native library designed to integrate state-of-the-art CP algorithms into deep learning techniques, including DNN-based classifier/regressor, GNN, and LLM. Released under the LGPL-3.0 license, TorchCP comprises about 16k lines of code, validated with 100% unit test coverage and detailed documentation. Notably, TorchCP enables CP-specific training algorithms, online prediction, and GPU-accelerated batch processing, achieving up to 90% reduction in inference time on large datasets. With its low-coupling design, comprehensive suite of advanced methods, and full GPU scalability, TorchCP empowers researchers and practitioners to enhance uncertainty quantification across cutting-edge applications.</p></details> |  |
| **[Molecular Machine Learning in Chemical Process Design](http://arxiv.org/abs/2508.20527v2)** | 2025-08-29 | <details><summary>Show</summary><p>We present a perspective on molecular machine learning (ML) in the field of chemical process engineering. Recently, molecular ML has demonstrated great potential in (i) providing highly accurate predictions for properties of pure components and their mixtures, and (ii) exploring the chemical space for new molecular structures. We review current state-of-the-art molecular ML models and discuss research directions that promise further advancements. This includes ML methods, such as graph neural networks and transformers, which can be further advanced through the incorporation of physicochemical knowledge in a hybrid or physics-informed fashion. Then, we consider leveraging molecular ML at the chemical process scale, which is highly desirable yet rather unexplored. We discuss how molecular ML can be integrated into process design and optimization formulations, promising to accelerate the identification of novel molecules and processes. To this end, it will be essential to create molecule and process design benchmarks and practically validate proposed candidates, possibly in collaboration with the chemical industry.</p></details> |  |
| **[A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics](http://arxiv.org/abs/2508.21249v1)** | 2025-08-28 | <details><summary>Show</summary><p>The computational cost associated with high-fidelity CFD simulations remains a significant bottleneck in the automotive design and optimization cycle. While ML-based surrogate models have emerged as a promising alternative to accelerate aerodynamic predictions, the field is characterized by a diverse and rapidly evolving landscape of specialized neural network architectures, with no single model demonstrating universal superiority. This paper introduces a novel meta-learning framework that leverages this architectural diversity as a strength. We propose a Mixture of Experts (MoE) model that employs a dedicated gating network to dynamically and optimally combine the predictions from three heterogeneous, state-of-the-art surrogate models: DoMINO, a decomposable multi-scale neural operator; X-MeshGraphNet, a scalable multi-scale graph neural network; and FigConvNet, a factorized implicit global convolution network. The gating network learns a spatially-variant weighting strategy, assigning credibility to each expert based on its localized performance in predicting surface pressure and wall shear stress fields. To prevent model collapse and encourage balanced expert contributions, we integrate an entropy regularization term into the training loss function. The entire system is trained and validated on the DrivAerML dataset, a large-scale, public benchmark of high-fidelity CFD simulations for automotive aerodynamics. Quantitative results demonstrate that the MoE model achieves a significant reduction in L-2 prediction error, outperforming not only the ensemble average but also the most accurate individual expert model across all evaluated physical quantities. This work establishes the MoE framework as a powerful and effective strategy for creating more robust and accurate composite surrogate models by synergistically combining the complementary strengths of specialized architectures.</p></details> |  |
| **[Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin](http://arxiv.org/abs/2509.04463v1)** | 2025-08-28 | <details><summary>Show</summary><p>This study presents the development of a domain-responsive edge-aware multiscale Graph Neural Network for predicting steady, turbulent flow and thermal behavior in a two-dimensional channel containing arbitrarily shaped complex pin-fin geometries. The training dataset was constructed through an automated framework that integrated geometry generation, meshing, and flow-field solutions in ANSYS Fluent. The pin-fin geometry was parameterized using piecewise cubic splines, producing 1,000 diverse configurations through Latin Hypercube Sampling. Each simulation was converted into a graph structure, where nodes carried a feature vector containing spatial coordinates, a normalized streamwise position, one-hot boundary indicators, and a signed distance to the nearest boundary such as wall. This graph structure served as input to the newly developed Graph Neural Network, which was trained to predict temperature, velocity magnitude, and pressure at each node using data from ANSYS. The network predicted fields with outstanding accuracy, capturing boundary layers, recirculation, and the stagnation region upstream of the pin-fins while reducing wall time by 2-3 orders of magnitude. In conclusion, the novel graph neural network offered a fast and reliable surrogate for simulations in complex flow configurations.</p></details> |  |
| **[Graph-Based Feature Augmentation for Predictive Tasks on Relational Datasets](http://arxiv.org/abs/2508.20986v1)** | 2025-08-28 | <details><summary>Show</summary><p>Data has become a foundational asset driving innovation across domains such as finance, healthcare, and e-commerce. In these areas, predictive modeling over relational tables is commonly employed, with increasing emphasis on reducing manual effort through automated machine learning (AutoML) techniques. This raises an interesting question: can feature augmentation itself be automated and identify and utilize task-related relational signals? To address this challenge, we propose an end-to-end automated feature augmentation framework, ReCoGNN, which enhances initial datasets using features extracted from multiple relational tables to support predictive tasks. ReCoGNN first captures semantic dependencies within each table by modeling intra-table attribute relationships, enabling it to partition tables into structured, semantically coherent segments. It then constructs a heterogeneous weighted graph that represents inter-row relationships across all segments. Finally, ReCoGNN leverages message-passing graph neural networks to propagate information through the graph, guiding feature selection and augmenting the original dataset. Extensive experiments conducted on ten real-life and synthetic datasets demonstrate that ReCoGNN consistently outperforms existing methods on both classification and regression tasks.</p></details> |  |
| **[Deep Learning Based Concurrency Bug Detection and Localization](http://arxiv.org/abs/2508.20911v1)** | 2025-08-28 | <details><summary>Show</summary><p>Concurrency bugs, caused by improper synchronization of shared resources in multi-threaded or distributed systems, are notoriously hard to detect and thus compromise software reliability and security. The existing deep learning methods face three main limitations. First, there is an absence of large and dedicated datasets of diverse concurrency bugs for them. Second, they lack sufficient representation of concurrency semantics. Third, binary classification results fail to provide finer-grained debug information such as precise bug lines. To address these problems, we propose a novel method for effective concurrency bug detection as well as localization. We construct a dedicated concurrency bug dataset to facilitate model training and evaluation. We then integrate a pre-trained model with a heterogeneous graph neural network (GNN), by incorporating a new Concurrency-Aware Code Property Graph (CCPG) that concisely and effectively characterizes concurrency semantics. To further facilitate debugging, we employ SubgraphX, a GNN-based interpretability method, which explores the graphs to precisely localize concurrency bugs, mapping them to specific lines of source code. On average, our method demonstrates an improvement of 10\% in accuracy and precision and 26\% in recall compared to state-of-the-art methods across diverse evaluation settings.</p></details> |  |
| **[ADAGE: Active Defenses Against GNN Extraction](http://arxiv.org/abs/2503.00065v3)** | 2025-08-28 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) achieve high performance in various real-world applications, such as drug discovery, traffic states prediction, and recommendation systems. The fact that building powerful GNNs requires a large amount of training data, powerful computing resources, and human expertise turns the models into lucrative targets for model stealing attacks. Prior work has revealed that the threat vector of stealing attacks against GNNs is large and diverse, as an attacker can leverage various heterogeneous signals ranging from node labels to high-dimensional node embeddings to create a local copy of the target GNN at a fraction of the original training costs. This diversity in the threat vector renders the design of effective and general defenses challenging and existing defenses usually focus on one particular stealing setup. Additionally, they solely provide means to identify stolen model copies rather than preventing the attack. To close this gap, we propose the first and general Active Defense Against GNN Extraction (ADAGE). ADAGE builds on the observation that stealing a model's full functionality requires highly diverse queries to leak its behavior across the input space. Our defense monitors this query diversity and progressively perturbs outputs as the accumulated leakage grows. In contrast to prior work, ADAGE can prevent stealing across all common attack setups. Our extensive experimental evaluation using six benchmark datasets, four GNN models, and three types of adaptive attackers shows that ADAGE penalizes attackers to the degree of rendering stealing impossible, whilst preserving predictive performance on downstream tasks. ADAGE, thereby, contributes towards securely sharing valuable GNNs in the future.</p></details> | <details><summary>Not a...</summary><p>Not all authors have given their explicit consent</p></details> |
| **[ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks](http://arxiv.org/abs/2508.20829v1)** | 2025-08-28 | <details><summary>Show</summary><p>Financial fraud detection is essential to safeguard billions of dollars, yet the intertwined entities and fast-changing transaction behaviors in modern financial systems routinely defeat conventional machine learning models. Recent graph-based detectors make headway by representing transactions as networks, but they still overlook two fraud hallmarks rooted in time: (1) temporal motifs--recurring, telltale subgraphs that reveal suspicious money flows as they unfold--and (2) account-specific intervals of anomalous activity, when fraud surfaces only in short bursts unique to each entity. To exploit both signals, we introduce ATM-GAD, an adaptive graph neural network that leverages temporal motifs for financial anomaly detection. A Temporal Motif Extractor condenses each account's transaction history into the most informative motifs, preserving both topology and temporal patterns. These motifs are then analyzed by dual-attention blocks: IntraA reasons over interactions within a single motif, while InterA aggregates evidence across motifs to expose multi-step fraud schemes. In parallel, a differentiable Adaptive Time-Window Learner tailors the observation window for every node, allowing the model to focus precisely on the most revealing time slices. Experiments on four real-world datasets show that ATM-GAD consistently outperforms seven strong anomaly-detection baselines, uncovering fraud patterns missed by earlier methods.</p></details> |  |
| **[Graph Data Modeling: Molecules, Proteins, & Chemical Processes](http://arxiv.org/abs/2508.19356v2)** | 2025-08-28 | <details><summary>Show</summary><p>Graphs are central to the chemical sciences, providing a natural language to describe molecules, proteins, reactions, and industrial processes. They capture interactions and structures that underpin materials, biology, and medicine. This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes, introduces graphs as mathematical objects in chemistry and shows how learning algorithms (particularly graph neural networks) can operate on them. We outline the foundations of graph design, key prediction tasks, representative examples across chemical sciences, and the role of machine learning in graph-based modeling. Together, these concepts prepare readers to apply graph methods to the next generation of chemical discovery.</p></details> | <details><summary>3 to ...</summary><p>3 to 4 hours read time. 73 pages. 35 figures</p></details> |
| **[Quantum Graph Attention Network: A Novel Quantum Multi-Head Attention Mechanism for Graph Learning](http://arxiv.org/abs/2508.17630v3)** | 2025-08-28 | <details><summary>Show</summary><p>We propose the Quantum Graph Attention Network (QGAT), a hybrid graph neural network that integrates variational quantum circuits into the attention mechanism. At its core, QGAT employs strongly entangling quantum circuits with amplitude-encoded node features to enable expressive nonlinear interactions. Distinct from classical multi-head attention that separately computes each head, QGAT leverages a single quantum circuit to simultaneously generate multiple attention coefficients. This quantum parallelism facilitates parameter sharing across heads, substantially reducing computational overhead and model complexity. Classical projection weights and quantum circuit parameters are optimized jointly in an end-to-end manner, ensuring flexible adaptation to learning tasks. Empirical results demonstrate QGAT's effectiveness in capturing complex structural dependencies and improved generalization in inductive scenarios, highlighting its potential for scalable quantum-enhanced learning across domains such as chemistry, biology, and network analysis. Furthermore, experiments confirm that quantum embedding enhances robustness against feature and structural noise, suggesting advantages in handling real-world noisy data. The modularity of QGAT also ensures straightforward integration into existing architectures, allowing it to easily augment classical attention-based models.</p></details> |  |
| **[LASE: Learned Adjacency Spectral Embeddings](http://arxiv.org/abs/2412.17734v2)** | 2025-08-28 | <details><summary>Show</summary><p>We put forth a principled design of a neural architecture to learn nodal Adjacency Spectral Embeddings (ASE) from graph inputs. By bringing to bear the gradient descent (GD) method and leveraging the principle of algorithm unrolling, we truncate and re-interpret each GD iteration as a layer in a graph neural network (GNN) that is trained to approximate the ASE. Accordingly, we call the resulting embeddings and our parametric model Learned ASE (LASE), which is interpretable, parameter efficient, robust to inputs with unobserved edges, and offers controllable complexity during inference. LASE layers combine Graph Convolutional Network (GCN) and fully-connected Graph Attention Network (GAT) modules, which is intuitively pleasing since GCN-based local aggregations alone are insufficient to express the sought graph eigenvectors. We propose several refinements to the unrolled LASE architecture (such as sparse attention in the GAT module and decoupled layerwise parameters) that offer favorable approximation error versus computation tradeoffs; even outperforming heavily-optimized eigendecomposition routines from scientific computing libraries. Because LASE is a differentiable function with respect to its parameters as well as its graph input, we can seamlessly integrate it as a trainable module within a larger (semi-)supervised graph representation learning pipeline. The resulting end-to-end system effectively learns ``discriminative ASEs'' that exhibit competitive performance in supervised link prediction and node classification tasks, outperforming a GNN even when the latter is endowed with open loop, meaning task-agnostic, precomputed spectral positional encodings.</p></details> |  |
| **[Local Virtual Nodes for Alleviating Over-Squashing in Graph Neural Networks](http://arxiv.org/abs/2508.20597v1)** | 2025-08-28 | <details><summary>Show</summary><p>Over-squashing is a challenge in training graph neural networks for tasks involving long-range dependencies. In such tasks, a GNN's receptive field should be large enough to enable communication between distant nodes. However, gathering information from a wide range of neighborhoods and squashing its content into fixed-size node representations makes message-passing vulnerable to bottlenecks. Graph rewiring and adding virtual nodes are commonly studied remedies that create additional pathways around bottlenecks to mitigate over-squashing. However, these techniques alter the input graph's global topology and disrupt the domain knowledge encoded in the original graph structure, both of which could be essential to specific tasks and domains. This study presents Local Virtual Nodes (LVN) with trainable embeddings to alleviate the effects of over-squashing without significantly corrupting the global structure of the input graph. The position of the LVNs is determined by the node centrality, which indicates the existence of potential bottlenecks. Thus, the proposed approach aims to improve the connectivity in the regions with likely bottlenecks. Furthermore, trainable LVN embeddings shared across selected central regions facilitate communication between distant nodes without adding more layers. Extensive experiments on benchmark datasets demonstrate that LVNs can enhance structural connectivity and significantly improve performance on graph and node classification tasks. The code can be found at https://github.com/ALLab-Boun/LVN/}{https://github.com/ALLab-Boun/LVN/.</p></details> |  |
| **[A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](http://arxiv.org/abs/2508.20583v1)** | 2025-08-28 | <details><summary>Show</summary><p>Developments in Graph-Language Models (GLMs) aim to integrate the structural reasoning capabilities of Graph Neural Networks (GNNs) with the semantic understanding of Large Language Models (LLMs). However, we demonstrate that current evaluation benchmarks for GLMs, which are primarily repurposed node-level classification datasets, are insufficient to assess multimodal reasoning. Our analysis reveals that strong performance on these benchmarks is achievable using unimodal information alone, suggesting that they do not necessitate graph-language integration. To address this evaluation gap, we introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed to evaluate multimodal reasoning at various complexity levels. Our benchmark employs a synthetic graph generation pipeline paired with questions that require joint reasoning over structure and textual semantics. We perform a thorough evaluation of representative GLM architectures and find that soft-prompted LLM baselines perform on par with GLMs that incorporate a full GNN backbone. This result calls into question the architectural necessity of incorporating graph structure into LLMs. We further show that GLMs exhibit significant performance degradation in tasks that require structural reasoning. These findings highlight limitations in the graph reasoning capabilities of current GLMs and provide a foundation for advancing the community toward explicit multimodal reasoning involving graph structure and language.</p></details> |  |
| **[GLaRE: A Graph-based Landmark Region Embedding Network for Emotion Recognition](http://arxiv.org/abs/2508.20579v1)** | 2025-08-28 | <details><summary>Show</summary><p>Facial expression recognition (FER) is a crucial task in computer vision with wide range of applications including human computer interaction, surveillance, and assistive technologies. However, challenges such as occlusion, expression variability, and lack of interpretability hinder the performance of traditional FER systems. Graph Neural Networks (GNNs) offer a powerful alternative by modeling relational dependencies between facial landmarks, enabling structured and interpretable learning. In this paper, we propose GLaRE, a novel Graph-based Landmark Region Embedding network for emotion recognition. Facial landmarks are extracted using 3D facial alignment, and a quotient graph is constructed via hierarchical coarsening to preserve spatial structure while reducing complexity. Our method achieves 64.89 percentage accuracy on AffectNet and 94.24 percentage on FERG, outperforming several existing baselines. Additionally, ablation studies have demonstrated that region-level embeddings from quotient graphs have contributed to improved prediction performance.</p></details> | 11 pages, 6 figures |
| **[Dynamic Triangulation-Based Graph Rewiring for Graph Neural Networks](http://arxiv.org/abs/2508.19071v2)** | 2025-08-28 | <details><summary>Show</summary><p>Graph Neural Networks (GNNs) have emerged as the leading paradigm for learning over graph-structured data. However, their performance is limited by issues inherent to graph topology, most notably oversquashing and oversmoothing. Recent advances in graph rewiring aim to mitigate these limitations by modifying the graph topology to promote more effective information propagation. In this work, we introduce TRIGON, a novel framework that constructs enriched, non-planar triangulations by learning to select relevant triangles from multiple graph views. By jointly optimizing triangle selection and downstream classification performance, our method produces a rewired graph with markedly improved structural properties such as reduced diameter, increased spectral gap, and lower effective resistance compared to existing rewiring methods. Empirical results demonstrate that TRIGON outperforms state-of-the-art approaches on node classification tasks across a range of homophilic and heterophilic benchmarks.</p></details> | <details><summary>Accep...</summary><p>Accepted to CIKM 2025</p></details> |
| **[Reconsidering the Performance of GAE in Link Prediction](http://arxiv.org/abs/2411.03845v4)** | 2025-08-28 | <details><summary>Show</summary><p>Recent advancements in graph neural networks (GNNs) for link prediction have introduced sophisticated training techniques and model architectures. However, reliance on outdated baselines may exaggerate the benefits of these new approaches. To tackle this issue, we systematically explore Graph Autoencoders (GAEs) by applying model-agnostic tricks in recent methods and tuning hyperparameters. We find that a well-tuned GAE can match the performance of recent sophisticated models while offering superior computational efficiency on widely-used link prediction benchmarks. Our approach delivers substantial performance gains on datasets where structural information dominates and feature data is limited. Specifically, our GAE achieves a state-of-the-art Hits@100 score of 78.41\% on the ogbl-ppa dataset. Furthermore, we examine the impact of various tricks to uncover the reasons behind our success and to guide the design of future methods. Our study emphasizes the critical need to update baselines for a more accurate assessment of progress in GNNs for link prediction. Our code is available at https://github.com/GraphPKU/Refined-GAE.</p></details> | <details><summary>Accep...</summary><p>Accepted at CIKM 2025</p></details> |
| **[Graph-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning](http://arxiv.org/abs/2508.17387v2)** | 2025-08-28 | <details><summary>Show</summary><p>Generalizing to unseen graph tasks without task-pecific supervision remains challenging. Graph Neural Networks (GNNs) are limited by fixed label spaces, while Large Language Models (LLMs) lack structural inductive biases. Recent advances in Large Reasoning Models (LRMs) provide a zero-shot alternative via explicit, long chain-of-thought reasoning. Inspired by this, we propose a GNN-free approach that reformulates graph tasks--node classification, link prediction, and graph classification--as textual reasoning problems solved by LRMs. We introduce the first datasets with detailed reasoning traces for these tasks and develop Graph-R1, a reinforcement learning framework that leverages task-specific rethink templates to guide reasoning over linearized graphs. Experiments demonstrate that Graph-R1 outperforms state-of-the-art baselines in zero-shot settings, producing interpretable and effective predictions. Our work highlights the promise of explicit reasoning for graph learning and provides new resources for future research.</p></details> | <details><summary>Accep...</summary><p>Accepted at EMNLP 2025</p></details> |
| **[Structure-aware Hypergraph Transformer for Diagnosis Prediction in Electronic Health Records](http://arxiv.org/abs/2508.20500v1)** | 2025-08-28 | <details><summary>Show</summary><p>Electronic Health Records (EHR) systematically organize patient health data through standardized medical codes, serving as a comprehensive and invaluable source for predictive modeling. Graph neural networks (GNNs) have demonstrated effectiveness in modeling interactions between medical codes within EHR. However, existing GNN-based methods are inadequate due to: a) their reliance on pairwise relations fails to capture the inherent higher-order dependencies in clinical data, and b) the localized message-passing scheme limits representation power. To address these issues, this paper proposes a novel Structure-aware HyperGraph Transformer (SHGT) framework following three-fold ideas: a) employing a hypergraph structural encoder to capture higher-order interactions among medical codes, b) integrating the Transformer architecture to reason over the entire hypergraph, and c) designing a tailored loss function incorporating hypergraph reconstruction to preserve the hypergraph's original structure. Experiments on real-world EHR datasets demonstrate that the proposed SHGT outperforms existing state-of-the-art models on diagnosis prediction.</p></details> |  |
| **[High-Rank Irreducible Cartesian Tensor Decomposition and Bases of Equivariant Spaces](http://arxiv.org/abs/2412.18263v7)** | 2025-08-28 | <details><summary>Show</summary><p>Irreducible Cartesian tensors (ICTs) play a crucial role in the design of equivariant graph neural networks, as well as in theoretical chemistry and chemical physics. Meanwhile, the design space of available linear operations on tensors that preserve symmetry presents a significant challenge. The ICT decomposition and a basis of this equivariant space are difficult to obtain for high-rank tensors. After decades of research, Bonvicini (2024) has recently achieved an explicit ICT decomposition for $n=5$ with factorial time/space complexity. In this work we, for the first time, obtain decomposition matrices for ICTs up to rank $n=9$ with reduced and affordable complexity, by constructing what we call path matrices. The path matrices are obtained via performing chain-like contractions with Clebsch-Gordan matrices following the parentage scheme. We prove and leverage that the concatenation of path matrices is an orthonormal change-of-basis matrix between the Cartesian tensor product space and the spherical direct sum spaces. Furthermore, we identify a complete orthogonal basis for the equivariant space, rather than a spanning set (Pearce-Crump, 2023b), through this path matrices technique. Our method avoids the RREF algorithm and maintains a fully analytical derivation of each ICT decomposition matrix, thereby significantly improving the algorithm's speed to obtain arbitrary rank orthogonal ICT decomposition matrices and orthogonal equivariant bases. We further extend our result to the arbitrary tensor product and direct sum spaces, enabling free design between different spaces while keeping symmetry. The Python code is available at https://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, where the $n=6,\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and 4m32s on 28-core Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz, respectively.</p></details> | <details><summary>53 pa...</summary><p>53 pages. Accepted to JMLR</p></details> |

